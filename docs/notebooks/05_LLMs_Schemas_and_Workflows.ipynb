{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 5: A Detailed Look at Agents - Custom LLMs, Structured Output, and Workflows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Welcome to the fifth tutorial in the Aurite Agents series! Building on what you learned in the previous tutorials, we'll now explore more advanced features that give you greater control over your AI agents.\n",
    "\n",
    "**In this tutorial, you will learn:**\n",
    "\n",
    "1. **Custom LLM Configurations** - How to create and use your own LLM settings beyond the defaults\n",
    "2. **Structured Output** - How to enforce JSON schemas so agents return data in exactly the format you need\n",
    "3. **Simple Workflows** - How to chain multiple agents together to create more complex behaviors\n",
    "\n",
    "By the end of this tutorial, you'll have built a multi-agent workflow that demonstrates all three concepts working together.\n",
    "\n",
    "> üìã **Prerequisites**\n",
    "> This tutorial assumes you've completed the previous tutorials and are familiar with basic agent creation and execution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚úÖ 1. Setup and Installation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start with the same setup as the previous tutorials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install aurite==0.3.14"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure Your API Key\n",
    "\n",
    "As before, we need to set up your OpenAI API key for this tutorial. Follow the same process from the previous tutorials:\n",
    "\n",
    "- **Google Colab Users:** Use the **Secrets** tab (üîë) to create a secret named `OPENAI_API_KEY`\n",
    "- **Local IDE Users:** Create a `.env` file with `OPENAI_API_KEY=sk-your-key-here`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Load API key safely\n",
    "try:\n",
    "    from google.colab import userdata #type: ignore\n",
    "    os.environ['OPENAI_API_KEY'] = userdata.get('OPENAI_API_KEY')\n",
    "except ImportError:\n",
    "    from dotenv import load_dotenv\n",
    "    load_dotenv()\n",
    "except Exception as e:\n",
    "    print(f\"Could not load API key. Please ensure it's set up correctly. Error: {e}\")\n",
    "\n",
    "if os.getenv(\"OPENAI_API_KEY\"):\n",
    "    print(\"‚úÖ OpenAI API Key is set and ready!\")\n",
    "else:\n",
    "    print(\"‚ùå OpenAI API Key not found. Please follow the setup steps above.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown\n",
    "\n",
    "def display_agent_response(agent_name: str, query: str, response: str):\n",
    "  \"\"\"Formats and displays the agent's response in a structured Markdown block.\"\"\"\n",
    "\n",
    "  output = f\"\"\"\n",
    "  <div style=\\\"border: 1px solid #D1D5DB; border-radius: 8px; margin-top: 20px; font-family: sans-serif; box-shadow: 0 4px 6px rgba(0,0,0,0.05);\\\">\n",
    "    <div style=\\\"background-color: #F3F4F6; padding: 10px 15px; border-bottom: 1px solid #D1D5DB; border-radius: 8px 8px 0 0;\\\">\n",
    "      <h3 style=\\\"margin: 0; font-size: 16px; color: #1F2937; display: flex; align-items: center;\\\">\n",
    "        <span style=\\\"margin-right: 8px;\\\">ü§ñ</span>\n",
    "        Agent Response: <code style=\\\"background-color: #E5E7EB; color: #374151; padding: 2px 6px; border-radius: 4px; margin-left: 8px;\\\">{agent_name}</code>\n",
    "      </h3>\n",
    "    </div>\n",
    "    <div style=\\\"padding: 15px;\\\">\n",
    "      <p style=\\\"margin: 0 0 10px 0; color: #6B7280; font-size: 14px;\\\">\n",
    "        <strong>Your Query:</strong>\n",
    "      </p>\n",
    "      <p style=\\\"background-color: #F9FAFB; margin: 0 0 15px 0; color: #1F2937; border: 1px solid #E5E7EB; border-left: 3px solid #9CA3AF; padding: 10px 12px; border-radius: 4px;\\\">\n",
    "        <em>\\\"{query}\\\"</em>\n",
    "      </p>\n",
    "      <hr style=\\\"border: none; border-top: 1px dashed #D1D5DB; margin-bottom: 15px;\\\">\n",
    "      <p style=\\\"margin: 0 0 10px 0; color: #6B7280; font-size: 14px;\\\">\n",
    "        <strong>Result:</strong>\n",
    "      </p>\n",
    "      <div style=\\\"background-color: #FFFFFF; padding: 15px; border-radius: 5px; border: 1px solid #E5E7EB; color: #1F2937; font-size: 15px; line-height: 1.6;\\\">\n",
    "        {response}\n",
    "      </div>\n",
    "    </div>\n",
    "  </div>\n",
    "  \"\"\"\n",
    "  display(Markdown(output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîß 2. Custom LLM Configurations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Tutorial 1, we used the default LLM settings (GPT-4 Turbo). But what if you want different settings? Maybe you want:\n",
    "\n",
    "- A faster, cheaper model for simple tasks\n",
    "- Different temperature settings for more creative or more predictable responses\n",
    "- Custom token limits\n",
    "- A different system prompt that applies to all agents using this LLM\n",
    "\n",
    "This is where **LLM Configurations** come in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Aurite\n",
    "from aurite import Aurite, AgentConfig, LLMConfig\n",
    "\n",
    "aurite = Aurite()\n",
    "await aurite.initialize()\n",
    "\n",
    "print(\"‚úÖ Aurite initialized!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a Custom LLM Configuration\n",
    "\n",
    "Let's create two different LLM configurations:\n",
    "1. A **fast, cheap** configuration using GPT-4o-mini\n",
    "2. A **creative** configuration with higher temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a fast, economical LLM configuration\n",
    "fast_llm = LLMConfig(\n",
    "    llm_id=\"fast_gpt\",\n",
    "    provider=\"openai\",\n",
    "    model_name=\"gpt-4o-mini\",\n",
    "    temperature=0.2,  # Lower temperature = more predictable\n",
    "    max_tokens=1024,  # Fewer tokens = faster + cheaper\n",
    "    default_system_prompt=\"You are a helpful, concise assistant. Keep responses brief and to the point.\"\n",
    ")\n",
    "\n",
    "# Create a creative LLM configuration\n",
    "creative_llm = LLMConfig(\n",
    "    llm_id=\"creative_gpt\",\n",
    "    provider=\"openai\",\n",
    "    model_name=\"gpt-4o\",\n",
    "    temperature=0.9,  # Higher temperature = more creative\n",
    "    max_tokens=2048,\n",
    "    default_system_prompt=\"You are a creative, imaginative assistant. Feel free to be expressive and think outside the box.\"\n",
    ")\n",
    "\n",
    "# Register both LLM configurations with Aurite\n",
    "await aurite.register_llm_config(fast_llm)\n",
    "await aurite.register_llm_config(creative_llm)\n",
    "\n",
    "print(\"‚úÖ Custom LLM configurations registered!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Custom LLM Configurations in Agents\n",
    "\n",
    "Now let's create agents that use our custom LLM configurations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an agent using the fast LLM\n",
    "fast_agent = AgentConfig(\n",
    "    name=\"Fast Summarizer\",\n",
    "    llm_config_id=\"fast_gpt\",  # Reference our custom LLM\n",
    "    system_prompt=\"Summarize the user's input in exactly one sentence.\"\n",
    ")\n",
    "\n",
    "# Create an agent using the creative LLM\n",
    "creative_agent = AgentConfig(\n",
    "    name=\"Creative Storyteller\",\n",
    "    llm_config_id=\"creative_gpt\",  # Reference our custom LLM\n",
    "    system_prompt=\"Turn the user's input into a short, imaginative story.\"\n",
    ")\n",
    "\n",
    "# Register both agents\n",
    "await aurite.register_agent(fast_agent)\n",
    "await aurite.register_agent(creative_agent)\n",
    "\n",
    "print(\"‚úÖ Agents with custom LLMs registered!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the Different LLM Behaviors\n",
    "\n",
    "Let's see how the same input produces different outputs based on our LLM configurations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input = \"A robot discovers an old library filled with forgotten books. \\\n",
    "It starts reading them and finds a book that changes its understanding of the world. \\\n",
    "It decides to share this knowledge with other robots, sparking a revolution of thought and creativity among them.\"\n",
    "\n",
    "# Test the fast agent\n",
    "fast_result = await aurite.run_agent(\n",
    "    agent_name=\"Fast Summarizer\",\n",
    "    user_message=user_input\n",
    ")\n",
    "\n",
    "display_agent_response(\n",
    "    agent_name=\"Fast Summarizer (GPT-4o-mini, temp=0.2)\",\n",
    "    query=user_input,\n",
    "    response=fast_result.primary_text\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the creative agent\n",
    "creative_result = await aurite.run_agent(\n",
    "    agent_name=\"Creative Storyteller\",\n",
    "    user_message=user_input\n",
    ")\n",
    "\n",
    "display_agent_response(\n",
    "    agent_name=\"Creative Storyteller (GPT-4o, temp=0.9)\",\n",
    "    query=user_input,\n",
    "    response=creative_result.primary_text\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how the **Fast Summarizer** gives you a concise, predictable response, while the **Creative Storyteller** produces a more imaginative and varied output. This demonstrates how LLM configurations let you tune the behavior for different use cases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä 3. Structured Output with JSON Schema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes you don't want free-form text from your agent‚Äîyou want **structured data** in a specific format. This is where `config_validation_schema` comes in.\n",
    "\n",
    "With a JSON schema, you can force your agent to return data in exactly the structure you need, making it easy to use the output in your application code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating an Agent with Structured Output\n",
    "\n",
    "Let's create an agent that analyzes text and returns structured data about it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a JSON schema for our structured output\n",
    "text_analysis_schema = {\n",
    "    \"type\": \"object\",\n",
    "    \"properties\": {\n",
    "        \"sentiment\": {\n",
    "            \"type\": \"string\",\n",
    "            \"enum\": [\"positive\", \"negative\", \"neutral\"],\n",
    "            \"description\": \"The overall sentiment of the text\"\n",
    "        },\n",
    "        \"key_topics\": {\n",
    "            \"type\": \"array\",\n",
    "            \"items\": {\"type\": \"string\"},\n",
    "            \"description\": \"Main topics or themes identified in the text\"\n",
    "        },\n",
    "        \"word_count\": {\n",
    "            \"type\": \"integer\",\n",
    "            \"description\": \"Approximate number of words in the text\"\n",
    "        },\n",
    "        \"summary\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"A brief summary of the text content\"\n",
    "        }\n",
    "    },\n",
    "    \"required\": [\"sentiment\", \"key_topics\", \"word_count\", \"summary\"]\n",
    "}\n",
    "\n",
    "# Create an agent that returns structured analysis\n",
    "analysis_agent = AgentConfig(\n",
    "    name=\"Text Analyzer\",\n",
    "    llm_config_id=\"fast_gpt\",  # Use our fast LLM for this structured task\n",
    "    system_prompt=\"You are a text analysis expert. Analyze the user's text and return your analysis as a JSON object matching the provided schema. CRITICAL: Your response MUST be a single JSON object matching the schema provided. Do not include any other text or explanations in your response - just the JSON object.\",\n",
    "    config_validation_schema=text_analysis_schema\n",
    ")\n",
    "\n",
    "await aurite.register_agent(analysis_agent)\n",
    "print(\"‚úÖ Text Analyzer agent with structured output registered!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Structured Output\n",
    "\n",
    "Now let's test our structured output agent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_to_analyze = \"\"\"\n",
    "I absolutely love the new AI features in this software!\n",
    "The machine learning capabilities are incredibly impressive and have streamlined our workflow significantly.\n",
    "Our team productivity has increased by 30% since we started using these tools.\n",
    "The natural language processing component is particularly noteworthy.\n",
    "\"\"\"\n",
    "\n",
    "analysis_result = await aurite.run_agent(\n",
    "    agent_name=\"Text Analyzer\",\n",
    "    user_message=f\"Please analyze this text: {text_to_analyze}\"\n",
    ")\n",
    "\n",
    "display_agent_response(\n",
    "    agent_name=\"Text Analyzer (Structured Output)\",\n",
    "    query=\"Analyze the provided text\",\n",
    "    response=analysis_result.primary_text\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working with the Structured Data\n",
    "\n",
    "Since the output is guaranteed to be valid JSON, we can easily parse it and use it in our code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Parse the JSON response\n",
    "try:\n",
    "    analysis_data = json.loads(analysis_result.primary_text)\n",
    "\n",
    "    print(\"üìä Parsed Analysis Results:\")\n",
    "    print(f\"   Sentiment: {analysis_data['sentiment']}\")\n",
    "    print(f\"   Word Count: {analysis_data['word_count']}\")\n",
    "    print(f\"   Key Topics: {', '.join(analysis_data['key_topics'])}\")\n",
    "    print(f\"   Summary: {analysis_data['summary']}\")\n",
    "\n",
    "except json.JSONDecodeError:\n",
    "    print(\"‚ùå Failed to parse JSON response\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîó 4. Building Simple Workflows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's combine everything we've learned to create a **workflow**‚Äîa sequence of agents that work together to accomplish a more complex task.\n",
    "\n",
    "We'll build a **Content Processing Workflow** that:\n",
    "1. **Step 1:** Takes raw text and creates a structured analysis\n",
    "2. **Step 2:** Takes that analysis and generates recommendations based on it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the Workflow Agents\n",
    "\n",
    "First, let's create our two specialized agents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agent 1: Content Analyzer (with structured output)\n",
    "content_analyzer_schema = {\n",
    "    \"type\": \"object\",\n",
    "    \"properties\": {\n",
    "        \"content_type\": {\n",
    "            \"type\": \"string\",\n",
    "            \"enum\": [\"marketing\", \"technical\", \"educational\", \"news\", \"social\", \"other\"],\n",
    "            \"description\": \"The type/category of content\"\n",
    "        },\n",
    "        \"target_audience\": {\n",
    "            \"type\": \"string\",\n",
    "            \"enum\": [\"general\", \"technical\", \"business\", \"academic\", \"youth\"],\n",
    "            \"description\": \"The intended audience for this content\"\n",
    "        },\n",
    "        \"complexity_level\": {\n",
    "            \"type\": \"integer\",\n",
    "            \"minimum\": 1,\n",
    "            \"maximum\": 5,\n",
    "            \"description\": \"Content complexity on a scale of 1-5\"\n",
    "        },\n",
    "        \"key_themes\": {\n",
    "            \"type\": \"array\",\n",
    "            \"items\": {\"type\": \"string\"},\n",
    "            \"description\": \"Main themes or topics in the content\"\n",
    "        }\n",
    "    },\n",
    "    \"required\": [\"content_type\", \"target_audience\", \"complexity_level\", \"key_themes\"]\n",
    "}\n",
    "\n",
    "content_analyzer = AgentConfig(\n",
    "    name=\"Content Analyzer\",\n",
    "    llm_config_id=\"fast_gpt\",\n",
    "    system_prompt=\"You are a content analysis expert. Analyze the provided text and categorize it according to the schema. CRITICAL: Your response MUST be a single JSON object matching the schema provided. Do not include any other text or explanations.\",\n",
    "    config_validation_schema=content_analyzer_schema\n",
    ")\n",
    "\n",
    "# Agent 2: Recommendation Generator (takes structured input, gives text output)\n",
    "recommendation_generator = AgentConfig(\n",
    "    name=\"Recommendation Generator\",\n",
    "    llm_config_id=\"creative_gpt\",\n",
    "    system_prompt=\"You are a content strategy expert. You will receive a JSON analysis of some content. Based on this analysis, provide 3-5 specific, actionable recommendations for how to improve or better utilize this content. Format your recommendations as a numbered list.\"\n",
    ")\n",
    "\n",
    "# Register both agents\n",
    "await aurite.register_agent(content_analyzer)\n",
    "await aurite.register_agent(recommendation_generator)\n",
    "\n",
    "print(\"‚úÖ Workflow agents registered!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating and Registering the Workflow\n",
    "\n",
    "Now let's create a `SimpleWorkflow` that chains these agents together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aurite import WorkflowConfig\n",
    "\n",
    "# Create a workflow that chains our two agents\n",
    "content_workflow = WorkflowConfig(\n",
    "    name=\"Content Processing Workflow\",\n",
    "    steps=[\"Content Analyzer\", \"Recommendation Generator\"],\n",
    "    description=\"Analyzes content and generates improvement recommendations\"\n",
    ")\n",
    "\n",
    "# Register the workflow\n",
    "await aurite.register_workflow(content_workflow)\n",
    "\n",
    "print(\"‚úÖ Content Processing Workflow registered!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running the Workflow\n",
    "\n",
    "Now let's test our complete workflow. Keep in mind that your initial input here is the message that you are sending to the first agent in the workflow. This agent is not aware of the second agent (unless you explain it in the system prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample content to process\n",
    "sample_content = \"\"\"\n",
    "Introducing Neural Networks: A Beginner's Guide\n",
    "\n",
    "Neural networks are computing systems inspired by biological neural networks.\n",
    "They consist of interconnected nodes (neurons) that process information through weighted connections.\n",
    "These systems excel at pattern recognition, classification, and prediction tasks.\n",
    "Modern applications include image recognition, natural language processing, and autonomous vehicles.\n",
    "While the mathematics can be complex, the core concept is intuitive:\n",
    "networks learn by adjusting connection weights based on training data.\n",
    "This tutorial series will guide you through building your first neural network using Python.\n",
    "\"\"\"\n",
    "\n",
    "# Run the workflow\n",
    "workflow_result = await aurite.run_workflow(\n",
    "    workflow_name=\"Content Processing Workflow\",\n",
    "    initial_input=f\"Please process this content: {sample_content}\"\n",
    ")\n",
    "\n",
    "print(\"üîÑ Workflow completed! Here is the final message:\")\n",
    "# The .final_message property is a convenient way to get the primary text from the last step\n",
    "print(workflow_result.final_message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Displaying Workflow Results\n",
    "\n",
    "Let's examine the output from each step of our workflow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display results from each step\n",
    "from aurite.components.agents.agent_models import AgentExecutionResult\n",
    "\n",
    "for i, step_result in enumerate(workflow_result.step_results, 1):\n",
    "    print(f\"\\nüìã Step {i}: {step_result.step_name} ({step_result.step_type})\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "    # The result of each step is a Pydantic model, which we can inspect\n",
    "    if isinstance(step_result.result, AgentExecutionResult):\n",
    "        # This was an agent step. We can display its output.\n",
    "        if step_result.step_name == \"Content Analyzer\":\n",
    "            try:\n",
    "                parsed_analysis = json.loads(step_result.result.primary_text) # Parse the JSON output\n",
    "                print(\"üìä Structured Analysis:\")\n",
    "                for key, value in parsed_analysis.items(): # Display each key-value pair\n",
    "                    print(f\"   {key}: {value}\")\n",
    "            except (json.JSONDecodeError, TypeError):\n",
    "                print(f\"Raw output: {step_result.result.primary_text}\")\n",
    "        else:\n",
    "            print(f\"üí° Recommendations:\\n{step_result.result.primary_text}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéâ Congratulations!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You've successfully completed Tutorial 5! You now know how to:\n",
    "\n",
    "### ‚úÖ What You've Learned:\n",
    "\n",
    "1. **Custom LLM Configurations**\n",
    "   - Create LLM configs with different models, temperatures, and token limits\n",
    "   - Use `llm_config_id` to assign specific LLMs to agents\n",
    "   - Tune behavior for different use cases (fast vs. creative)\n",
    "\n",
    "2. **Structured Output**\n",
    "   - Define JSON schemas using `config_validation_schema`\n",
    "   - Force agents to return data in exactly the format you need\n",
    "   - Parse and use structured data in your applications\n",
    "\n",
    "3. **Simple Workflows**\n",
    "   - Chain multiple agents together in sequence\n",
    "   - Pass output from one agent as input to the next\n",
    "   - Build complex behaviors from simple, specialized agents\n",
    "\n",
    "### üöÄ Next Steps:\n",
    "\n",
    "In the next tutorial, we'll explore:\n",
    "- **Custom Tool Servers** - Creating your own tools that agents can use\n",
    "- **Advanced Workflows** - More complex agent coordination patterns\n",
    "- **Real-world Integration** - Connecting agents to external APIs and services\n",
    "\n",
    "### üí° Key Takeaway:\n",
    "\n",
    "The power of Aurite Agents comes from **composition**‚Äîcombining simple, well-defined components (LLMs, agents, workflows) to build sophisticated AI applications. Each component has a single responsibility, making your system modular, testable, and maintainable."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "notebook-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
