{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":"Aurite Agents <p>Build, Manage, and Deploy Sophisticated AI Agents.</p> <p>Welcome to the documentation site for the Aurite Agent Framework.</p> <p>Aurite provides a comprehensive suite of tools and a flexible architecture to support the development of complex agentic applications, enabling interaction with various Language Models (LLMs) and external services through the Model Context Protocol (MCP).</p> <p>New to Aurite? Start Here!</p> <p>Get up and running in minutes by following our Quick Start Guide.</p>"},{"location":"#documentation-sections","title":"Documentation Sections","text":"<p>Navigate through the documentation using the tabs below to find what you need.</p>  Getting Started Component Configurations Usage Guides Framework Architecture <p>New to the framework? These guides will help you get started.</p> <ul> <li>Quick Start: The fastest way to get Aurite running.</li> <li>Tutorials Overview: A comprehensive learning section with concepts and assignments.</li> <li>Package README: Information specific to the pip-installable <code>aurite</code> package.</li> </ul> <p>An in-depth look at the features each component offers through JSON/YAML configuration.</p> <ul> <li>Projects and Workspaces: The foundation of your Aurite setup. Start here!</li> <li>LLM Configs: Configure language model providers.</li> <li>MCP Server Configs: Connect tools and resources.</li> <li>Agent Configs: Define agent behaviors.</li> <li>Linear Workflow Configs: Create simple, sequential workflows.</li> <li>Custom Workflow Configs: Implement complex logic in Python.</li> </ul> <p>Learn how to interact with the framework.</p> <ul> <li>CLI Reference: Guide to using the Aurite command-line interface.</li> <li>API Reference: Detailed documentation for the Python API.</li> <li>TUI Guide: Instructions for the text-based user interface.</li> </ul> <p>Dive deep into the framework's design and execution flow.</p> <ul> <li>Framework Overview: High-level architecture and design principles.</li> <li>Design Documents:<ul> <li>Aurite Engine Design</li> <li>Config Manager Design</li> <li>MCP Host Design</li> </ul> </li> <li>Execution &amp; Flow:<ul> <li>Aurite Engine Execution Flow</li> <li>Config Index Building Flow</li> <li>MCP Server Registration Flow</li> <li>Session Management Flow</li> </ul> </li> </ul>"},{"location":"0.3.28-migration-guide/","title":"Migration Guide","text":"<p>This guide will help you migrate your existing Aurite framework projects to the latest version, which introduces a new project and workspace system, along with several key renames for consistency.</p>"},{"location":"0.3.28-migration-guide/#1-new-project-structure-the-aurite-file","title":"1. New Project Structure: The <code>.aurite</code> file","text":"<p>The biggest change is the introduction of a project and workspace system. Your project now requires an <code>.aurite</code> file in its root directory to be recognized by the framework.</p> <p>Action Required:</p> <p>In the root directory of your project (the same folder that contains your <code>config</code> directory), create a new file named <code>.aurite</code> with the following content:</p> <pre><code># .aurite\n[aurite]\ntype = \"project\"\ninclude_configs = [\"config\"]\n</code></pre> <ul> <li><code>type = \"project\"</code>: Identifies this directory as an Aurite project.</li> <li><code>include_configs = [\"config\"]</code>: Tells Aurite to load all your component configurations from the <code>config/</code> directory. If you store configs in other folders, add their relative paths to this list.</li> </ul> <p>For more details on projects and workspaces, see the Projects and Workspaces documentation.</p>"},{"location":"0.3.28-migration-guide/#2-import-paths-simplification","title":"2. Import Paths Simplification","text":"<p>All major components and models can now be imported directly from the top-level <code>aurite</code> package. This simplifies imports and makes them more consistent.</p> <p>Action Required:</p> <p>Update all your imports from the Aurite framework.</p> <p>Before:</p> <pre><code>from aurite.lib.models.config.components import LLMConfig\nfrom aurite.execution.aurite_engine import Aurite\n</code></pre> <p>After:</p> <pre><code>from aurite import LLMConfig, Aurite\n</code></pre> <p>Simply change your imports to pull directly from <code>aurite</code>.</p>"},{"location":"0.3.28-migration-guide/#3-aurite-class-method-renames","title":"3. <code>Aurite</code> Class Method Renames","text":"<p>Several methods in the <code>Aurite</code> class have been renamed for clarity and consistency.</p> <p>Action Required:</p> <p>Update your code to use the new method names.</p> Old Method Name New Method Name Description <code>register_llm_config</code> <code>register_llm</code> Registers an LLM configuration. <code>register_workflow</code> <code>register_linear_workflow</code> Registers a linear workflow. <code>register_client</code> <code>register_mcp_server</code> Registers an MCP server. <code>run_workflow</code> <code>run_linear_workflow</code> Runs a linear workflow. <p>Example:</p> <p>Before:</p> <pre><code>from aurite import Aurite, LLMConfig\n\naurite = Aurite()\nmy_llm = LLMConfig(llm_id=\"my-llm\", model_name=\"gpt-4\")\naurite.register_llm_config(my_llm)\naurite.run_workflow(\"my-workflow\")\n</code></pre> <p>After:</p> <pre><code>from aurite import Aurite, LLMConfig\n\naurite = Aurite()\nmy_llm = LLMConfig(name=\"my-llm\", model=\"gpt-4\") # Note the model changes too!\naurite.register_llm(my_llm)\naurite.run_linear_workflow(\"my-workflow\")\n</code></pre>"},{"location":"0.3.28-migration-guide/#4-llmconfig-model-field-renames","title":"4. <code>LLMConfig</code> Model Field Renames","text":"<p>The fields in the <code>LLMConfig</code> model have been updated to align with the naming convention used by all other components.</p> <p>Action Required:</p> <p>Update your <code>LLMConfig</code> instantiations and any configuration files (<code>.json</code> or <code>.yaml</code>) where you define LLMs.</p> Old Field Name New Field Name Description <code>llm_id</code> <code>name</code> The unique identifier for the LLM. <code>model_name</code> <code>model</code> The specific model string (e.g., \"gpt-4o\"). <p>Example (in Python):</p> <p>Before:</p> <pre><code>from aurite import LLMConfig\n\nllm_config = LLMConfig(\n    llm_id=\"openai-gpt4\",\n    model_name=\"gpt-4-turbo\",\n    provider=\"litellm\"\n)\n</code></pre> <p>After:</p> <pre><code>from aurite import LLMConfig\n\nllm_config = LLMConfig(\n    name=\"openai-gpt4\",\n    model=\"gpt-4-turbo\",\n    provider=\"litellm\"\n)\n</code></pre> <p>Example (in <code>config/llms.json</code>):</p> <p>Before:</p> <pre><code>{\n  \"llms\": [\n    {\n      \"llm_id\": \"claude-sonnet\",\n      \"model_name\": \"claude-3-5-sonnet-20240620\",\n      \"provider\": \"litellm\"\n    }\n  ]\n}\n</code></pre> <p>After:</p> <pre><code>{\n  \"llms\": [\n    {\n      \"name\": \"claude-sonnet\",\n      \"model\": \"claude-3-5-sonnet-20240620\",\n      \"provider\": \"litellm\"\n    }\n  ]\n}\n</code></pre> <p>By following these steps, your project will be up-to-date with the latest version of the Aurite framework.</p>"},{"location":"architecture/overview/","title":"Aurite Framework Architecture Overview","text":"<p>Version: 1.0 Date: 2025-08-02</p>"},{"location":"architecture/overview/#overview","title":"Overview","text":"<p>The Aurite Framework is a comprehensive system for building and executing AI agents and workflows with distributed tool access through the Model Context Protocol (MCP). The framework provides a unified interface for orchestrating complex AI interactions while maintaining clean separation of concerns through a layered architecture centered around the <code>Aurite</code> class and its internal <code>AuriteKernel</code>.</p> <p>Key Problem Solved: Unified AI agent and workflow orchestration with distributed tool access, persistent session management, and comprehensive configuration management across complex project hierarchies.</p>"},{"location":"architecture/overview/#framework-architecture","title":"Framework Architecture","text":"<pre><code>graph TD\n    A[Aurite Framework] --&gt; B[Public API Layer]\n    A --&gt; C[Kernel Layer]\n    A --&gt; D[Execution Layer]\n    A --&gt; E[Infrastructure Layer]\n\n    B --&gt; F[Aurite Class]\n    B --&gt; G[CLI Interface]\n    B --&gt; H[REST API]\n    B --&gt; I[TUI Interface]\n\n    C --&gt; J[AuriteKernel]\n    C --&gt; K[Lazy Initialization]\n    C --&gt; L[Lifecycle Management]\n\n    D --&gt; M[AuriteEngine]\n    D --&gt; N[Agent Execution]\n    D --&gt; O[Workflow Execution]\n    D --&gt; P[Streaming Support]\n\n    E --&gt; Q[ConfigManager]\n    E --&gt; R[MCPHost]\n    E --&gt; S[SessionManager]\n    E --&gt; T[Storage Systems]\n\n    style A fill:#2196F3,stroke:#1976D2,stroke-width:2px,color:#fff\n    style B fill:#FF9800,stroke:#F57C00,stroke-width:2px,color:#fff\n    style C fill:#FF9800,stroke:#F57C00,stroke-width:2px,color:#fff\n    style D fill:#FF9800,stroke:#F57C00,stroke-width:2px,color:#fff\n    style E fill:#FF9800,stroke:#F57C00,stroke-width:2px,color:#fff\n    style F fill:#4CAF50,stroke:#388E3C,stroke-width:2px,color:#fff\n    style J fill:#4CAF50,stroke:#388E3C,stroke-width:2px,color:#fff\n    style M fill:#4CAF50,stroke:#388E3C,stroke-width:2px,color:#fff</code></pre>"},{"location":"architecture/overview/#core-framework-components","title":"Core Framework Components","text":"<p>The Aurite Framework is built around a two-tier architecture that separates public interfaces from internal implementation details while providing comprehensive AI orchestration capabilities.</p>"},{"location":"architecture/overview/#public-interface-layer","title":"Public Interface Layer","text":"Aurite ClassInterface Diversity <p>Purpose: Main framework entrypoint providing a clean, async-native API for AI agent and workflow execution.</p> <p>Key Responsibilities: - Lazy Initialization: Components initialized only when first used for optimal performance - Lifecycle Management: Automatic resource cleanup and graceful shutdown handling - Public API: Simple, intuitive methods for agent and workflow execution - Programmatic Registration: Runtime component registration for testing and notebooks - Context Management: Async context manager support for explicit resource control</p> <p>Core API Methods: <pre><code># Agent execution\nasync def run_agent(self, agent_name: str, user_message: str,\n                   system_prompt: Optional[str] = None,\n                   session_id: Optional[str] = None) -&gt; AgentRunResult\n\n# Streaming agent execution\nasync def stream_agent(self, agent_name: str, user_message: str,\n                      system_prompt: Optional[str] = None,\n                      session_id: Optional[str] = None) -&gt; AsyncGenerator[Dict[str, Any], None]\n\n# Workflow execution\nasync def run_linear_workflow(self, workflow_name: str,\n                             initial_input: Any) -&gt; LinearWorkflowExecutionResult\nasync def run_custom_workflow(self, workflow_name: str, initial_input: Any,\n                             session_id: Optional[str] = None) -&gt; Any\n\n# Component registration\nasync def register_agent(self, config: AgentConfig)\nasync def register_llm(self, config: LLMConfig)\nasync def register_mcp_server(self, config: ClientConfig)\n</code></pre></p> <p>Design Patterns: - Wrapper Pattern: Encapsulates complex async lifecycle management - Lazy Initialization: Services started only when needed - Graceful Degradation: Continues operation even with partial component failures</p> <p>CLI Interface: Command-line tools for development and operations - Component management (list, create, update, delete) - Execution commands for agents and workflows - Configuration validation and testing - Session management and cleanup</p> <p>REST API: HTTP endpoints for web applications and integrations - RESTful component CRUD operations - Execution endpoints with streaming support - Session history and management APIs - Real-time execution monitoring</p> <p>TUI Interface: Terminal-based interactive interface - Visual component browsing and management - Interactive execution with real-time feedback - Session exploration and debugging tools - Configuration editing and validation</p> <p>Python API: Direct programmatic access - Jupyter notebook integration - Testing framework support - Custom application embedding - Programmatic component registration</p>"},{"location":"architecture/overview/#kernel-layer","title":"Kernel Layer","text":"AuriteKernel <p>Purpose: Internal framework kernel managing core component lifecycle and coordination.</p> <p>Architecture Responsibilities: - Component Initialization: Manages startup sequence and dependencies - Resource Coordination: Coordinates between ConfigManager, MCPHost, and storage systems - Environment Configuration: Handles environment-based feature toggles and settings - Cleanup Management: Ensures proper resource cleanup including external library cleanup</p> <p>Component Initialization Flow: <pre><code># AuriteKernel.__init__\nself.config_manager = ConfigManager(start_dir=start_dir)\nself.project_root = self.config_manager.project_root\nself.host = MCPHost()\n\n# Conditional storage initialization\nif os.getenv(\"AURITE_ENABLE_DB\", \"false\").lower() == \"true\":\n    self._db_engine = create_db_engine()\n    self.storage_manager = StorageManager(engine=self._db_engine)\n\n# Session management setup\ncache_dir = self.project_root / \".aurite_cache\" if self.project_root else Path(\".aurite_cache\")\nself.cache_manager = CacheManager(cache_dir=cache_dir)\n\n# Observability integration\nif os.getenv(\"LANGFUSE_ENABLED\", \"false\").lower() == \"true\":\n    self.langfuse = Langfuse(...)\n\n# Central execution engine\nself.execution = AuriteEngine(\n    config_manager=self.config_manager,\n    host_instance=self.host,\n    storage_manager=self.storage_manager,\n    cache_manager=self.cache_manager,\n    langfuse=self.langfuse,\n)\n</code></pre></p> <p>Async Lifecycle Management: <pre><code>async def initialize(self):\n    # Database initialization\n    if self.storage_manager:\n        self.storage_manager.init_db()\n\n    # MCP Host startup\n    if self.host:\n        await self.host.__aenter__()\n\nasync def shutdown(self):\n    # External library cleanup (litellm)\n    # MCP Host cleanup\n    # Database connection cleanup\n    # Resource disposal\n</code></pre></p> <p>Key Design Decisions: - Environment-Driven Configuration: Features enabled through environment variables - Graceful Degradation: Optional components (DB, Langfuse) don't prevent startup - Project-Aware Caching: Cache directory based on detected project structure - Comprehensive Cleanup: Handles cleanup of external libraries and resources</p>"},{"location":"architecture/overview/#execution-layer","title":"Execution Layer","text":"AuriteEngine Integration <p>Purpose: Central execution orchestrator coordinating all framework components for unified AI operations.</p> <p>Integration Architecture: <pre><code>graph TD\n    A[AuriteEngine] --&gt; B[ConfigManager Integration]\n    A --&gt; C[MCPHost Integration]\n    A --&gt; D[SessionManager Integration]\n    A --&gt; E[Component Execution]\n\n    B --&gt; F[Component Resolution]\n    B --&gt; G[Configuration Validation]\n    B --&gt; H[Path Resolution]\n\n    C --&gt; I[JIT Server Registration]\n    C --&gt; J[Tool Execution]\n    C --&gt; K[Resource Access]\n\n    D --&gt; L[History Management]\n    D --&gt; M[Result Persistence]\n    D --&gt; N[Session Lifecycle]\n\n    E --&gt; O[Agent Orchestration]\n    E --&gt; P[Workflow Coordination]\n    E --&gt; Q[Streaming Management]\n\n    style A fill:#2196F3,stroke:#1976D2,stroke-width:2px,color:#fff\n    style B fill:#4CAF50,stroke:#388E3C,stroke-width:2px,color:#fff\n    style C fill:#4CAF50,stroke:#388E3C,stroke-width:2px,color:#fff\n    style D fill:#4CAF50,stroke:#388E3C,stroke-width:2px,color:#fff\n    style E fill:#4CAF50,stroke:#388E3C,stroke-width:2px,color:#fff</code></pre></p> <p>Orchestration Capabilities: - Unified Execution Interface: Single API for agents, linear workflows, and custom workflows - JIT Resource Provisioning: Dynamic MCP server registration based on component requirements - Session Coordination: Automatic session management with history persistence - Streaming Support: Real-time event streaming for interactive applications - Error Handling: Comprehensive error management with context preservation</p> <p>\ud83d\udccb Detailed Architecture: See AuriteEngine Design for complete design patterns and integration details.</p>"},{"location":"architecture/overview/#infrastructure-layer","title":"Infrastructure Layer","text":"Configuration ManagementDistributed Tool ManagementSession &amp; Storage Management <p>ConfigManager: Hierarchical configuration discovery and management system.</p> <p>Key Capabilities: - Project/Workspace Discovery: Automatic detection of project boundaries and hierarchies - Priority-Based Resolution: Context-aware configuration with proper precedence handling - Component Indexing: Comprehensive indexing of agents, LLMs, MCP servers, and workflows - CRUD Operations: Full component lifecycle management with validation - Path Resolution: Context-aware path resolution for relative configurations</p> <p>Integration Points: - AuriteEngine: Primary configuration provider for all component resolution - API Endpoints: Configuration management through REST API - CLI Tools: Command-line configuration management and validation</p> <p>\ud83d\udccb Detailed Architecture: See ConfigManager Design for complete configuration patterns and indexing flows.</p> <p>MCPHost: Model Context Protocol server management and tool orchestration.</p> <p>Key Capabilities: - Multi-Transport Support: STDIO, local command, and HTTP stream transports - JIT Registration: Dynamic server registration based on agent requirements - Component Discovery: Automatic tool, prompt, and resource discovery - Security &amp; Filtering: Comprehensive access control and filtering systems - Session Management: Robust session lifecycle with proper cleanup</p> <p>Integration Points: - AuriteEngine: Tool execution and resource access during agent/workflow execution - Agent Components: Direct tool access through unified interface - Configuration System: Server configuration resolution and validation</p> <p>\ud83d\udccb Detailed Architecture: See MCP Host Design for complete server management and security patterns.</p> <p>SessionManager + CacheManager: Persistent conversation and execution result management.</p> <p>Key Capabilities: - Two-Tier Storage: High-level session operations with low-level file management - Metadata Tracking: Comprehensive session metadata with validation - Relationship Management: Parent-child relationships for workflow sessions - Retention Policies: Automatic cleanup with age and count-based policies - Partial ID Matching: Flexible session retrieval with ambiguity resolution</p> <p>Storage Options: - File-Based (CacheManager): JSON files with in-memory caching for development - Database (StorageManager): PostgreSQL/SQLite for production environments</p> <p>\ud83d\udccb Detailed Architecture: See Session Management Flow for complete session lifecycle and storage patterns.</p>"},{"location":"architecture/overview/#framework-integration-patterns","title":"Framework Integration Patterns","text":""},{"location":"architecture/overview/#lazy-initialization-pattern","title":"Lazy Initialization Pattern","text":"<p>The framework implements comprehensive lazy initialization to optimize startup performance and resource usage:</p> <pre><code># Aurite class initialization\ndef __init__(self, start_dir: Optional[Path] = None, disable_logging: bool = False):\n    # Only create kernel, don't initialize services\n    self.kernel = AuriteKernel(start_dir=start_dir, disable_logging=disable_logging)\n    self._initialized = False\n\nasync def _ensure_initialized(self):\n    # Services initialized only on first use\n    if not self._initialized:\n        await self.kernel.initialize()\n        self._initialized = True\n</code></pre> <p>Benefits:</p> <ul> <li>Fast Startup: Framework ready immediately without waiting for service initialization</li> <li>Resource Efficiency: Only needed services are started</li> <li>Error Isolation: Initialization failures don't prevent framework instantiation</li> <li>Development Friendly: Quick iteration cycles during development</li> </ul>"},{"location":"architecture/overview/#component-coordination-pattern","title":"Component Coordination Pattern","text":"<p>The framework coordinates between multiple specialized components through the AuriteEngine:</p> <pre><code># Component coordination in AuriteEngine\nasync def run_agent(self, agent_name: str, user_message: str, ...):\n    # 1. Configuration resolution through ConfigManager\n    agent_config = self._config_manager.get_config(\"agent\", agent_name)\n\n    # 2. JIT server registration through MCPHost\n    for server_name in agent_config.mcp_servers:\n        if server_name not in self._host.registered_server_names:\n            await self._host.register_client(server_config)\n\n    # 3. Session management through SessionManager\n    if session_id and self._session_manager:\n        history = self._session_manager.get_session_history(session_id)\n\n    # 4. Agent execution with coordinated resources\n    agent_instance = Agent(config, llm_config, host, initial_messages)\n    result = await agent_instance.run_conversation()\n\n    # 5. Result persistence\n    self._session_manager.save_agent_result(session_id, result)\n</code></pre>"},{"location":"architecture/overview/#environment-driven-configuration","title":"Environment-Driven Configuration","text":"<p>The framework uses environment variables to enable optional features and integrations:</p> <pre><code># Optional database integration\nif os.getenv(\"AURITE_ENABLE_DB\", \"false\").lower() == \"true\":\n    self._db_engine = create_db_engine()\n    self.storage_manager = StorageManager(engine=self._db_engine)\n\n# Optional observability integration\nif os.getenv(\"LANGFUSE_ENABLED\", \"false\").lower() == \"true\":\n    self.langfuse = Langfuse(\n        secret_key=os.getenv(\"LANGFUSE_SECRET_KEY\"),\n        public_key=os.getenv(\"LANGFUSE_PUBLIC_KEY\"),\n        host=os.getenv(\"LANGFUSE_HOST\"),\n    )\n\n# Development vs production configuration\nAURITE_CONFIG_FORCE_REFRESH = os.getenv(\"AURITE_CONFIG_FORCE_REFRESH\", \"true\")\n</code></pre> <p>Configuration Variables:</p> <ul> <li><code>AURITE_ENABLE_DB</code>: Enable database storage backend</li> <li><code>LANGFUSE_ENABLED</code>: Enable Langfuse observability integration</li> <li><code>AURITE_CONFIG_FORCE_REFRESH</code>: Force configuration refresh on every operation</li> <li><code>LANGFUSE_USER_ID</code>: User ID for trace grouping</li> <li>Database connection variables for StorageManager</li> </ul>"},{"location":"architecture/overview/#framework-execution-flows","title":"Framework Execution Flows","text":""},{"location":"architecture/overview/#agent-execution-flow","title":"Agent Execution Flow","text":"<pre><code>sequenceDiagram\n    participant User\n    participant Aurite\n    participant Kernel\n    participant Engine\n    participant Config\n    participant Host\n    participant Session\n\n    User-&gt;&gt;Aurite: run_agent(name, message)\n    Aurite-&gt;&gt;Aurite: _ensure_initialized()\n    Aurite-&gt;&gt;Kernel: initialize() [if needed]\n    Aurite-&gt;&gt;Engine: run_agent(name, message)\n    Engine-&gt;&gt;Config: get_config(\"agent\", name)\n    Config--&gt;&gt;Engine: agent_config\n    Engine-&gt;&gt;Host: register_servers(mcp_servers)\n    Host--&gt;&gt;Engine: servers_registered\n    Engine-&gt;&gt;Session: get_session_history(session_id)\n    Session--&gt;&gt;Engine: conversation_history\n    Engine-&gt;&gt;Engine: execute_agent()\n    Engine-&gt;&gt;Session: save_agent_result(result)\n    Engine--&gt;&gt;Aurite: AgentRunResult\n    Aurite--&gt;&gt;User: result</code></pre>"},{"location":"architecture/overview/#workflow-execution-flow","title":"Workflow Execution Flow","text":"<pre><code>sequenceDiagram\n    participant User\n    participant Aurite\n    participant Engine\n    participant Workflow\n    participant Agent\n\n    User-&gt;&gt;Aurite: run_linear_workflow(name, input)\n    Aurite-&gt;&gt;Engine: run_linear_workflow(name, input)\n    Engine-&gt;&gt;Engine: create_workflow_executor()\n    Engine-&gt;&gt;Workflow: execute(input, session_id)\n\n    loop For each step\n        Workflow-&gt;&gt;Engine: run_agent(step_name, step_input)\n        Engine-&gt;&gt;Agent: execute_with_tools()\n        Agent--&gt;&gt;Engine: step_result\n        Engine--&gt;&gt;Workflow: step_result\n    end\n\n    Workflow--&gt;&gt;Engine: workflow_result\n    Engine-&gt;&gt;Engine: save_workflow_result()\n    Engine--&gt;&gt;Aurite: LinearWorkflowExecutionResult\n    Aurite--&gt;&gt;User: result</code></pre>"},{"location":"architecture/overview/#framework-extension-points","title":"Framework Extension Points","text":""},{"location":"architecture/overview/#programmatic-component-registration","title":"Programmatic Component Registration","text":"<p>The framework supports runtime component registration for testing and dynamic scenarios:</p> <pre><code># Register components programmatically\nawait aurite.register_agent(AgentConfig(\n    name=\"dynamic_agent\",\n    llm_config_id=\"gpt4\",\n    system_prompt=\"Dynamic agent for testing\"\n))\n\nawait aurite.register_mcp_server(ClientConfig(\n    name=\"test_server\",\n    server_path=\"./test_server.py\"\n))\n</code></pre>"},{"location":"architecture/overview/#custom-workflow-integration","title":"Custom Workflow Integration","text":"<p>Custom workflows can leverage the full framework through the execution engine:</p> <pre><code>class CustomWorkflow:\n    async def execute(self, initial_input: Any, executor: AuriteEngine, session_id: str):\n        # Access full framework capabilities\n        agent_result = await executor.run_agent(\"analyzer\", initial_input)\n        processed_data = self.process_result(agent_result)\n        final_result = await executor.run_agent(\"summarizer\", processed_data)\n        return final_result\n</code></pre>"},{"location":"architecture/overview/#interface-extensions","title":"Interface Extensions","text":"<p>The framework supports multiple interface types through consistent internal APIs:</p> <ul> <li>CLI Extensions: New commands through the CLI router</li> <li>API Extensions: Additional REST endpoints through FastAPI routers</li> <li>TUI Extensions: New screens and components through the TUI framework</li> <li>Custom Interfaces: Direct integration through the Aurite class API</li> </ul>"},{"location":"architecture/overview/#performance-scalability","title":"Performance &amp; Scalability","text":""},{"location":"architecture/overview/#optimization-strategies","title":"Optimization Strategies","text":"<p>Lazy Initialization: Components initialized only when needed JIT Resource Management: MCP servers registered dynamically based on requirements In-Memory Caching: Configuration and session data cached for fast access Connection Pooling: Reuse of LLM and database connections where possible Streaming Support: Real-time event streaming for interactive applications</p>"},{"location":"architecture/overview/#scalability-considerations","title":"Scalability Considerations","text":"<p>Horizontal Scaling: Multiple framework instances can share database storage Resource Isolation: Each framework instance manages its own MCP server connections Session Distribution: Sessions can be distributed across instances through shared storage Configuration Sharing: Shared configuration repositories across development teams</p>"},{"location":"architecture/overview/#references","title":"References","text":"<ul> <li>Core Implementation: <code>src/aurite/aurite.py</code> - Main Aurite class and AuriteKernel</li> <li>Execution Orchestration: AuriteEngine Design - Central execution coordination</li> <li>Configuration Management: ConfigManager Design - Hierarchical configuration system</li> <li>Tool Management: MCP Host Design - Distributed tool orchestration</li> <li>Session Management: Session Management Flow - Persistent conversation management</li> <li>Execution Flows: AuriteEngine Execution Flow - Detailed execution patterns</li> </ul>"},{"location":"architecture/design/aurite_engine_design/","title":"AuriteEngine Design","text":"<p>Version: 1.0 Date: 2025-08-02</p>"},{"location":"architecture/design/aurite_engine_design/#overview","title":"Overview","text":"<p>The AuriteEngine is the central execution orchestrator in the Aurite framework, providing a unified interface for executing agents, linear workflows, and custom workflows. It coordinates between the ConfigManager, MCPHost, and SessionManager to handle component resolution, resource management, and execution lifecycle while providing both synchronous and streaming execution modes.</p> <p>Key Problem Solved: Unified execution orchestration with Just-in-Time resource provisioning, session management integration, and comprehensive error handling across all component types.</p>"},{"location":"architecture/design/aurite_engine_design/#architecture","title":"Architecture","text":"<pre><code>graph TD\n    A[AuriteEngine] --&gt; B[Component Resolution]\n    A --&gt; C[Resource Management]\n    A --&gt; D[Session Integration]\n    A --&gt; E[Execution Orchestration]\n\n    B --&gt; F[ConfigManager]\n    C --&gt; G[MCPHost]\n    D --&gt; H[SessionManager]\n\n    F --&gt; I[Agent Configs]\n    F --&gt; J[LLM Configs]\n    F --&gt; K[Workflow Configs]\n\n    G --&gt; L[JIT Server Registration]\n    G --&gt; M[Tool Execution]\n\n    H --&gt; N[History Management]\n    H --&gt; O[Result Persistence]\n\n    E --&gt; P[Agent Execution]\n    E --&gt; Q[Linear Workflows]\n    E --&gt; R[Custom Workflows]\n    E --&gt; S[Streaming Support]\n\n    style A fill:#2196F3,stroke:#1976D2,stroke-width:2px,color:#fff\n    style B fill:#FF9800,stroke:#F57C00,stroke-width:2px,color:#fff\n    style C fill:#FF9800,stroke:#F57C00,stroke-width:2px,color:#fff\n    style D fill:#FF9800,stroke:#F57C00,stroke-width:2px,color:#fff\n    style E fill:#FF9800,stroke:#F57C00,stroke-width:2px,color:#fff\n    style F fill:#4CAF50,stroke:#388E3C,stroke-width:2px,color:#fff\n    style G fill:#4CAF50,stroke:#388E3C,stroke-width:2px,color:#fff\n    style H fill:#4CAF50,stroke:#388E3C,stroke-width:2px,color:#fff</code></pre>"},{"location":"architecture/design/aurite_engine_design/#core-responsibilities","title":"Core Responsibilities","text":"<p>Primary Functions</p> <ul> <li>Component Resolution: Retrieves and validates component configurations from ConfigManager with fallback handling</li> <li>JIT Resource Management: Dynamically registers MCP servers based on agent requirements through MCPHost integration</li> <li>Session Orchestration: Manages conversation history and result persistence through SessionManager integration</li> <li>Execution Lifecycle: Coordinates component initialization, execution, and cleanup across all component types</li> <li>Streaming Support: Provides real-time event streaming with state management and error handling</li> <li>Observability Integration: Langfuse tracing and monitoring for execution analytics</li> <li>Error Management: Comprehensive error handling with context preservation and graceful degradation</li> </ul> <p>What This Component Does NOT Do</p> <ul> <li>Does not manage configuration discovery or indexing (that's the ConfigManager's responsibility)</li> <li>Does not handle MCP server connections or tool routing (that's the MCPHost's job)</li> <li>Does not implement session storage backends (that's the SessionManager's role)</li> <li>Does not execute LLM calls directly (delegates to Agent and Workflow components)</li> </ul>"},{"location":"architecture/design/aurite_engine_design/#key-design-patterns","title":"Key Design Patterns","text":"JIT MCP Server RegistrationSession Management IntegrationComponent Execution OrchestrationStreaming ArchitectureLangfuse Integration <p>Purpose: Dynamic server registration based on agent requirements to optimize resource usage and startup time.</p> <p>Registration Flow: <pre><code># During agent preparation\nif agent_config_for_run.mcp_servers:\n    for server_name in agent_config_for_run.mcp_servers:\n        if server_name not in self._host.registered_server_names:\n            server_config_dict = self._config_manager.get_config(\"mcp_server\", server_name)\n            if not server_config_dict:\n                raise ConfigurationError(f\"MCP Server '{server_name}' required by agent '{agent_name}' not found.\")\n            server_config = ClientConfig(**server_config_dict)\n            await self._host.register_client(server_config)\n            dynamically_registered_servers.append(server_name)\n</code></pre></p> <p>Key Design Decisions: - Persistent Registration: Servers remain active after execution for subsequent use - Lazy Loading: Servers only loaded when required by specific agents - Early Validation: Configuration errors caught before execution begins - Graceful Failure: Missing server configurations result in clear error messages</p> <p>\ud83d\udccb Server Registration Details: See MCP Server Registration Flow for complete registration process and error handling patterns.</p> <p>Purpose: Unified session handling across all execution types with automatic ID generation and history management.</p> <p>Session ID Management: <pre><code># Auto-generation for agents with history enabled\nif effective_include_history:\n    if final_session_id:\n        if not final_session_id.startswith(\"agent-\") and not final_session_id.startswith(\"workflow-\"):\n            final_session_id = f\"agent-{final_session_id}\"\n    else:\n        final_session_id = f\"agent-{uuid.uuid4().hex[:8]}\"\n        logger.info(f\"Auto-generated session_id for agent '{agent_name}': {final_session_id}\")\n</code></pre></p> <p>History Integration: - Immediate Updates: Current user message added to history before execution - Result Persistence: Complete execution results saved with session metadata - Backend Abstraction: Works with both CacheManager and StorageManager backends - Workflow Support: Base session ID tracking for workflow step coordination</p> <p>Session Lifecycle: 1. Pre-execution: Load existing history if <code>include_history=true</code> 2. During execution: Add current user message to session 3. Post-execution: Save complete conversation and execution results 4. Cleanup: Session metadata updated with execution statistics</p> <p>Agent Execution Pattern: <pre><code>async def run_agent(self, agent_name: str, user_message: str, ...):\n    # 1. Component Resolution\n    agent_instance, servers_to_unregister = await self._prepare_agent_for_run(...)\n\n    # 2. Execution\n    run_result = await agent_instance.run_conversation()\n\n    # 3. Result Processing\n    run_result.agent_name = agent_name\n    if session_id and self._session_manager:\n        self._session_manager.save_agent_result(session_id, run_result, base_session_id)\n\n    return run_result\n</code></pre></p> <p>Workflow Execution Pattern: <pre><code>async def run_linear_workflow(self, workflow_name: str, initial_input: Any, ...):\n    # 1. Configuration Resolution\n    workflow_config = WorkflowConfig(**workflow_config_dict)\n\n    # 2. Session Management\n    final_session_id = self._manage_workflow_session_id(session_id, workflow_config)\n\n    # 3. Execution Delegation\n    workflow_executor = LinearWorkflowExecutor(config=workflow_config, engine=self)\n    result = await workflow_executor.execute(initial_input, final_session_id, base_session_id)\n\n    # 4. Result Persistence\n    if result.session_id and self._session_manager:\n        self._session_manager.save_workflow_result(result.session_id, result, base_session_id)\n\n    return result\n</code></pre></p> <p>Key Orchestration Features: - Unified Interface: Same execution pattern across all component types - Error Context: Execution errors wrapped with component and operation context - Resource Cleanup: Proper cleanup even on execution failure - Result Standardization: Consistent result format with metadata injection</p> <p>Purpose: Real-time event streaming with state management and error handling for interactive agent execution.</p> <p>Event Flow Management: <pre><code>async def stream_agent_run(self, agent_name: str, user_message: str, ...):\n    # Yield session info as first event\n    if session_id:\n        yield {\"type\": \"session_info\", \"data\": {\"session_id\": session_id}}\n\n    # Stream agent events\n    async for event in agent_instance.stream_conversation():\n        yield event\n</code></pre></p> <p>State Management: - Session Tracking: Session ID provided as first event for client tracking - History Updates: Conversation history updated in real-time during streaming - Error Handling: Errors converted to stream events with graceful termination - Resource Cleanup: Proper cleanup in finally blocks regardless of stream outcome</p> <p>Integration Features: - Langfuse Tracing: Streaming executions tracked with observability metadata - Auto Session Generation: Automatic session ID creation for agents with history enabled - Event Translation: Internal agent events translated to standardized API events</p> <p>Purpose: Comprehensive observability and tracing for execution analytics and debugging.</p> <p>Trace Creation: <pre><code>if self.langfuse:\n    trace = self.langfuse.trace(\n        name=f\"Agent: {agent_name} - Aurite Runtime\",\n        session_id=session_id,\n        user_id=session_id or \"anonymous\",\n        input={\"user_message\": user_message, \"system_prompt\": system_prompt},\n        metadata={\"agent_name\": agent_name, \"source\": \"execution-engine\"}\n    )\n    agent_instance.trace = trace\n</code></pre></p> <p>Observability Features: - Execution Tracing: Complete execution traces with input/output capture - Session Grouping: Traces grouped by session ID for conversation analysis - Metadata Enrichment: Agent names, execution context, and source tracking - Performance Monitoring: Execution timing and resource usage tracking - Error Tracking: Exception capture with full context preservation</p> <p>Integration Points: - Agent Integration: Traces passed to agent instances for LLM call tracking - Workflow Support: Workflow executions traced with step-level granularity - Streaming Support: Streaming executions tracked with real-time updates</p>"},{"location":"architecture/design/aurite_engine_design/#error-handling-strategy","title":"Error Handling Strategy","text":""},{"location":"architecture/design/aurite_engine_design/#configuration-errors","title":"Configuration Errors","text":"<ul> <li>Early Detection: Configuration validation during preparation phase</li> <li>Clear Messaging: Specific error messages indicating missing or invalid components</li> <li>Graceful Degradation: Fallback to default configurations where appropriate</li> <li>Context Preservation: Full error context maintained through exception chaining</li> </ul>"},{"location":"architecture/design/aurite_engine_design/#execution-errors","title":"Execution Errors","text":"<ul> <li>Component Context: Errors wrapped with information about which component failed</li> <li>Resource Cleanup: Proper cleanup of registered servers and sessions on failure</li> <li>State Consistency: Session state maintained even on execution failure</li> <li>Error Propagation: Original errors preserved in exception chains</li> </ul>"},{"location":"architecture/design/aurite_engine_design/#streaming-errors","title":"Streaming Errors","text":"<ul> <li>Event Conversion: Errors converted to stream events for client handling</li> <li>Stream Termination: Clean stream termination with proper resource cleanup</li> <li>Client Recovery: Error events include information for client reconnection</li> <li>State Preservation: Session state saved even on streaming failure</li> </ul>"},{"location":"architecture/design/aurite_engine_design/#integration-points","title":"Integration Points","text":"<p>Integration with ConfigManager</p> <p>The AuriteEngine serves as the primary consumer of the ConfigManager's configuration services:</p> <p>Component Resolution: Engine calls <code>get_config()</code> to retrieve component configurations with automatic path resolution and validation. The ConfigManager handles all hierarchical priority resolution and context-aware path computation.</p> <p>Configuration Updates: Engine updates ConfigManager reference when in-memory components are registered, ensuring consistent configuration state across execution cycles.</p> <p>Validation Integration: Engine relies on ConfigManager's validation system for component integrity, with all configurations validated against Pydantic models before execution.</p> <p>Integration with MCPHost</p> <p>The AuriteEngine coordinates with the MCPHost for dynamic tool and resource provisioning:</p> <p>JIT Registration: Engine triggers server registration based on agent requirements, calling MCPHost to register servers that aren't already active. This ensures optimal resource usage by only loading servers when needed.</p> <p>Tool Execution: During agent execution, the engine provides the MCPHost instance to agents for tool execution. The MCPHost handles all tool routing, session management, and security filtering transparently.</p> <p>Resource Management: Engine leverages MCPHost's component discovery and filtering capabilities, ensuring agents only have access to authorized tools and resources based on their configuration.</p> <p>Integration with SessionManager</p> <p>The AuriteEngine integrates with the SessionManager for comprehensive conversation and result management:</p> <p>History Management: Engine loads conversation history before execution and saves complete results after execution. The SessionManager handles all backend abstraction and storage optimization.</p> <p>Session Lifecycle: Engine manages session ID generation, prefixing, and metadata tracking. The SessionManager provides the storage and retrieval interface for session data.</p> <p>Result Persistence: Engine saves both conversation history and execution results through the SessionManager, enabling comprehensive session analytics and debugging capabilities.</p>"},{"location":"architecture/design/aurite_engine_design/#references","title":"References","text":"<ul> <li>Implementation: <code>src/aurite/execution/aurite_engine.py</code></li> <li>Flow Details: AuriteEngine Execution Flow</li> <li>Configuration Integration: ConfigManager Design</li> <li>Resource Management: MCP Host Design</li> </ul>"},{"location":"architecture/design/config_manager_design/","title":"ConfigManager Design","text":"<p>Version: 1.0 Date: 2025-08-02</p>"},{"location":"architecture/design/config_manager_design/#overview","title":"Overview","text":"<p>The ConfigManager is the central component responsible for discovering, loading, and managing all configuration data in the Aurite framework. It implements a hierarchical configuration system that respects project and workspace boundaries while providing a unified interface for accessing component configurations (agents, LLMs, MCP servers, workflows).</p> <p>Key Problem Solved: Configuration management across complex project structures with automatic discovery, priority-based resolution, and unified CRUD operations.</p>"},{"location":"architecture/design/config_manager_design/#architecture","title":"Architecture","text":"<pre><code>graph TD\n    A[ConfigManager] --&gt; B[Context Discovery]\n    A --&gt; C[Source Initialization]\n    A --&gt; D[Component Indexing]\n    A --&gt; E[FileManager]\n\n    B --&gt; F[find_anchor_files]\n    C --&gt; G[Priority-ordered Sources]\n    D --&gt; H[Component Index]\n    E --&gt; I[CRUD Operations]\n\n    G --&gt; J[Project Configs]\n    G --&gt; K[Workspace Configs]\n    G --&gt; L[User Global Configs]\n\n    style A fill:#2196F3,stroke:#1976D2,stroke-width:2px,color:#fff\n    style B fill:#FF9800,stroke:#F57C00,stroke-width:2px,color:#fff\n    style C fill:#FF9800,stroke:#F57C00,stroke-width:2px,color:#fff\n    style D fill:#FF9800,stroke:#F57C00,stroke-width:2px,color:#fff\n    style E fill:#FF9800,stroke:#F57C00,stroke-width:2px,color:#fff\n    style G fill:#4CAF50,stroke:#388E3C,stroke-width:2px,color:#fff\n    style H fill:#4CAF50,stroke:#388E3C,stroke-width:2px,color:#fff\n    style I fill:#4CAF50,stroke:#388E3C,stroke-width:2px,color:#fff\n    style J fill:#607D8B,stroke:#455A64,stroke-width:2px,color:#fff\n    style K fill:#607D8B,stroke:#455A64,stroke-width:2px,color:#fff\n    style L fill:#607D8B,stroke:#455A64,stroke-width:2px,color:#fff</code></pre>"},{"location":"architecture/design/config_manager_design/#core-responsibilities","title":"Core Responsibilities","text":"<p>Primary Functions</p> <ul> <li>Configuration Discovery: Automatically finds and parses <code>.aurite</code> files to understand project/workspace structure</li> <li>Hierarchical Indexing: Builds priority-ordered index of components respecting context boundaries</li> <li>Component CRUD: Provides create, read, update, delete operations for all component types</li> <li>Path Resolution: Resolves relative paths in configurations based on their context</li> <li>Validation: Validates component configurations against Pydantic models</li> <li>LLM Validation Tracking: Tracks successful LLM validations with timestamps for reliability monitoring</li> <li>Project Management: Full CRUD operations for projects within workspaces</li> <li>In-Memory Registration: Supports programmatic component registration for testing and notebooks</li> </ul> <p>What This Component Does NOT Do</p> <ul> <li>Does not execute or run components (that's the AuriteEngine's job)</li> <li>Does not manage MCP server connections (that's the MCPHost's responsibility)</li> <li>Does not handle component lifecycle or state management</li> </ul>"},{"location":"architecture/design/config_manager_design/#key-classes-interfaces","title":"Key Classes &amp; Interfaces","text":""},{"location":"architecture/design/config_manager_design/#configmanager-class","title":"ConfigManager Class","text":"<p>Central facade for all configuration operations with hierarchical context discovery and unified interface for component access, validation, and manipulation.</p> <p>Core Interface Groups:</p> <ul> <li>Configuration Operations: Component retrieval, listing, and CRUD operations with automatic path resolution</li> <li>Validation System: Component validation against Pydantic models with detailed error reporting</li> <li>Project Management: Full project lifecycle management within workspace contexts</li> <li>LLM Validation Tracking: Reliability monitoring with timestamp-based validation tracking</li> <li>In-Memory Registration: Programmatic component registration for testing and notebook environments</li> </ul>"},{"location":"architecture/design/config_manager_design/#supporting-components","title":"Supporting Components","text":"<p><code>find_anchor_files</code> Function: Hierarchical <code>.aurite</code> file discovery with proper context establishment and complex project/workspace boundary detection.</p> <p><code>FileManager</code> Class: Low-level file operations with atomic transaction support and multi-format configuration file handling (JSON/YAML).</p> <p>Configuration Models: Pydantic-based validation models for all component types with automatic transport type inference and specialized path field handling.</p> <p>\ud83d\udccb Implementation Details: See Configuration Index Building Flow for detailed method signatures, usage examples, and implementation specifics.</p>"},{"location":"architecture/design/config_manager_design/#configuration-dependencies","title":"Configuration &amp; Dependencies","text":""},{"location":"architecture/design/config_manager_design/#configuration","title":"Configuration","text":"<pre><code># Environment configuration\nAURITE_CONFIG_FORCE_REFRESH = \"true\"  # Forces refresh on every operation\n\n# .aurite file structure\n[aurite]\ntype = \"project\"  # or \"workspace\"\ninclude_configs = [\"config\", \"shared_config\"]\nprojects = [\"project1\", \"project2\"]  # workspace only\ndescription = \"Project description\"\n</code></pre>"},{"location":"architecture/design/config_manager_design/#priority-resolution-system","title":"Priority Resolution System","text":"<p>The ConfigManager implements a sophisticated priority system where the first-found component wins conflicts:</p> <pre><code># Priority order (highest to lowest)\n1. In-Memory (programmatic registrations) - HIGHEST PRIORITY\n2. Current Project (if in project context)\n3. Workspace (shared configurations)\n4. Other Projects (in workspace order)\n5. User Global (~/.aurite) - LOWEST PRIORITY\n</code></pre> <p>In-Memory Priority</p> <p>In-memory registrations have the highest priority to support testing and notebook environments where components need to override file-based configurations temporarily.</p>"},{"location":"architecture/design/config_manager_design/#key-design-patterns","title":"Key Design Patterns","text":"Three-Phase Index BuildingComponent Index StructureLLM Validation SystemPath Resolution SystemForce Refresh Mechanism <p>Process Overview: The ConfigManager builds its configuration index through three distinct phases for reliable discovery and proper priority resolution.</p> <p>Phase 1: Context Discovery - Find all <code>.aurite</code> files by searching upward from start directory - Parse TOML content to determine context types (project/workspace) - Establish configuration hierarchy with proper priority ordering - Build context relationships and boundaries</p> <p>Phase 2: Source Initialization - Extract <code>include_configs</code> paths from each <code>.aurite</code> file in priority order - Resolve paths relative to their <code>.aurite</code> file locations - Convert relative paths to absolute paths for consistent access - Build ordered source list respecting priority hierarchy</p> <p>Phase 3: Component Indexing - Scan configuration directories for JSON/YAML files - Parse files as arrays of component configurations - Apply first-found-wins conflict resolution - Add metadata fields for traceability and path resolution</p> <p>\ud83d\udccb Detailed Flow: See Configuration Index Building Flow for complete implementation details and examples.</p> <p>Data Structure: Three-level nested dictionary: <code>{component_type: {component_name: {config_data}}}</code></p> <p>Component Metadata: Each indexed component includes metadata fields for traceability and path resolution: - <code>_source_file</code>: Full path to the configuration file - <code>_context_path</code>: Root directory of the context (project/workspace) - <code>_context_level</code>: \"project\", \"workspace\", \"user\", or \"programmatic\" - <code>_project_name</code>: Name of the project (if applicable) - <code>_workspace_name</code>: Name of the workspace (if applicable)</p> <p>Conflict Resolution: When the same component name exists in multiple locations, the first occurrence wins based on the priority order.</p> <p>Example Conflict Resolution: If \"Weather Agent\" exists in:</p> <ol> <li><code>project_bravo/config/agents/agents.json</code> (when running from project_bravo)</li> <li><code>my_workspace/config/agents/shared_agents.json</code></li> <li><code>project_alpha/config/agents/agents.json</code></li> </ol> <p>The version from <code>project_bravo</code> will be used because it has the highest priority.</p> <p>Access Patterns: The ConfigManager provides multiple access methods: - Single Component: Direct component retrieval with path resolution - By Type: All components of a specific type with metadata - Full Index: Complete nested dictionary structure - Flattened View: Linear list of all components across types</p> <p>Index Refresh: The index can be rebuilt on-demand or automatically based on force refresh settings.</p> <p>Purpose: Tracks successful LLM operations with timestamp-based validation for reliability monitoring.</p> <p>Key Features: - Automatic validation timestamp recording after successful LLM operations - Validation status included in component configurations - Automatic reset when LLM configurations are updated - Persistence across ConfigManager refresh operations</p> <p>Integration Points: - Runtime Integration: AuriteEngine integration for automatic validation tracking - Configuration Updates: Timestamps reset when configurations change - Reliability Monitoring: Validation status available in component metadata - Development Support: Clear indication of tested vs untested LLM configurations</p> <p>Usage Pattern: <pre><code># After successful LLM operation\nconfig_manager.validate_llm(\"gpt4\")\n\n# Validation status automatically included\nllm_config = config_manager.get_config(\"llm\", \"gpt4\")\nis_validated = llm_config.get(\"validated_at\") is not None\n</code></pre></p> <p>Purpose: Context-aware path resolution for component configurations based on their configuration context.</p> <p>Resolution Strategy: - MCP Servers: Resolves <code>server_path</code> relative to component's context directory - Custom Workflows: Handles both dot-notation module paths and direct file paths - LLM Components: Injects validation timestamps during resolution - Lazy Resolution: Paths resolved only when configurations are retrieved</p> <p>Context Awareness: - Paths resolved relative to the configuration file's location - Different component types have specialized resolution logic - Fallback handling for missing or invalid paths - Type-specific resolution for different component categories</p> <p>Performance Optimization: - Resolution occurs only during configuration retrieval - Cached resolution results for repeated access - Efficient path computation with minimal filesystem operations</p> <p>Purpose: Development-time control over when the configuration index is rebuilt for optimal performance.</p> <p>Configuration: <pre><code># Development: Force refresh on every operation (default)\nexport AURITE_CONFIG_FORCE_REFRESH=true\n\n# Production: Disable for performance\nexport AURITE_CONFIG_FORCE_REFRESH=false\n</code></pre></p> <p>Behavior: - Enabled: Rebuilds entire configuration index on every operation - Disabled: Uses cached index until explicit refresh is called - Development: Useful for seeing configuration changes immediately - Production: Should be disabled for optimal performance</p> <p>Performance Impact</p> <p>Force refresh rebuilds the entire configuration index on every operation. Useful for development but should be disabled in production for optimal performance.</p> <p>Use Cases: - Development: Immediate reflection of configuration file changes - Testing: Ensure tests see latest configuration state - Production: Optimized performance with cached index - Debugging: Force refresh to troubleshoot configuration issues</p>"},{"location":"architecture/design/config_manager_design/#integration-points","title":"Integration Points","text":"<p>Integration with AuriteEngine</p> <p>The ConfigManager serves as the primary configuration provider for the AuriteEngine:</p> <p>Component Resolution: Engine calls <code>get_config()</code> to retrieve component configurations for agents, LLMs, MCP servers, and workflows. The ConfigManager handles all path resolution and validation automatically.</p> <p>JIT Registration: Engine uses ConfigManager to get MCP server configurations for dynamic registration. When an agent requires specific MCP servers, the engine queries the ConfigManager to retrieve their configurations and passes them to the MCP Host for registration.</p> <p>Validation: Engine relies on ConfigManager's validation system for component integrity. All configurations are validated against Pydantic models before being used, ensuring type safety and completeness.</p> <p>Priority Resolution: The hierarchical priority system ensures that project-specific configurations override workspace and global settings, allowing for proper development isolation and shared resource management.</p>"},{"location":"architecture/design/config_manager_design/#references","title":"References","text":"<ul> <li>Implementation: <code>src/aurite/lib/config/config_manager.py</code></li> <li>Flow Details: Configuration Index Building Flow</li> </ul>"},{"location":"architecture/design/mcp_host_design/","title":"MCP Host Design","text":"<p>Version: 1.0 Date: 2025-08-02</p>"},{"location":"architecture/design/mcp_host_design/#overview","title":"Overview","text":"<p>The MCP Host is a core execution layer component that provides a secure, unified interface for accessing distributed tools, prompts, and resources from external MCP (Model Context Protocol) servers. It solves the problem of distributed tool and resource management through Just-in-Time (JIT) server registration, unified component access, and comprehensive security filtering.</p> <p>Key Problem Solved: Distributed tool and resource management with dynamic server registration, unified component access, and comprehensive security filtering.</p>"},{"location":"architecture/design/mcp_host_design/#architecture","title":"Architecture","text":"<pre><code>graph TD\n    A[MCPHost] --&gt; B[Foundation Layer]\n    A --&gt; C[Resource Layer]\n    A --&gt; D[Session Management]\n\n    B --&gt; E[SecurityManager]\n    B --&gt; F[MessageRouter]\n    B --&gt; G[RootManager]\n    B --&gt; H[FilteringManager]\n\n    C --&gt; I[ToolManager]\n    C --&gt; J[PromptManager]\n    C --&gt; K[ResourceManager]\n\n    D --&gt; L[ClientSessions]\n    D --&gt; M[AsyncExitStack]\n    D --&gt; N[Component Discovery]\n\n    style A fill:#2196F3,stroke:#1976D2,stroke-width:2px,color:#fff\n    style B fill:#FF9800,stroke:#F57C00,stroke-width:2px,color:#fff\n    style C fill:#FF9800,stroke:#F57C00,stroke-width:2px,color:#fff\n    style D fill:#FF9800,stroke:#F57C00,stroke-width:2px,color:#fff\n    style E fill:#4CAF50,stroke:#388E3C,stroke-width:2px,color:#fff\n    style F fill:#4CAF50,stroke:#388E3C,stroke-width:2px,color:#fff\n    style G fill:#4CAF50,stroke:#388E3C,stroke-width:2px,color:#fff\n    style H fill:#4CAF50,stroke:#388E3C,stroke-width:2px,color:#fff\n    style I fill:#607D8B,stroke:#455A64,stroke-width:2px,color:#fff\n    style J fill:#607D8B,stroke:#455A64,stroke-width:2px,color:#fff\n    style K fill:#607D8B,stroke:#455A64,stroke-width:2px,color:#fff\n    style L fill:#9C27B0,stroke:#7B1FA2,stroke-width:2px,color:#fff\n    style M fill:#9C27B0,stroke:#7B1FA2,stroke-width:2px,color:#fff\n    style N fill:#9C27B0,stroke:#7B1FA2,stroke-width:2px,color:#fff</code></pre>"},{"location":"architecture/design/mcp_host_design/#core-responsibilities","title":"Core Responsibilities","text":"<p>Primary Functions</p> <ul> <li>Session Management: Manages MCP client session lifecycles with proper resource cleanup</li> <li>Just-in-Time Registration: Dynamically registers servers based on agent requirements</li> <li>Component Discovery: Automatically discovers and indexes tools, prompts, and resources</li> <li>Security &amp; Filtering: Enforces access control based on agent configurations and global rules</li> <li>Unified Interface: Provides consistent API for tool execution and component access</li> <li>Transport Abstraction: Supports multiple transport types (stdio, local, http_stream)</li> <li>Error Handling: Comprehensive timeout and error management with graceful degradation</li> </ul> <p>What This Component Does NOT Do</p> <ul> <li>Does not manage component configurations (that's the ConfigManager's job)</li> <li>Does not execute agents or workflows (that's the AuriteEngine's responsibility)</li> <li>Does not handle LLM communications directly</li> </ul>"},{"location":"architecture/design/mcp_host_design/#key-components","title":"Key Components","text":""},{"location":"architecture/design/mcp_host_design/#foundation-layer","title":"Foundation Layer","text":"SecurityManagerMessageRouterRootManagerFilteringManager <p>Purpose: Manages encryption keys and credential resolution from multiple sources</p> <p>Key Features: - Environment variable substitution with placeholder resolution - GCP Secret Manager integration for secure credential storage - Encrypted storage support for sensitive configuration data - Multi-source credential resolution with fallback mechanisms</p> <p>Integration: Used during Phase 1 (Configuration Resolution) to resolve encrypted credentials and environment variables in server configurations.</p> <p>Purpose: Maintains component-to-session mappings for efficient request routing</p> <p>Key Features: - Component-to-session mapping registry for fast lookup - Efficient routing during tool execution with O(1) lookup time - Session lifecycle tracking for proper cleanup - Support for dynamic component registration and unregistration</p> <p>Integration: Updated during Phase 5 (Component Registration) and used during tool execution for session routing.</p> <p>Purpose: Enforces hierarchical access control for MCP resources</p> <p>Key Features: - URI pattern-based access control validation - Hierarchical resource permission checking - Resource access policy enforcement - Integration with agent-specific access rules</p> <p>Integration: Used during Phase 4 (Component Discovery) to validate resource access permissions before registration.</p> <p>Purpose: Applies filtering rules to ensure proper access control</p> <p>Key Features: - Global filtering rules from ClientConfig - Agent-specific filtering rules from AgentConfig - Component-level access control enforcement - Dynamic filtering rule application</p> <p>Integration: Applied throughout the registration process and during component access to enforce security policies.</p>"},{"location":"architecture/design/mcp_host_design/#resource-layer","title":"Resource Layer","text":"ToolManagerPromptManagerResourceManager <p>Purpose: Manages tool discovery, registration, and execution</p> <p>Key Features: - Tool discovery and metadata extraction from MCP servers - Server prefix application for unique tool naming - Timeout handling and execution management - LLM-compatible tool formatting for agent consumption</p> <p>Integration: Handles tool registration during Phase 4 and provides tool execution interface for agents.</p> <p>Purpose: Stores and manages discovered prompt definitions</p> <p>Key Features: - Prompt template storage and lifecycle management - Parameter substitution support for dynamic prompts - Server prefix application for unique prompt naming - Filtering and access control integration</p> <p>Integration: Manages prompt registration during Phase 4 and provides prompt access interface for agents.</p> <p>Purpose: Manages resource discovery with access control validation</p> <p>Key Features: - Resource discovery and metadata extraction - URI-based access control validation through RootManager - Resource lifecycle management and cleanup - Integration with agent-specific resource permissions</p> <p>Integration: Handles resource registration during Phase 4 with proper access control validation.</p>"},{"location":"architecture/design/mcp_host_design/#core-concepts","title":"Core Concepts","text":"Registration TriggersTransport TypesComponent Discovery <p>Static Registration: Servers registered during MCPHost initialization</p> <ul> <li>Occurs during system startup or explicit initialization</li> <li>Pre-loads commonly used servers for immediate availability</li> <li>Reduces latency for frequently accessed tools and resources</li> <li>Suitable for core infrastructure servers</li> </ul> <p>Just-in-Time (JIT) Registration: Servers registered dynamically when needed by agents</p> <ul> <li>Triggered by agent execution requirements</li> <li>Optimizes resource usage by loading only needed servers</li> <li>Enables dynamic scaling based on actual usage patterns</li> <li>Supports agent-specific server configurations</li> </ul> <p>STDIO Transport: Local Python subprocess communication via stdin/stdout</p> <ul> <li>Best for: Local Python-based MCP servers</li> <li>Communication: Direct subprocess stdin/stdout streams</li> <li>Performance: Low latency, high throughput</li> <li>Use cases: File system tools, local data processing, development servers</li> </ul> <p>Local Command Transport: Execute local commands with environment variable substitution</p> <ul> <li>Best for: Non-Python local executables (Node.js, Go, Rust, etc.)</li> <li>Communication: Command execution with argument passing</li> <li>Performance: Medium latency, good throughput</li> <li>Use cases: System utilities, compiled tools, cross-language integration</li> </ul> <p>HTTP Stream Transport: Remote server communication via HTTP streaming protocols</p> <ul> <li>Best for: Remote MCP servers, cloud services, distributed systems</li> <li>Communication: HTTP with Server-Sent Events (SSE) for streaming</li> <li>Performance: Higher latency, network-dependent throughput</li> <li>Use cases: Cloud APIs, remote databases, distributed microservices</li> </ul> <p>After successful registration, the system automatically discovers and indexes:</p> <p>Tools: Executable functions with timeout and metadata support</p> <ul> <li>Discovered via <code>session.list_tools()</code> MCP protocol call</li> <li>Prefixed with server name to prevent naming conflicts</li> <li>Enhanced with timeout metadata for execution management</li> <li>Formatted for LLM consumption with proper schemas</li> </ul> <p>Prompts: Reusable prompt templates with parameter substitution</p> <ul> <li>Discovered via <code>session.list_prompts()</code> MCP protocol call</li> <li>Support dynamic parameter substitution for flexible usage</li> <li>Managed with lifecycle tracking and filtering</li> <li>Integrated with agent-specific access controls</li> </ul> <p>Resources: File and data resources with URI-based access control</p> <ul> <li>Discovered via <code>session.list_resources()</code> MCP protocol call</li> <li>Validated through RootManager for hierarchical access control</li> <li>Support various URI schemes (file://, http://, custom protocols)</li> <li>Integrated with agent-specific resource permissions</li> </ul>"},{"location":"architecture/design/mcp_host_design/#server-registration-process","title":"Server Registration Process","text":"<p>The MCP Host uses a comprehensive five-phase registration process to establish connections with external MCP servers and discover their capabilities. This process ensures reliable server registration, proper component discovery, and robust error handling.</p> <p>Registration Phases Overview:</p> <ol> <li>Configuration Resolution: Retrieve and validate server configuration with credential resolution</li> <li>Transport Establishment: Establish appropriate transport connection based on server configuration</li> <li>MCP Session Initialization: Create MCP client session and perform protocol handshake</li> <li>Component Discovery: Query MCP server for available tools, prompts, and resources</li> <li>Component Registration: Register discovered components with internal registries and update routing tables</li> </ol> <p>Each phase must complete successfully before proceeding to the next phase, ensuring reliable server registration and proper error handling.</p> <p>\ud83d\udccb Detailed Registration Process: See MCP Server Registration Flow for complete implementation details, phase-by-phase breakdowns, code examples, and error handling patterns.</p>"},{"location":"architecture/design/mcp_host_design/#key-design-patterns","title":"Key Design Patterns","text":""},{"location":"architecture/design/mcp_host_design/#session-lifecycle-management","title":"Session Lifecycle Management","text":"<p>The MCPHost uses AsyncExitStack for robust session lifecycle management with guaranteed cleanup on failure. Sessions are stored with their exit stacks for proper resource management.</p>"},{"location":"architecture/design/mcp_host_design/#component-registration","title":"Component Registration","text":"<p>Registration creates multiple data structures:</p> <ul> <li>Component storage (by type): <code>{tools: {name: Tool}, prompts: {name: Prompt}, resources: {name: Resource}}</code></li> <li>Session routing (for execution): <code>{tool_to_session: {name: ClientSession}}</code></li> <li>MessageRouter mappings for fast lookup during tool execution</li> </ul>"},{"location":"architecture/design/mcp_host_design/#unregistration-process","title":"Unregistration Process","text":"<p>Dynamic server unregistration removes all components from the server and cleans up all associated resources through the stored AsyncExitStack.</p>"},{"location":"architecture/design/mcp_host_design/#error-handling","title":"Error Handling","text":"<p>The MCP Host implements comprehensive error handling patterns following the framework's standardized patterns:</p> <ul> <li>Timeout Errors: Registration timeouts, tool execution timeouts, and session initialization timeouts</li> <li>Connection Errors: Transport establishment failures, network connectivity issues, and server startup failures</li> <li>Configuration Errors: Invalid transport configurations, missing required fields, and credential resolution failures</li> <li>Resource Cleanup Errors: Session cleanup failures and AsyncExitStack management</li> </ul>"},{"location":"architecture/design/mcp_host_design/#configuration-integration","title":"Configuration Integration","text":"<p>The MCP Host consumes server configurations provided by the ConfigManager. All configuration examples, validation patterns, and integration scenarios are documented in the ConfigManager flow documentation.</p>"},{"location":"architecture/design/mcp_host_design/#integration-points","title":"Integration Points","text":"<p>Integration with AuriteEngine</p> <p>The MCP Host serves as the primary tool and resource provider for the AuriteEngine, enabling dynamic agent capabilities:</p> <p>Just-in-Time Registration: The AuriteEngine triggers server registration based on agent requirements. When an agent is executed, the engine analyzes the agent's <code>mcp_servers</code> configuration and calls the MCP Host to register any servers that aren't already active. This ensures optimal resource usage by only loading servers when needed.</p> <p>Tool Execution: During agent execution, the AuriteEngine calls the MCP Host to execute tools with proper session routing. The MCP Host's MessageRouter provides O(1) lookup to route tool calls to the correct MCP server session, handling timeout management and error recovery transparently.</p> <p>Resource Access: Agents can access MCP resources (files, databases, APIs) through the MCP Host's unified interface. The RootManager enforces hierarchical access control, ensuring agents can only access resources they're authorized to use based on their configuration.</p> <p>Component Discovery: The MCP Host automatically discovers and indexes all available tools, prompts, and resources from registered servers, making them available to the AuriteEngine for agent execution. Components are prefixed with server names to prevent conflicts and preserve original names for display purposes.</p> <p>Security &amp; Filtering: The FilteringManager applies both global and agent-specific filtering rules, ensuring that agents only have access to the tools and resources appropriate for their role and security context.</p>"},{"location":"architecture/design/mcp_host_design/#references","title":"References","text":"<ul> <li>Implementation: <code>src/aurite/execution/mcp_host.py</code></li> <li>Flow Details: MCP Server Registration Flow</li> </ul>"},{"location":"architecture/flow/aurite_engine_execution_flow/","title":"AuriteEngine Execution Flow","text":"<p>This document explains the execution flows used by the AuriteEngine to orchestrate agents, workflows, and streaming operations across the Aurite framework.</p>"},{"location":"architecture/flow/aurite_engine_execution_flow/#overview","title":"Overview","text":"<p>The AuriteEngine implements distinct execution flows for different component types while maintaining consistent patterns for session management, resource provisioning, and error handling. Each flow coordinates between the ConfigManager, MCPHost, and SessionManager to provide unified execution orchestration.</p>"},{"location":"architecture/flow/aurite_engine_execution_flow/#core-execution-flows","title":"Core Execution Flows","text":"<p>The AuriteEngine supports four primary execution patterns, each optimized for specific use cases while sharing common orchestration principles.</p> Agent Execution FlowLinear Workflow Execution FlowCustom Workflow Execution FlowStreaming Execution Flow <p>Objective: Execute individual agents with JIT server registration, session management, and comprehensive error handling.</p> <pre><code>flowchart TD\n    A[Agent Execution Request] --&gt; B[Configuration Resolution]\n    B --&gt; C[Session ID Management]\n    C --&gt; D[Agent Preparation]\n    D --&gt; E[JIT Server Registration]\n    E --&gt; F[History Loading]\n    F --&gt; G[Agent Execution]\n    G --&gt; H[Result Processing]\n    H --&gt; I[Session Persistence]\n    I --&gt; J[Cleanup &amp; Return]\n\n    style A fill:#2196F3,stroke:#1976D2,stroke-width:2px,color:#fff\n    style J fill:#4CAF50,stroke:#388E3C,stroke-width:2px,color:#fff\n    style D fill:#FF9800,stroke:#F57C00,stroke-width:2px,color:#fff\n    style E fill:#FF9800,stroke:#F57C00,stroke-width:2px,color:#fff\n    style G fill:#9C27B0,stroke:#7B1FA2,stroke-width:2px,color:#fff</code></pre> <p>Phase 1: Configuration Resolution <pre><code># Retrieve agent configuration from ConfigManager\nagent_config_dict = self._config_manager.get_config(\"agent\", agent_name)\nif not agent_config_dict:\n    raise ConfigurationError(f\"Agent configuration '{agent_name}' not found.\")\n\nagent_config_for_run = AgentConfig(**agent_config_dict)\n</code></pre></p> <p>Phase 2: Session ID Management <pre><code># Auto-generate session ID if agent has history enabled\neffective_include_history = (\n    force_include_history if force_include_history is not None\n    else agent_config.include_history\n)\n\nif effective_include_history:\n    if not final_session_id:\n        final_session_id = f\"agent-{uuid.uuid4().hex[:8]}\"\n        logger.info(f\"Auto-generated session_id for agent '{agent_name}': {final_session_id}\")\n</code></pre></p> <p>Phase 3: JIT Server Registration <pre><code># Register required MCP servers dynamically\nif agent_config_for_run.mcp_servers:\n    for server_name in agent_config_for_run.mcp_servers:\n        if server_name not in self._host.registered_server_names:\n            server_config_dict = self._config_manager.get_config(\"mcp_server\", server_name)\n            server_config = ClientConfig(**server_config_dict)\n            await self._host.register_client(server_config)\n            dynamically_registered_servers.append(server_name)\n</code></pre></p> <p>Phase 4: History Loading &amp; Agent Creation <pre><code># Load conversation history if enabled\ninitial_messages = []\nif effective_include_history and session_id and self._session_manager:\n    history = self._session_manager.get_session_history(session_id)\n    if history:\n        initial_messages.extend(history)\n\n# Add current user message and create agent\ncurrent_user_message = {\"role\": \"user\", \"content\": user_message}\ninitial_messages.append(current_user_message)\n\nagent_instance = Agent(\n    agent_config=agent_config_for_run,\n    base_llm_config=base_llm_config,\n    host_instance=self._host,\n    initial_messages=initial_messages,\n    session_id=session_id,\n)\n</code></pre></p> <p>Phase 5: Execution &amp; Result Processing <pre><code># Execute agent conversation\nrun_result = await agent_instance.run_conversation()\nrun_result.agent_name = agent_name\n\n# Save complete execution result\nif agent_instance.config.include_history and final_session_id and self._session_manager:\n    self._session_manager.save_agent_result(\n        session_id=final_session_id,\n        agent_result=run_result,\n        base_session_id=final_base_session_id\n    )\n</code></pre></p> <p>Objective: Execute sequential workflow steps with coordinated session management and step-level error handling.</p> <pre><code>flowchart TD\n    A[Workflow Execution Request] --&gt; B[Workflow Configuration]\n    B --&gt; C[Session Management]\n    C --&gt; D[Workflow Executor Creation]\n    D --&gt; E[Step-by-Step Execution]\n    E --&gt; F[Result Aggregation]\n    F --&gt; G[Session Persistence]\n    G --&gt; H[Cleanup &amp; Return]\n\n    style A fill:#2196F3,stroke:#1976D2,stroke-width:2px,color:#fff\n    style H fill:#4CAF50,stroke:#388E3C,stroke-width:2px,color:#fff\n    style E fill:#9C27B0,stroke:#7B1FA2,stroke-width:2px,color:#fff\n    style F fill:#FF9800,stroke:#F57C00,stroke-width:2px,color:#fff</code></pre> <p>Phase 1: Configuration &amp; Session Setup <pre><code># Resolve workflow configuration\nworkflow_config_dict = self._config_manager.get_config(\"linear_workflow\", workflow_name)\nworkflow_config = WorkflowConfig(**workflow_config_dict)\n\n# Manage workflow session ID with prefix\nfinal_session_id = session_id\nbase_session_id = session_id\nif workflow_config.include_history:\n    if final_session_id:\n        if not final_session_id.startswith(\"workflow-\"):\n            final_session_id = f\"workflow-{final_session_id}\"\n    else:\n        final_session_id = f\"workflow-{uuid.uuid4().hex[:8]}\"\n        base_session_id = final_session_id\n</code></pre></p> <p>Phase 2: Workflow Execution Delegation <pre><code># Create workflow executor with engine reference\nworkflow_executor = LinearWorkflowExecutor(\n    config=workflow_config,\n    engine=self,  # Engine passed for step execution\n)\n\n# Execute workflow with session coordination\nresult = await workflow_executor.execute(\n    initial_input=initial_input,\n    session_id=final_session_id,\n    base_session_id=base_session_id\n)\n</code></pre></p> <p>Phase 3: Result Persistence <pre><code># Save complete workflow execution result\nif result.session_id and self._session_manager:\n    self._session_manager.save_workflow_result(\n        session_id=result.session_id,\n        workflow_result=result,\n        base_session_id=base_session_id\n    )\n</code></pre></p> <p>Step Execution Pattern: Each workflow step is executed through the AuriteEngine, enabling: - Recursive Orchestration: Steps can be agents, workflows, or custom components - Session Coordination: Base session ID maintained across all steps - Error Isolation: Step failures don't prevent result persistence - Resource Sharing: JIT-registered servers available to all steps</p> <p>Objective: Execute Python-based custom workflows with dynamic component resolution and flexible execution patterns.</p> <pre><code>flowchart TD\n    A[Custom Workflow Request] --&gt; B[Configuration Resolution]\n    B --&gt; C[Module Loading]\n    C --&gt; D[Executor Creation]\n    D --&gt; E[Dynamic Execution]\n    E --&gt; F[Result Processing]\n    F --&gt; G[Cleanup &amp; Return]\n\n    style A fill:#2196F3,stroke:#1976D2,stroke-width:2px,color:#fff\n    style G fill:#4CAF50,stroke:#388E3C,stroke-width:2px,color:#fff\n    style E fill:#9C27B0,stroke:#7B1FA2,stroke-width:2px,color:#fff\n    style C fill:#FF9800,stroke:#F57C00,stroke-width:2px,color:#fff</code></pre> <p>Phase 1: Configuration &amp; Module Resolution <pre><code># Resolve custom workflow configuration\nworkflow_config_dict = self._config_manager.get_config(\"custom_workflow\", workflow_name)\nworkflow_config = CustomWorkflowConfig(**workflow_config_dict)\n\n# Create executor with dynamic module loading\nworkflow_executor = CustomWorkflowExecutor(config=workflow_config)\n</code></pre></p> <p>Phase 2: Dynamic Execution <pre><code># Execute with engine reference for component access\nresult = await workflow_executor.execute(\n    initial_input=initial_input,\n    executor=self,  # Engine passed for dynamic component execution\n    session_id=session_id\n)\n</code></pre></p> <p>Key Features: - Dynamic Component Access: Custom workflows can execute agents and other workflows through the engine - Flexible Session Management: Session handling delegated to custom workflow implementation - Type Safety: Input/output type validation through workflow executor - Error Propagation: Custom workflow errors wrapped with execution context</p> <p>Objective: Provide real-time event streaming for interactive agent execution with comprehensive state management.</p> <pre><code>flowchart TD\n    A[Streaming Request] --&gt; B[Agent Preparation]\n    B --&gt; C[Session Info Event]\n    C --&gt; D[Event Stream Loop]\n    D --&gt; E[State Management]\n    E --&gt; F[History Persistence]\n    F --&gt; G[Resource Cleanup]\n\n    style A fill:#2196F3,stroke:#1976D2,stroke-width:2px,color:#fff\n    style G fill:#4CAF50,stroke:#388E3C,stroke-width:2px,color:#fff\n    style D fill:#9C27B0,stroke:#7B1FA2,stroke-width:2px,color:#fff\n    style E fill:#FF9800,stroke:#F57C00,stroke-width:2px,color:#fff</code></pre> <p>Phase 1: Streaming Setup <pre><code># Auto-generate session ID for agents with history\nif not session_id:\n    agent_config_dict = self._config_manager.get_config(\"agent\", agent_name)\n    if agent_config_dict:\n        agent_config = AgentConfig(**agent_config_dict)\n        if agent_config.include_history:\n            session_id = f\"agent-{uuid.uuid4().hex[:8]}\"\n\n# Prepare agent with same flow as synchronous execution\nagent_instance, servers_to_unregister = await self._prepare_agent_for_run(\n    agent_name, user_message, system_prompt, session_id\n)\n</code></pre></p> <p>Phase 2: Event Streaming <pre><code># Yield session info as first event\nif session_id:\n    yield {\"type\": \"session_info\", \"data\": {\"session_id\": session_id}}\n\n# Stream agent conversation events\nasync for event in agent_instance.stream_conversation():\n    yield event\n</code></pre></p> <p>Phase 3: State Management &amp; Cleanup <pre><code># Save conversation history in finally block\nif agent_instance and agent_instance.config.include_history and session_id and self._session_manager:\n    self._session_manager.save_conversation_history(\n        session_id=session_id,\n        conversation=agent_instance.conversation_history,\n        agent_name=agent_name,\n    )\n\n# Keep dynamically registered servers active for future use\nif servers_to_unregister:\n    logger.debug(f\"Keeping {len(servers_to_unregister)} dynamically registered servers active\")\n</code></pre></p> <p>Error Handling in Streaming: <pre><code>try:\n    # Streaming execution\n    async for event in agent_instance.stream_conversation():\n        yield event\nexcept Exception as e:\n    error_msg = f\"Error during streaming execution for Agent '{agent_name}': {type(e).__name__}: {str(e)}\"\n    yield {\"type\": \"error\", \"data\": {\"message\": error_msg}}\n    raise AgentExecutionError(error_msg) from e\n</code></pre></p>"},{"location":"architecture/flow/aurite_engine_execution_flow/#jit-registration-integration","title":"JIT Registration Integration","text":""},{"location":"architecture/flow/aurite_engine_execution_flow/#registration-trigger-points","title":"Registration Trigger Points","text":"<ul> <li>Agent Execution: Servers registered during <code>_prepare_agent_for_run</code></li> <li>Workflow Steps: Each step triggers its own JIT registration through recursive engine calls</li> <li>Streaming Execution: Same registration flow as synchronous agent execution</li> </ul>"},{"location":"architecture/flow/aurite_engine_execution_flow/#server-lifecycle-management","title":"Server Lifecycle Management","text":"<p>Registration Strategy:</p> <ul> <li>On-Demand: Servers registered only when required by specific components</li> <li>Persistent: Registered servers remain active for subsequent executions</li> <li>Shared: Multiple agents can use the same registered servers</li> </ul>"},{"location":"architecture/flow/aurite_engine_execution_flow/#references","title":"References","text":"<ul> <li>Implementation: <code>src/aurite/execution/aurite_engine.py</code> - Main AuriteEngine implementation</li> <li>Design Details: AuriteEngine Design - Architecture and design patterns</li> <li>Configuration Integration: Configuration Index Building Flow - ConfigManager integration</li> <li>Resource Management: MCP Server Registration Flow - MCPHost integration</li> </ul>"},{"location":"architecture/flow/config_index_building_flow/","title":"Configuration Index Building Flow","text":"<p>This document explains how the Aurite Framework builds its configuration index by discovering and processing <code>.aurite</code> files throughout the project hierarchy.</p>"},{"location":"architecture/flow/config_index_building_flow/#overview","title":"Overview","text":"<p>The configuration system uses a three-phase process to build a comprehensive index of all available components (agents, LLMs, MCP servers, workflows). The system respects a priority hierarchy where the current context (project or workspace) takes precedence.</p>"},{"location":"architecture/flow/config_index_building_flow/#core-concepts","title":"Core Concepts","text":""},{"location":"architecture/flow/config_index_building_flow/#priority-principle","title":"Priority Principle","text":"<p>Priority order from highest to lowest:</p> <ol> <li>In-Memory Registrations (programmatic components for testing/notebooks)</li> <li>Current Context (project if in project, workspace if in workspace)</li> <li>Shared Configurations (workspace-level shared configs)</li> <li>Other Projects (other projects in workspace, in order)</li> <li>User Global (~/.aurite directory)</li> </ol>"},{"location":"architecture/flow/config_index_building_flow/#file-structure-example","title":"File Structure Example","text":"<pre><code>my_workspace/\n\u251c\u2500\u2500 .aurite\n|   # type=\"workspace\"\n\u2502   # projects: [\"project_alpha\", \"project_bravo\"]\n\u2502   # include_configs: [\"config\"]\n\u2502\n\u251c\u2500\u2500 config/\n\u2502   \u251c\u2500\u2500 agents/\n\u2502   \u2502   \u2514\u2500\u2500 shared_agents.json\n\u2502   \u251c\u2500\u2500 mcp_servers/\n\u2502   \u2502   \u2514\u2500\u2500 shared_servers.json\n\u2502   \u2514\u2500\u2500 llms/\n\u2502       \u2514\u2500\u2500 company_llms.json\n\u2502\n\u251c\u2500\u2500 project_alpha/\n\u2502   \u251c\u2500\u2500 .aurite\n|   |   # type=\"project\"\n\u2502   \u2502   # include_configs: [\"config\", \"shared_config\"]\n\u2502   \u251c\u2500\u2500 config/\n\u2502   \u2502   \u251c\u2500\u2500 agents/\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 alpha_agents.json\n\u2502   \u2502   \u2514\u2500\u2500 workflows/\n\u2502   \u2502       \u2514\u2500\u2500 alpha_workflows.json\n\u2502   \u2514\u2500\u2500 shared_config/\n\u2502       \u2514\u2500\u2500 alpha_shared.json\n\u2502\n\u2514\u2500\u2500 project_bravo/\n    \u251c\u2500\u2500 .aurite\n    |   # type=\"project\"\n    \u2502   # include_configs: [\"config\"]\n    \u2514\u2500\u2500 config/\n        \u251c\u2500\u2500 agents/\n        \u2502   \u2514\u2500\u2500 bravo_agents.json\n        \u2514\u2500\u2500 mcp_servers/\n            \u2514\u2500\u2500 bravo_servers.json\n</code></pre>"},{"location":"architecture/flow/config_index_building_flow/#three-phase-index-building-process","title":"Three-Phase Index Building Process","text":"<p>The ConfigManager builds its index through three distinct phases, each with specific responsibilities and outcomes. This ensures reliable configuration discovery and proper priority resolution.</p> Phase 1: Context DiscoveryPhase 2: Source DiscoveryPhase 3: Component Indexing <p>Objective: Find all <code>.aurite</code> files and establish the configuration hierarchy with proper priority ordering.</p> <pre><code>flowchart TD\n    A[ConfigManager.__init__] --&gt; B[find_anchor_files]\n    B --&gt; C{.aurite found?}\n    C --&gt;|Yes| D[Parse TOML content]\n    C --&gt;|No| E[Move up directory]\n    E --&gt; C\n    D --&gt; F{Determine type}\n    F --&gt;|workspace| G[Add to workspace context]\n    F --&gt;|project| H[Add to project context]\n    G --&gt; I[Build context hierarchy]\n    H --&gt; I\n    I --&gt; J[Context discovery complete]\n\n    style A fill:#2196F3,stroke:#1976D2,stroke-width:2px,color:#fff\n    style J fill:#4CAF50,stroke:#388E3C,stroke-width:2px,color:#fff\n    style F fill:#FF9800,stroke:#F57C00,stroke-width:2px,color:#fff\n    style C fill:#9C27B0,stroke:#7B1FA2,stroke-width:2px,color:#fff\n    style G fill:#607D8B,stroke:#455A64,stroke-width:2px,color:#fff\n    style H fill:#607D8B,stroke:#455A64,stroke-width:2px,color:#fff</code></pre> <p>Key Steps:</p> <p>1. Search for .aurite files: <pre><code>def find_anchor_files(start_path: Path) -&gt; List[Path]:\n    anchor_files = []\n    current_path = start_path.resolve()\n\n    while True:\n        anchor_file = current_path / \".aurite\"\n        if anchor_file.is_file():\n            anchor_files.append(anchor_file)\n\n        if current_path.parent == current_path:  # Filesystem root\n            break\n        current_path = current_path.parent\n\n    return anchor_files  # Ordered from closest to furthest\n</code></pre></p> <p>2. Parse and categorize: <pre><code># Parse each .aurite file to determine context type\nfor anchor_path in anchor_files:\n    with open(anchor_path, \"rb\") as f:\n        settings = tomllib.load(f).get(\"aurite\", {})\n\n    context_type = settings.get(\"type\")\n    if context_type == \"project\":\n        self.project_root = anchor_path.parent\n    elif context_type == \"workspace\":\n        self.workspace_root = anchor_path.parent\n</code></pre></p> <p>3. Build priority hierarchy:</p> <p>When in PROJECT context: <pre><code>1. In-Memory Registrations (highest priority)\n2. Current Project\n3. Workspace (shared configs)\n4. Other Projects (in workspace order)\n5. User Global (~/.aurite)\n</code></pre></p> <p>When in WORKSPACE context: <pre><code>1. In-Memory Registrations (highest priority)\n2. Workspace\n3. All Projects (in workspace order)\n4. User Global (~/.aurite)\n</code></pre></p> <p>In-Memory Registration Priority</p> <p>In-memory registrations always have the highest priority regardless of context. This supports:</p> <ul> <li>Testing Environments: Override configurations for unit tests</li> <li>Jupyter Notebooks: Programmatic component registration for experimentation</li> <li>Development Workflows: Temporary configuration overrides without file modifications</li> </ul> <p>Example Results:</p> <p>Running from project_bravo/: <pre><code>Context Order:\nproject_bravo \u2192 /path/to/my_workspace/project_bravo\nmy_workspace \u2192 /path/to/my_workspace\nproject_alpha \u2192 /path/to/my_workspace/project_alpha\n</code></pre></p> <p>Running from my_workspace/: <pre><code>Context Order:\nmy_workspace \u2192 /path/to/my_workspace\nproject_alpha \u2192 /path/to/my_workspace/project_alpha\nproject_bravo \u2192 /path/to/my_workspace/project_bravo\n</code></pre></p> <p>Objective: Extract <code>include_configs</code> paths from each <code>.aurite</code> file in priority order and build the ordered source list.</p> <pre><code>flowchart TD\n    A[_initialize_sources] --&gt; B[For each context in priority order]\n    B --&gt; C[Read .aurite include_configs list]\n    C --&gt; D[Resolve paths relative to .aurite location]\n    D --&gt; E[Convert relative paths to absolute]\n    E --&gt; F{More contexts?}\n    F --&gt;|Yes| B\n    F --&gt;|No| G[Build ordered source list]\n    G --&gt; H[Source discovery complete]\n\n    style A fill:#2196F3,stroke:#1976D2,stroke-width:2px,color:#fff\n    style H fill:#4CAF50,stroke:#388E3C,stroke-width:2px,color:#fff\n    style F fill:#9C27B0,stroke:#7B1FA2,stroke-width:2px,color:#fff\n    style G fill:#FF9800,stroke:#F57C00,stroke-width:2px,color:#fff\n    style C fill:#607D8B,stroke:#455A64,stroke-width:2px,color:#fff\n    style D fill:#607D8B,stroke:#455A64,stroke-width:2px,color:#fff\n    style E fill:#607D8B,stroke:#455A64,stroke-width:2px,color:#fff</code></pre> <p>Key Activities: - Extract <code>include_configs</code> paths from each <code>.aurite</code> file in priority order - Resolve paths relative to their <code>.aurite</code> file locations - Convert relative paths to absolute paths for consistent access - Build ordered source list respecting priority hierarchy</p> <p>Example Configuration Sources (from project_bravo): <pre><code>1. /path/to/my_workspace/project_bravo/config        (current project - highest)\n2. /path/to/my_workspace/config                      (workspace shared)\n3. /path/to/my_workspace/project_alpha/config        (other project)\n4. /path/to/my_workspace/project_alpha/shared_config (other project)\n5. ~/.aurite                                         (user global - lowest)\n</code></pre></p> <p>Objective: Scan configuration directories and build the final component index with proper conflict resolution.</p> <pre><code>flowchart TD\n    A[_build_component_index] --&gt; B[For each source directory in order]\n    B --&gt; C[Scan for config files]\n    C --&gt; D[*.json, *.yaml, *.yml]\n    D --&gt; E[For each file]\n    E --&gt; F[Parse as array of components]\n    F --&gt; G[For each component]\n    G --&gt; H{Already indexed?}\n    H --&gt;|Yes| I[Skip - first wins]\n    H --&gt;|No| J[Add to index with metadata]\n    J --&gt; K{More components?}\n    I --&gt; K\n    K --&gt;|Yes| G\n    K --&gt;|No| L{More files?}\n    L --&gt;|Yes| E\n    L --&gt;|No| M{More sources?}\n    M --&gt;|Yes| B\n    M --&gt;|No| N[Component indexing complete]\n\n    style A fill:#2196F3,stroke:#1976D2,stroke-width:2px,color:#fff\n    style N fill:#4CAF50,stroke:#388E3C,stroke-width:2px,color:#fff\n    style H fill:#9C27B0,stroke:#7B1FA2,stroke-width:2px,color:#fff\n    style J fill:#FF9800,stroke:#F57C00,stroke-width:2px,color:#fff\n    style I fill:#F44336,stroke:#D32F2F,stroke-width:2px,color:#fff\n    style C fill:#607D8B,stroke:#455A64,stroke-width:2px,color:#fff\n    style F fill:#607D8B,stroke:#455A64,stroke-width:2px,color:#fff</code></pre> <p>Key Activities: - Scan configuration directories for JSON/YAML files - Parse files as arrays of component configurations - Apply first-found-wins conflict resolution - Add metadata fields for traceability and path resolution</p> <p>Component Metadata Each indexed component includes the following metadata fields:</p> <ul> <li><code>_source_file</code>: Full path to the configuration file</li> <li><code>_context_path</code>: Root directory of the context (project/workspace)</li> <li><code>_context_level</code>: <code>\"project\"</code>, <code>\"workspace\"</code>, or <code>\"user\"</code></li> <li><code>_project_name</code>: Name of the project (if applicable)</li> <li><code>_workspace_name</code>: Name of the workspace (if applicable)</li> </ul> <p>Conflict Resolution: When the same component name exists in multiple locations, the first occurrence wins based on the priority order.</p>"},{"location":"architecture/flow/config_index_building_flow/#references","title":"References","text":"<ul> <li>Implementation: <code>src/aurite/lib/config/config_manager.py</code> - Main ConfigManager class</li> <li>Design Details: ConfigManager Design - Architecture and design patterns</li> </ul>"},{"location":"architecture/flow/mcp_server_registration_flow/","title":"MCP Server Registration Flow","text":"<p>This document explains the five-phase process used by the MCP Host to register MCP (Model Context Protocol) servers and discover their capabilities.</p>"},{"location":"architecture/flow/mcp_server_registration_flow/#overview","title":"Overview","text":"<p>The MCP Host uses a comprehensive five-phase registration process to establish connections with external MCP servers and discover their tools, prompts, and resources. This process ensures reliable server registration, proper component discovery, and robust error handling.</p>"},{"location":"architecture/flow/mcp_server_registration_flow/#registration-process","title":"Registration Process","text":"<p>The registration process follows a sequential five-phase approach, where each phase must complete successfully before proceeding to the next phase.</p>"},{"location":"architecture/flow/mcp_server_registration_flow/#five-phase-registration-process","title":"Five-Phase Registration Process","text":"Phase 1: Configuration ResolutionPhase 2: Transport EstablishmentPhase 3: MCP Session InitializationPhase 4: Component DiscoveryPhase 5: Component Registration <p>Objective: Retrieve and validate server configuration with credential resolution.</p> <pre><code>flowchart TD\n    A[ClientConfig] --&gt; B[SecurityManager.resolve_credentials]\n    B --&gt; C[Environment Variable Substitution]\n    C --&gt; D[Transport Validation]\n    D --&gt; E[Resolved Configuration]\n\n    style A fill:#2196F3,stroke:#1976D2,stroke-width:2px,color:#fff\n    style E fill:#4CAF50,stroke:#388E3C,stroke-width:2px,color:#fff\n    style B fill:#FF9800,stroke:#F57C00,stroke-width:2px,color:#fff\n    style C fill:#FF9800,stroke:#F57C00,stroke-width:2px,color:#fff\n    style D fill:#9C27B0,stroke:#7B1FA2,stroke-width:2px,color:#fff</code></pre> <p>Key Activities: - SecurityManager resolves encrypted credentials and environment variables - Environment variable substitution with placeholder resolution - Transport-specific validation (stdio, local, http_stream) - Configuration integrity verification</p> <p>Implementation Details: <pre><code># SecurityManager resolves encrypted credentials\nresolved_config = security_manager.resolve_credentials(server_config)\n\n# Environment variable substitution\nif \"{API_TOKEN}\" in resolved_config.headers.get(\"Authorization\", \"\"):\n    resolved_config.headers[\"Authorization\"] = resolved_config.headers[\"Authorization\"].replace(\n        \"{API_TOKEN}\", os.environ.get(\"API_TOKEN\", \"\")\n    )\n</code></pre></p> <p>Validation Examples: <pre><code># Validate required fields based on transport type\nif server_config.transport_type == \"stdio\":\n    if not server_config.server_path:\n        raise ValueError(\"'server_path' is required for stdio transport\")\nelif server_config.transport_type == \"http_stream\":\n    if not server_config.http_endpoint:\n        raise ValueError(\"'http_endpoint' is required for http_stream transport\")\n</code></pre></p> <p>Objective: Establish the appropriate transport connection based on server configuration.</p> <pre><code>flowchart TD\n    A[Resolved ClientConfig] --&gt; B{Transport Type}\n    B --&gt;|stdio| C[StdioServerParameters]\n    B --&gt;|local| D[Local Command Setup]\n    B --&gt;|http_stream| E[StreamableHttpParameters]\n\n    C --&gt; F[AsyncExitStack Context]\n    D --&gt; F\n    E --&gt; F\n\n    F --&gt; G[read, write streams]\n\n    style A fill:#2196F3,stroke:#1976D2,stroke-width:2px,color:#fff\n    style G fill:#4CAF50,stroke:#388E3C,stroke-width:2px,color:#fff\n    style B fill:#9C27B0,stroke:#7B1FA2,stroke-width:2px,color:#fff\n    style F fill:#607D8B,stroke:#455A64,stroke-width:2px,color:#fff</code></pre> <p>Key Activities: - Transport-specific parameter setup based on configuration - AsyncExitStack context creation for guaranteed cleanup - Stream establishment (stdin/stdout, HTTP, or command execution) - Connection validation and error handling</p> <p>Transport Implementations:</p> <p>STDIO Transport: <pre><code># Local Python subprocess\nparams = StdioServerParameters(\n    command=\"python\",\n    args=[str(server_config.server_path)],\n    env=client_env\n)\nclient = stdio_client(params, errlog=open(os.devnull, \"w\"))\nread, write = await session_stack.enter_async_context(client)\n</code></pre></p> <p>Local Command Transport: <pre><code># Execute local command with arguments\nresolved_args = [\n    _resolve_placeholders(arg) for arg in (config.args or [])\n]\nparams = StdioServerParameters(\n    command=config.command,\n    args=resolved_args,\n    env=client_env\n)\nclient = stdio_client(params, errlog=open(os.devnull, \"w\"))\nread, write = await session_stack.enter_async_context(client)\n</code></pre></p> <p>HTTP Stream Transport: <pre><code># Remote HTTP streaming connection\nendpoint_url = _resolve_placeholders(config.http_endpoint)\nparams = StreamableHttpParameters(\n    url=endpoint_url,\n    headers=config.headers,\n    timeout=timedelta(seconds=config.timeout or 30.0)\n)\nclient = streamablehttp_client(\n    url=params.url,\n    headers=params.headers,\n    timeout=params.timeout,\n    sse_read_timeout=params.sse_read_timeout,\n    terminate_on_close=True\n)\nread, write, _ = await session_stack.enter_async_context(client)\n</code></pre></p> <p>Objective: Create MCP client session and perform protocol handshake.</p> <pre><code>flowchart TD\n    A[Transport Streams] --&gt; B[mcp.ClientSession]\n    B --&gt; C[session.initialize]\n    C --&gt; D{Handshake Success?}\n    D --&gt;|Yes| E[Session Ready]\n    D --&gt;|No| F[Cleanup &amp; Error]\n    E --&gt; G[Store Session]\n\n    style A fill:#2196F3,stroke:#1976D2,stroke-width:2px,color:#fff\n    style G fill:#4CAF50,stroke:#388E3C,stroke-width:2px,color:#fff\n    style D fill:#9C27B0,stroke:#7B1FA2,stroke-width:2px,color:#fff\n    style F fill:#F44336,stroke:#D32F2F,stroke-width:2px,color:#fff</code></pre> <p>Key Activities: - MCP ClientSession creation with transport streams - Protocol handshake and capability negotiation - Session validation and error recovery - Session storage with exit stack for lifecycle management</p> <p>Session Creation: <pre><code># Create MCP client session\nsession = await session_stack.enter_async_context(\n    mcp.ClientSession(read, write)\n)\n\n# Store session for lifecycle management\nself._sessions[server_name] = session\nself._session_exit_stacks[server_name] = session_stack\n</code></pre></p> <p>Protocol Handshake: <pre><code># Perform MCP protocol initialization\nawait session.initialize()\n\n# Session now ready for component discovery\nlogger.info(f\"MCP session initialized for '{server_name}'\")\n</code></pre></p> <p>Objective: Query MCP server for available tools, prompts, and resources.</p> <pre><code>flowchart TD\n    A[Initialized Session] --&gt; B[session.list_tools]\n    A --&gt; C[session.list_prompts]\n    A --&gt; D[session.list_resources]\n\n    B --&gt; E[Process &amp; Prefix Tools]\n    C --&gt; F[Process &amp; Prefix Prompts]\n    D --&gt; G[Validate &amp; Store Resources]\n\n    E --&gt; H[Update Registries]\n    F --&gt; H\n    G --&gt; H\n\n    style A fill:#2196F3,stroke:#1976D2,stroke-width:2px,color:#fff\n    style H fill:#4CAF50,stroke:#388E3C,stroke-width:2px,color:#fff\n    style B fill:#FF9800,stroke:#F57C00,stroke-width:2px,color:#fff\n    style C fill:#FF9800,stroke:#F57C00,stroke-width:2px,color:#fff\n    style D fill:#FF9800,stroke:#F57C00,stroke-width:2px,color:#fff</code></pre> <p>Key Activities: - Parallel discovery of tools, prompts, and resources via MCP protocol - Server prefix application to prevent naming conflicts - Resource access validation through RootManager - Metadata enhancement (timeouts, schemas, access controls)</p> <p>Tool Discovery: <pre><code># Discover available tools\ntry:\n    tools_response = await session.list_tools()\n    for tool in tools_response.tools:\n        # Preserve original name in title\n        tool.title = tool.name\n\n        # Add server prefix for uniqueness\n        tool.name = f\"{server_name}-{tool.name}\"\n\n        # Add timeout metadata\n        if not tool.meta:\n            tool.meta = {}\n        tool.meta[\"timeout\"] = server_config.timeout\n\n        # Register with ToolManager\n        self._tools[tool.name] = tool\n        self._tool_to_session[tool.name] = session\n\n    logger.info(f\"Discovered {len(tools_response.tools)} tools from '{server_name}'\")\n\nexcept Exception as e:\n    logger.warning(f\"Could not fetch tools from '{server_name}': {e}\")\n</code></pre></p> <p>Prompt Discovery: <pre><code># Discover available prompts\ntry:\n    prompts_response = await session.list_prompts()\n    for prompt in prompts_response.prompts:\n        # Add server prefix for uniqueness\n        prompt_name = f\"{server_name}-{prompt.name}\"\n\n        # Store prompt definition\n        self._prompts[prompt_name] = prompt\n\n        # Map to session for execution\n        self._prompt_to_session[prompt_name] = session\n\n    logger.info(f\"Discovered {len(prompts_response.prompts)} prompts from '{server_name}'\")\n\nexcept Exception as e:\n    logger.warning(f\"Could not fetch prompts from '{server_name}': {e}\")\n</code></pre></p> <p>Resource Discovery: <pre><code># Discover available resources\ntry:\n    resources_response = await session.list_resources()\n    for resource in resources_response.resources:\n        # Add server prefix for uniqueness\n        resource_name = f\"{server_name}-{resource.name}\"\n\n        # Validate resource URI with RootManager\n        if self._root_manager.validate_access(resource.uri):\n            # Store resource definition\n            self._resources[resource_name] = resource\n\n            # Map to session for access\n            self._resource_to_session[resource_name] = session\n        else:\n            logger.warning(f\"Resource '{resource.name}' denied by root manager\")\n\n    logger.info(f\"Discovered {len(resources_response.resources)} resources from '{server_name}'\")\n\nexcept Exception as e:\n    logger.warning(f\"Could not fetch resources from '{server_name}': {e}\")\n</code></pre></p> <p>Component Naming Strategy</p> <p>Components are prefixed with server names to prevent conflicts:</p> <ul> <li>Tool Names: <code>weather_server-get_weather</code> (server_name-tool_name)</li> <li>Prompt Names: <code>planning_server-task_breakdown</code> (server_name-prompt_name)</li> <li>Resource Names: <code>file_server-document.txt</code> (server_name-resource_name)</li> <li>Original Names: Preserved in <code>title</code> field for display purposes</li> </ul> <p>Objective: Register discovered components with internal registries and update routing tables.</p> <pre><code>flowchart TD\n    A[Discovered Components] --&gt; B[Update Tool Registry]\n    A --&gt; C[Update Prompt Registry]\n    A --&gt; D[Update Resource Registry]\n\n    B --&gt; E[Update MessageRouter]\n    C --&gt; E\n    D --&gt; E\n\n    E --&gt; F[Registration Complete]\n\n    style A fill:#2196F3,stroke:#1976D2,stroke-width:2px,color:#fff\n    style F fill:#4CAF50,stroke:#388E3C,stroke-width:2px,color:#fff\n    style E fill:#FF9800,stroke:#F57C00,stroke-width:2px,color:#fff</code></pre> <p>Key Activities: - Component storage in type-specific registries - Session routing table updates for efficient tool execution - MessageRouter mapping creation for O(1) component lookup - FilteringManager integration for access control enforcement</p> <p>Registry Updates: <pre><code># Registration creates multiple data structures\nregistration_data = {\n    # Component storage (by type)\n    \"tools\": {\n        \"weather_server-get_weather\": Tool(name=\"weather_server-get_weather\", ...),\n        \"location_server-geocode\": Tool(name=\"location_server-geocode\", ...)\n    },\n\n    # Session routing (for execution)\n    \"tool_to_session\": {\n        \"weather_server-get_weather\": &lt;ClientSession for weather_server&gt;,\n        \"location_server-geocode\": &lt;ClientSession for location_server&gt;\n    }\n}\n</code></pre></p> <p>MessageRouter Updates: <pre><code># MessageRouter maintains component-to-session mappings\nself._message_router.register_component_mappings({\n    \"weather_server-get_weather\": session_weather,\n    \"weather_server-get_forecast\": session_weather,\n    \"location_server-geocode\": session_location,\n    \"location_server-reverse_geocode\": session_location\n})\n\n# Enables fast lookup during tool execution\ntarget_session = self._message_router.get_session_for_component(\"weather_server-get_weather\")\n</code></pre></p>"},{"location":"architecture/flow/mcp_server_registration_flow/#references","title":"References","text":"<ul> <li>Implementation: <code>src/aurite/execution/mcp_host.py</code> - Main MCP Host implementation</li> <li>Design Details: MCP Host Design - Architecture and component details</li> </ul>"},{"location":"architecture/flow/session_management_flow/","title":"Session Management Flow","text":"<p>This document explains the session management flows used by the SessionManager and CacheManager to handle conversation history, execution results, and session lifecycle across the Aurite framework.</p>"},{"location":"architecture/flow/session_management_flow/#overview","title":"Overview","text":"<p>The session management system provides persistent storage and retrieval of execution sessions through a two-tier architecture: the SessionManager provides high-level session operations while the CacheManager handles low-level file-based storage with in-memory caching. Sessions support both agent conversations and workflow executions with comprehensive metadata tracking.</p>"},{"location":"architecture/flow/session_management_flow/#core-session-operations","title":"Core Session Operations","text":"<p>The session management system supports four primary operations with different flows based on the operation type and session characteristics.</p> Session Creation FlowSession Retrieval FlowSession Update FlowSession Deletion Flow <p>Objective: Create new sessions with proper metadata initialization and storage backend setup.</p> <pre><code>flowchart TD\n    A[Session Creation Request] --&gt; B[Session ID Generation]\n    B --&gt; C[Metadata Extraction]\n    C --&gt; D[Session Data Assembly]\n    D --&gt; E[CacheManager Storage]\n    E --&gt; F[In-Memory Cache Update]\n    F --&gt; G[File Persistence]\n    G --&gt; H[Session Created]\n\n    style A fill:#2196F3,stroke:#1976D2,stroke-width:2px,color:#fff\n    style H fill:#4CAF50,stroke:#388E3C,stroke-width:2px,color:#fff\n    style E fill:#FF9800,stroke:#F57C00,stroke-width:2px,color:#fff\n    style G fill:#9C27B0,stroke:#7B1FA2,stroke-width:2px,color:#fff</code></pre> <p>Phase 1: Session Data Assembly <pre><code># SessionManager._save_result\nnow = datetime.utcnow().isoformat()\nexisting_data = self._cache.get_result(session_id) or {}\n\nmetadata = self._extract_metadata(execution_result)\nsession_data = {\n    \"session_id\": session_id,\n    \"base_session_id\": base_session_id,\n    \"execution_result\": execution_result,\n    \"result_type\": result_type,  # \"agent\" or \"workflow\"\n    \"created_at\": existing_data.get(\"created_at\", now),\n    \"last_updated\": now,\n    **metadata,  # name, message_count, agents_involved\n}\n</code></pre></p> <p>Phase 2: Metadata Extraction <pre><code># Different extraction logic based on result type\nif is_workflow:\n    name = execution_result.get(\"workflow_name\")\n    # Extract message count from all step results\n    for step in execution_result.get(\"step_results\", []):\n        if \"conversation_history\" in step_result:\n            message_count += len(step_result.get(\"conversation_history\", []))\n\n    # Track agents involved in workflow\n    agent_session_id = step_result.get(\"session_id\")\n    agent_name_in_step = step_result.get(\"agent_name\")\n    if agent_session_id and agent_name_in_step:\n        agents_involved[agent_session_id] = agent_name_in_step\nelse:  # Agent result\n    name = execution_result.get(\"agent_name\")\n    message_count = len(execution_result.get(\"conversation_history\", []))\n</code></pre></p> <p>Phase 3: Storage Persistence <pre><code># CacheManager.save_result\n# Update in-memory cache first\nself._result_cache[session_id] = session_data\n\n# Persist to disk with error handling\nsession_file = self._get_session_file(session_id)\nwith open(session_file, \"w\") as f:\n    json.dump(session_data, f, indent=2)\n</code></pre></p> <p>Session File Structure: <pre><code>{\n  \"session_id\": \"agent-a1b2c3d4\",\n  \"base_session_id\": \"agent-a1b2c3d4\",\n  \"execution_result\": {\n    \"status\": \"success\",\n    \"conversation_history\": [...],\n    \"agent_name\": \"weather_agent\"\n  },\n  \"result_type\": \"agent\",\n  \"created_at\": \"2025-01-09T19:08:48.959750\",\n  \"last_updated\": \"2025-01-09T19:08:52.329089\",\n  \"name\": \"weather_agent\",\n  \"message_count\": 4\n}\n</code></pre></p> <p>Objective: Retrieve session data with support for partial ID matching and metadata validation.</p> <pre><code>flowchart TD\n    A[Session Retrieval Request] --&gt; B[Direct ID Lookup]\n    B --&gt; C{Session Found?}\n    C --&gt;|Yes| D[Return Session Data]\n    C --&gt;|No| E[Base Session ID Search]\n    E --&gt; F{Matches Found?}\n    F --&gt;|None| G[Return Not Found]\n    F --&gt;|One| H[Return Matched Session]\n    F --&gt;|Multiple| I[Primary Session Resolution]\n    I --&gt; J{Primary Found?}\n    J --&gt;|Yes| H\n    J --&gt;|No| K[Return Ambiguous Error]\n\n    style A fill:#2196F3,stroke:#1976D2,stroke-width:2px,color:#fff\n    style D fill:#4CAF50,stroke:#388E3C,stroke-width:2px,color:#fff\n    style H fill:#4CAF50,stroke:#388E3C,stroke-width:2px,color:#fff\n    style G fill:#F44336,stroke:#D32F2F,stroke-width:2px,color:#fff\n    style K fill:#F44336,stroke:#D32F2F,stroke-width:2px,color:#fff</code></pre> <p>Phase 1: Direct Lookup <pre><code># SessionManager.get_full_session_details\nexecution_result = self.get_session_result(session_id)\nmetadata_model = self.get_session_metadata(session_id)\n\nif execution_result is None:\n    # Proceed to base session ID search\n    all_sessions_result = self.get_sessions_list(limit=10000, offset=0)\n    matching_sessions = [\n        s for s in all_sessions_result[\"sessions\"]\n        if s.base_session_id and s.base_session_id == session_id\n    ]\n</code></pre></p> <p>Phase 2: Cache Lookup with Disk Fallback <pre><code># CacheManager.get_result\n# Check memory cache first\nif session_id in self._result_cache:\n    return self._result_cache[session_id]\n\n# Try to load from disk if not in memory\nsession_file = self._get_session_file(session_id)\nif session_file.exists():\n    with open(session_file, \"r\") as f:\n        data = json.load(f)\n    self._result_cache[session_id] = data\n    return data\n</code></pre></p> <p>Phase 3: Primary Session Resolution <pre><code># Handle multiple matches by finding primary session\nif len(matching_sessions) &gt; 1:\n    # Primary session doesn't have suffix like -0, -1\n    primary_match = [\n        s for s in matching_sessions\n        if not (s.session_id[-2] == \"-\" and s.session_id[-1].isdigit())\n    ]\n    if len(primary_match) == 1:\n        matched_session_id = primary_match[0].session_id\n    else:\n        # Ambiguous case - return error\n        session_ids = [s.session_id for s in matching_sessions]\n        raise HTTPException(\n            status_code=400,\n            detail=f\"Ambiguous partial ID '{session_id}'. Multiple sessions found: {session_ids[:5]}\"\n        )\n</code></pre></p> <p>Objective: Update existing sessions with new conversation messages or execution results while preserving metadata.</p> <pre><code>flowchart TD\n    A[Session Update Request] --&gt; B[Load Existing Session]\n    B --&gt; C[Update Session Data]\n    C --&gt; D[Refresh Metadata]\n    D --&gt; E[Update Timestamps]\n    E --&gt; F[Cache Update]\n    F --&gt; G[File Persistence]\n    G --&gt; H[Session Updated]\n\n    style A fill:#2196F3,stroke:#1976D2,stroke-width:2px,color:#fff\n    style H fill:#4CAF50,stroke:#388E3C,stroke-width:2px,color:#fff\n    style C fill:#FF9800,stroke:#F57C00,stroke-width:2px,color:#fff\n    style D fill:#FF9800,stroke:#F57C00,stroke-width:2px,color:#fff</code></pre> <p>Phase 1: Message Addition (Streaming) <pre><code># SessionManager.add_message_to_history\nexisting_history = self.get_session_history(session_id) or []\nupdated_history = existing_history + [message]\nself.save_conversation_history(session_id, updated_history, agent_name)\n</code></pre></p> <p>Phase 2: Complete Result Update <pre><code># SessionManager.save_agent_result / save_workflow_result\ndef _save_result(self, session_id: str, execution_result: Dict[str, Any],\n                 result_type: str, base_session_id: Optional[str] = None):\n    now = datetime.utcnow().isoformat()\n    existing_data = self._cache.get_result(session_id) or {}\n\n    # Preserve creation timestamp, update last_updated\n    session_data = {\n        \"session_id\": session_id,\n        \"base_session_id\": base_session_id,\n        \"execution_result\": execution_result,\n        \"result_type\": result_type,\n        \"created_at\": existing_data.get(\"created_at\", now),  # Preserve original\n        \"last_updated\": now,  # Always update\n        **self._extract_metadata(execution_result),\n    }\n    self._cache.save_result(session_id, session_data)\n</code></pre></p> <p>Phase 3: Metadata Refresh <pre><code># Automatic metadata extraction on update\ndef _extract_metadata(self, execution_result: Dict[str, Any]) -&gt; Dict[str, Any]:\n    message_count = 0\n    name = None\n    agents_involved: Dict[str, str] = {}\n    is_workflow = \"step_results\" in execution_result\n\n    # Extract current metadata from execution result\n    if is_workflow:\n        name = execution_result.get(\"workflow_name\")\n        # Recalculate message count from all steps\n        for step in execution_result.get(\"step_results\", []):\n            if \"conversation_history\" in step_result:\n                message_count += len(step_result.get(\"conversation_history\", []))\n    else:\n        name = execution_result.get(\"agent_name\")\n        message_count = len(execution_result.get(\"conversation_history\", []))\n\n    return {\"name\": name, \"message_count\": message_count, \"agents_involved\": agents_involved}\n</code></pre></p> <p>Objective: Delete sessions with cascading cleanup for workflow hierarchies and parent-child relationships.</p> <pre><code>flowchart TD\n    A[Session Deletion Request] --&gt; B[Load Session Metadata]\n    B --&gt; C{Session Type?}\n    C --&gt;|Workflow| D[Find Child Agent Sessions]\n    C --&gt;|Child Agent| E[Update Parent Workflow]\n    C --&gt;|Standalone Agent| F[Direct Deletion]\n    D --&gt; G[Delete Child Sessions]\n    G --&gt; F\n    E --&gt; H[Remove from Parent Agents List]\n    H --&gt; F\n    F --&gt; I[Delete from Cache]\n    I --&gt; J[Delete File]\n    J --&gt; K[Session Deleted]\n\n    style A fill:#2196F3,stroke:#1976D2,stroke-width:2px,color:#fff\n    style K fill:#4CAF50,stroke:#388E3C,stroke-width:2px,color:#fff\n    style D fill:#FF9800,stroke:#F57C00,stroke-width:2px,color:#fff\n    style E fill:#FF9800,stroke:#F57C00,stroke-width:2px,color:#fff\n    style G fill:#9C27B0,stroke:#7B1FA2,stroke-width:2px,color:#fff</code></pre> <p>Phase 1: Workflow Cascade Deletion <pre><code># SessionManager.delete_session\nsession_to_delete = self.get_session_metadata(session_id)\n\n# Case 1: Deleting a workflow - cascade to child agents\nif session_to_delete.is_workflow:\n    all_sessions = self.get_sessions_list(limit=10000)[\"sessions\"]\n    child_agent_sessions = [\n        s for s in all_sessions\n        if not s.is_workflow\n        and s.base_session_id == session_to_delete.base_session_id\n        and s.session_id != session_to_delete.session_id\n    ]\n    for child in child_agent_sessions:\n        self._cache.delete_session(child.session_id)\n        logger.info(f\"Cascading delete: removed child agent session '{child.session_id}'\")\n</code></pre></p> <p>Phase 2: Parent Workflow Update <pre><code># Case 2: Deleting a child agent - update parent workflow\nelif session_to_delete.base_session_id and session_to_delete.base_session_id != session_id:\n    all_sessions = self.get_sessions_list(limit=10000)[\"sessions\"]\n    parent_workflows = [\n        s for s in all_sessions\n        if s.is_workflow and s.base_session_id == session_to_delete.base_session_id\n    ]\n    for parent in parent_workflows:\n        parent_data = self._cache.get_result(parent.session_id)\n        if parent_data and parent_data.get(\"agents_involved\") and session_id in parent_data[\"agents_involved\"]:\n            del parent_data[\"agents_involved\"][session_id]\n            self._cache.save_result(parent.session_id, parent_data)\n</code></pre></p> <p>Phase 3: Physical Deletion <pre><code># CacheManager.delete_session\n# Remove from memory cache\nsession_exists_in_mem = self._result_cache.pop(session_id, None) is not None\n\n# Remove from disk\nsession_file = self._get_session_file(session_id)\nsession_exists_on_disk = session_file.exists()\nif session_exists_on_disk:\n    session_file.unlink()\n\nreturn session_exists_in_mem or session_exists_on_disk\n</code></pre></p>"},{"location":"architecture/flow/session_management_flow/#session-lifecycle-management","title":"Session Lifecycle Management","text":""},{"location":"architecture/flow/session_management_flow/#session-id-generation-patterns","title":"Session ID Generation Patterns","text":"<p>The session management system supports different ID generation patterns based on execution context:</p> <p>Agent Sessions:</p> <ul> <li>Standalone: <code>agent-{uuid4().hex[:8]}</code> (e.g., <code>agent-a1b2c3d4</code>)</li> <li>User Provided: Prefixed with <code>agent-</code> if not already prefixed</li> <li>Workflow Context: Uses workflow's base session ID without additional prefixing</li> </ul> <p>Workflow Sessions:</p> <ul> <li>Standalone: <code>workflow-{uuid4().hex[:8]}</code> (e.g., <code>workflow-x9y8z7w6</code>)</li> <li>User Provided: Prefixed with <code>workflow-</code> if not already prefixed</li> <li>Base Session Tracking: Original session ID preserved for step coordination</li> </ul>"},{"location":"architecture/flow/session_management_flow/#session-metadata-validation","title":"Session Metadata Validation","text":"<p>Pydantic Model Validation:</p> <pre><code># SessionManager._validate_and_transform_metadata\ndef _validate_and_transform_metadata(self, session_data: Dict[str, Any]) -&gt; SessionMetadata:\n    session_id = session_data.get(\"session_id\", \"N/A\")\n    result_type = session_data.get(\"result_type\")\n    is_workflow = result_type == \"workflow\"\n\n    # Extract name with fallback handling\n    name = session_data.get(\"name\")\n    if not name:\n        type_str = \"Workflow\" if is_workflow else \"Agent\"\n        logger.warning(f\"{type_str} session '{session_id}' is missing a name. Using placeholder.\")\n        name = f\"Untitled {type_str} ({session_id[:8]})\"\n\n    return SessionMetadata(\n        session_id=session_id,\n        name=name,\n        created_at=session_data.get(\"created_at\"),\n        last_updated=session_data.get(\"last_updated\"),\n        message_count=session_data.get(\"message_count\"),\n        is_workflow=is_workflow,\n        agents_involved=session_data.get(\"agents_involved\"),\n        base_session_id=session_data.get(\"base_session_id\"),\n    )\n</code></pre> <p>Backwards Compatibility:</p> <pre><code># Handle legacy sessions without message_count\nif \"message_count\" not in session_data:\n    metadata = self._extract_metadata(session_data.get(\"execution_result\", {}))\n    session_data.update(metadata)\n</code></pre>"},{"location":"architecture/flow/session_management_flow/#session-filtering-and-pagination","title":"Session Filtering and Pagination","text":"<p>Query Processing:</p> <pre><code># SessionManager.get_sessions_list\ndef get_sessions_list(self, agent_name: Optional[str] = None,\n                     workflow_name: Optional[str] = None,\n                     limit: int = 50, offset: int = 0) -&gt; Dict[str, Any]:\n    # Load and validate all sessions\n    all_validated_sessions: List[SessionMetadata] = []\n    cache_dir = self._cache.get_cache_dir()\n\n    for session_file in cache_dir.glob(\"*.json\"):\n        try:\n            with open(session_file, \"r\") as f:\n                session_data = json.load(f)\n\n            # Ensure backwards compatibility\n            if \"message_count\" not in session_data:\n                metadata = self._extract_metadata(session_data.get(\"execution_result\", {}))\n                session_data.update(metadata)\n\n            model = self._validate_and_transform_metadata(session_data)\n            all_validated_sessions.append(model)\n        except (json.JSONDecodeError, ValidationError) as e:\n            logger.warning(f\"Skipping invalid session file: {session_file}\")\n</code></pre> <p>Filtering Logic:</p> <pre><code># Apply filtering based on request parameters\nfiltered_sessions: List[SessionMetadata] = []\nif workflow_name:\n    # Only return parent workflow sessions\n    filtered_sessions = [s for s in all_validated_sessions\n                        if s.is_workflow and s.name == workflow_name]\nelif agent_name:\n    # Only return direct agent runs (not workflow steps)\n    filtered_sessions = [s for s in all_validated_sessions\n                        if not s.is_workflow and s.name == agent_name]\nelse:\n    filtered_sessions = all_validated_sessions\n\n# Sort by last_updated descending and apply pagination\nfiltered_sessions.sort(key=lambda x: x.last_updated or \"\", reverse=True)\ntotal = len(filtered_sessions)\npaginated_sessions = filtered_sessions[offset:offset + limit]\n</code></pre>"},{"location":"architecture/flow/session_management_flow/#storage-architecture","title":"Storage Architecture","text":""},{"location":"architecture/flow/session_management_flow/#two-tier-storage-design","title":"Two-Tier Storage Design","text":"<p>SessionManager (High-Level):</p> <ul> <li>Provides business logic for session operations</li> <li>Handles metadata extraction and validation</li> <li>Manages session relationships and cascading operations</li> <li>Implements filtering, pagination, and search functionality</li> </ul> <p>CacheManager (Low-Level):</p> <ul> <li>Handles file I/O operations with error handling</li> <li>Maintains in-memory cache for performance</li> <li>Manages session file naming and sanitization</li> <li>Provides atomic read/write operations</li> </ul>"},{"location":"architecture/flow/session_management_flow/#file-system-organization","title":"File System Organization","text":"<p>Cache Directory Structure:</p> <pre><code>.aurite_cache/\n\u251c\u2500\u2500 agent-a1b2c3d4.json          # Agent session\n\u251c\u2500\u2500 workflow-x9y8z7w6.json       # Workflow session\n\u251c\u2500\u2500 workflow-x9y8z7w6-0.json     # Workflow step 0\n\u251c\u2500\u2500 workflow-x9y8z7w6-1.json     # Workflow step 1\n\u2514\u2500\u2500 ...\n</code></pre> <p>Session ID Sanitization:</p> <pre><code># CacheManager._get_session_file\ndef _get_session_file(self, session_id: str) -&gt; Path:\n    # Sanitize session_id to prevent directory traversal\n    safe_session_id = \"\".join(c for c in session_id if c.isalnum() or c in \"-_\")\n    return self._cache_dir / f\"{safe_session_id}.json\"\n</code></pre>"},{"location":"architecture/flow/session_management_flow/#performance-optimizations","title":"Performance Optimizations","text":"<p>In-Memory Caching:</p> <ul> <li>All sessions loaded into memory on startup</li> <li>Memory cache updated immediately on write operations</li> <li>Disk operations performed asynchronously when possible</li> </ul> <p>Lazy Loading:</p> <ul> <li>Sessions loaded from disk only when not in memory cache</li> <li>Failed disk reads don't prevent memory cache operations</li> <li>Graceful degradation on file system errors</li> </ul>"},{"location":"architecture/flow/session_management_flow/#cleanup-and-retention","title":"Cleanup and Retention","text":""},{"location":"architecture/flow/session_management_flow/#retention-policy-implementation","title":"Retention Policy Implementation","text":"<p>Age-Based Cleanup:</p> <pre><code># SessionManager.cleanup_old_sessions\ncutoff_date = datetime.utcnow() - timedelta(days=days)\n\nfor session in all_sessions:\n    last_updated_str = session.last_updated\n    if last_updated_str:\n        last_updated = datetime.fromisoformat(last_updated_str.replace(\"Z\", \"+00:00\")).replace(tzinfo=None)\n        if last_updated &lt; cutoff_date:\n            sessions_to_delete.add(session.session_id)\n</code></pre> <p>Count-Based Cleanup:</p> <pre><code># Keep only the most recent max_sessions\nexcess_count = len(sessions_kept) - max_sessions\nif excess_count &gt; 0:\n    # Sessions already sorted oldest to newest\n    for i in range(excess_count):\n        sessions_to_delete.add(sessions_kept[i].session_id)\n</code></pre> <p>Cascading Cleanup:</p> <ul> <li>Workflow deletion automatically removes child agent sessions</li> <li>Parent workflow metadata updated when child agents are deleted</li> <li>Orphaned sessions cleaned up during retention policy execution</li> </ul>"},{"location":"architecture/flow/session_management_flow/#integration-with-auriteengine","title":"Integration with AuriteEngine","text":""},{"location":"architecture/flow/session_management_flow/#session-creation-integration","title":"Session Creation Integration","text":"<p>Agent Execution:</p> <pre><code># AuriteEngine integration points\nif agent_instance.config.include_history and final_session_id and self._session_manager:\n    self._session_manager.save_agent_result(\n        session_id=final_session_id,\n        agent_result=run_result,\n        base_session_id=final_base_session_id\n    )\n</code></pre> <p>Workflow Execution:</p> <pre><code># Workflow result persistence\nif result.session_id and self._session_manager:\n    self._session_manager.save_workflow_result(\n        session_id=result.session_id,\n        workflow_result=result,\n        base_session_id=base_session_id\n    )\n</code></pre>"},{"location":"architecture/flow/session_management_flow/#history-loading-integration","title":"History Loading Integration","text":"<p>Pre-Execution History Loading:</p> <pre><code># AuriteEngine._prepare_agent_for_run\nif effective_include_history and session_id and self._session_manager:\n    history = self._session_manager.get_session_history(session_id)\n    if history:\n        initial_messages.extend(history)\n\n# Immediate message addition for streaming\nself._session_manager.add_message_to_history(\n    session_id=session_id,\n    message=current_user_message,\n    agent_name=agent_name,\n)\n</code></pre>"},{"location":"architecture/flow/session_management_flow/#references","title":"References","text":"<ul> <li>Implementation: <code>src/aurite/lib/storage/sessions/session_manager.py</code> - Main SessionManager implementation</li> <li>Storage Backend: <code>src/aurite/lib/storage/sessions/cache_manager.py</code> - CacheManager file operations</li> <li>Data Models: <code>src/aurite/lib/models/api/responses.py</code> - Session metadata and response models</li> <li>API Integration: <code>src/aurite/bin/api/routes/execution_routes.py</code> - Session management endpoints</li> <li>Engine Integration: AuriteEngine Execution Flow - Session integration patterns</li> </ul>"},{"location":"config/agent/","title":"Agent Configuration","text":"<p>Agents are the primary actors in the Aurite framework, responsible for executing tasks by interacting with tools and models. The agent configuration defines an agent's identity, its capabilities, and its behavior.</p> <p>An agent configuration is a JSON or YAML object with a <code>type</code> field set to <code>\"agent\"</code>.</p> <p>Configuration Location</p> <p>Agent configurations can be placed in any directory specified in your project's <code>.aurite</code> file (e.g., <code>config/agents/</code>, <code>shared/agents/</code>). The framework will automatically discover them.</p>"},{"location":"config/agent/#schema","title":"Schema","text":"<p>The <code>AgentConfig</code> defines the structure for an agent configuration. Below are the available fields, categorized for clarity.</p>  Core Fields Tool Management LLM Overrides Behavior Control <p>These fields define the fundamental properties of the agent.</p> Field Type Required Description <code>name</code> <code>string</code> Yes A unique identifier for the agent. This name is used to reference the agent in workflows and commands. <code>description</code> <code>string</code> No A brief, human-readable description of what the agent does. <code>llm_config_id</code> <code>string</code> <code>None</code> The <code>name</code> of an <code>llm</code> component to use. This is the recommended way to assign an LLM, allowing for reusable configurations. <code>system_prompt</code> <code>string</code> No The primary system prompt for the agent. This can be overridden by the <code>system_prompt</code> in the <code>llm</code> block. <code>mcp_servers</code> <code>list[string]</code> <code>[]</code> A list of <code>mcp_server</code> component names this agent can use. The agent gains access to all tools, prompts, and resources from these servers. <code>config_validation_schema</code> <code>dict</code> <code>None</code> A JSON schema for validating agent-specific configurations. <p>These fields control which tools and resources the agent can access.</p> Field Type Default Description <code>exclude_components</code> <code>list[string]</code> <code>None</code> A list of component names (tools, prompts, resources) to explicitly exclude, even if provided by allowed <code>mcp_servers</code>. <code>auto</code> <code>boolean</code> <code>false</code> If <code>true</code>, an LLM dynamically selects the most appropriate <code>mcp_servers</code> at runtime based on the user's prompt. <p>These fields control the Large Language Model that powers the agent's reasoning.</p> Field Type Default Description <code>model</code> <code>string</code> None Override the model name (e.g., <code>\"gpt-3.5-turbo\"</code>). <code>temperature</code> <code>float</code> None Override the sampling temperature for the agent's LLM. <code>max_tokens</code> <code>integer</code> None Override the maximum token limit for responses. <code>system_prompt</code> <code>string</code> None Provide a more specific system prompt for this agent. <code>api_base</code> <code>string</code> None Custom API endpoint base URL for the LLM provider. <code>api_key</code> <code>string</code> None Custom API key for the LLM provider. <code>api_version</code> <code>string</code> None Custom API version for the LLM provider. other fields various None Any other provider-specific parameters supported by the LLM Configuration. <p>LLM Overrides</p> <p>Agent Configurations can include llm variables (See LLM Overrides in the table above). These variables will replace the corresponding values in the LLM Configuration referenced by <code>llm_config_id</code>. This allows for agent-specific customization while still using a shared LLM configuration.</p> <p>These fields fine-tune how the agent executes its tasks.</p> Field Type Default Description <code>max_iterations</code> <code>integer</code> <code>50</code> The maximum number of conversational turns before stopping automatically. This is a safeguard to prevent infinite loops. <code>include_history</code> <code>boolean</code> <code>None</code> If <code>true</code>, the entire conversation history is included in each turn. If <code>false</code> or <code>None</code>, the agent is stateless and only sees the latest message."},{"location":"config/agent/#configuration-examples","title":"Configuration Examples","text":"<p>Here are some practical examples of agent configurations.</p> Simple AgentAgent with LLM OverridesStateful AgentAgent with Schema <p>A basic agent that uses a centrally-defined LLM and has access to a set of tools.</p> <pre><code>{\n  \"type\": \"agent\",\n  \"name\": \"code-refactor-agent\",\n  \"description\": \"An agent that helps refactor Python code by using static analysis tools.\",\n  \"mcp_servers\": [\"pylint-server\", \"file-system-server\"],\n  \"llm_config_id\": \"claude-3-opus\",\n  \"system_prompt\": \"You are an expert Python programmer. You will be given a file and your goal is to refactor it to improve readability and performance.\",\n  \"max_iterations\": 10\n}\n</code></pre> <p>This agent uses a base LLM configuration but overrides the model and temperature for its specific task.</p> <pre><code>{\n  \"type\": \"agent\",\n  \"name\": \"creative-writer-agent\",\n  \"description\": \"An agent for brainstorming creative ideas.\",\n  \"mcp_servers\": [\"internet-search-server\"],\n  \"llm_config_id\": \"gpt-4-base\",\n  \"model\": \"gpt-4-1106-preview\",\n  \"temperature\": 0.9\n}\n</code></pre> <p>This agent is configured to be stateful (<code>include_history</code> is <code>true</code>), allowing it to maintain context across multiple turns.</p> <pre><code>{\n  \"type\": \"agent\",\n  \"name\": \"simple-calculator-agent\",\n  \"description\": \"A stateless agent that performs a single calculation.\",\n  \"mcp_servers\": [\"calculator-tool-server\"],\n  \"llm_config_id\": \"gpt-3.5-turbo\",\n  \"include_history\": true\n}\n</code></pre> <p>This agent includes a custom validation schema to ensure its configuration adheres to specific rules.</p> <pre><code>{\n  \"type\": \"agent\",\n  \"name\": \"data-validation-agent\",\n  \"description\": \"An agent that validates data formats.\",\n  \"mcp_servers\": [\"data-validator-server\"],\n  \"llm_config_id\": \"gpt-3.5-turbo\",\n  \"config_validation_schema\": {\n    \"type\": \"object\",\n    \"properties\": {\n      \"input_format\": { \"type\": \"string\" },\n      \"output_format\": { \"type\": \"string\" }\n    },\n    \"required\": [\"input_format\", \"output_format\"]\n  }\n}\n</code></pre>"},{"location":"config/custom_workflow/","title":"Custom Workflow Configuration","text":"<p>When a <code>linear_workflow</code> isn't enough to capture your logic, you can implement a Custom Workflow directly in Python. This gives you complete control over the execution flow, allowing for conditional logic, branching, looping, and complex data manipulation between steps.</p> <p>A custom workflow configuration is a JSON or YAML object with a <code>type</code> field set to <code>\"custom_workflow\"</code>. Its purpose is to link a component name to your Python code.</p> <p>How It Works</p> <ol> <li>Configuration: You create a config file that gives your workflow a <code>name</code> and points to the <code>module_path</code> and <code>class_name</code> of your Python code.</li> <li>Implementation: You write a Python class that inherits from <code>aurite.BaseCustomWorkflow</code> and implements the <code>run</code> method.</li> <li>Execution: When you run the workflow by its <code>name</code>, the framework dynamically loads your Python class, instantiates it, and calls its <code>run</code> method, passing in the initial input and an execution engine.</li> </ol>"},{"location":"config/custom_workflow/#schema-and-implementation","title":"Schema and Implementation","text":"<p>Configuring a custom workflow involves two parts: the configuration file and the Python implementation.</p>  Configuration Schema Python Implementation <p>The configuration file tells the framework where to find your Python code.</p> Field Type Required Description <code>name</code> <code>string</code> Yes A unique identifier for the custom workflow. <code>description</code> <code>string</code> No A brief, human-readable description of what the workflow does. <code>module_path</code> <code>string</code> Yes The path to the Python file containing your workflow class, relative to your project's root directory. <code>class_name</code> <code>string</code> Yes The name of the class within the module that implements the workflow. <p>Your Python class must inherit from <code>BaseCustomWorkflow</code> and implement the <code>run</code> method.</p> <pre><code>from typing import Any, Optional\nfrom aurite import AuriteEngine, BaseCustomWorkflow, AgentRunResult\n\nclass MyWorkflow(BaseCustomWorkflow):\n    async def run(\n        self,\n        initial_input: Any,\n        executor: \"AuriteEngine\",\n        session_id: Optional[str] = None\n    ) -&gt; Any:\n        # Your custom logic goes here\n        print(f\"Workflow started with input: {initial_input}\")\n\n        # You can run agents using the executor instance passed to this method\n        result: AgentRunResult = await executor.run_agent(\n            agent_name=\"my-agent\",\n            user_message=\"What is the weather in SF?\",\n            session_id=session_id # Pass the session_id for history\n        )\n\n        return {\"final_output\": result.message_content}\n\n    def get_input_type(self) -&gt; Any:\n        \"\"\"(Optional) Returns the expected type of `initial_input`.\"\"\"\n        return str\n\n    def get_output_type(self) -&gt; Any:\n        \"\"\"(Optional) Returns the expected type of the workflow's final output.\"\"\"\n        return dict\n</code></pre> <p>Key Components:</p> <ul> <li><code>BaseCustomWorkflow</code>: The required base class from <code>aurite</code>.</li> <li><code>run(self, initial_input, executor, session_id)</code>: The main entry point for your workflow's logic. This method must be implemented.<ul> <li><code>initial_input</code>: The data passed to the workflow when it's executed.</li> <li><code>executor</code>: An instance of <code>AuriteEngine</code>, which allows you to run other components like agents (<code>executor.run_agent(...)</code>).</li> <li><code>session_id</code>: An optional session ID for maintaining conversation history.</li> </ul> </li> <li><code>get_input_type()</code> (Optional): A method that returns the expected Python type for <code>initial_input</code>. This can be used for documentation or validation.</li> <li><code>get_output_type()</code> (Optional): A method that returns the expected Python type for the value your <code>run</code> method returns.</li> </ul>"},{"location":"config/custom_workflow/#end-to-end-example","title":"End-to-End Example","text":"<p>This example shows how to create a custom workflow that intelligently routes a task to one of two agents based on the input. The file structure illustrates how the <code>module_path</code> is relative to the directory containing the <code>.aurite</code> file.</p> 1. Project Structure2. Configuration File3. Python Implementation <pre><code>my_project/\n\u251c\u2500\u2500 .aurite\n\u251c\u2500\u2500 config/\n\u2502   \u2514\u2500\u2500 workflows/\n\u2502       \u2514\u2500\u2500 routing_workflow.json  &lt;-- Configuration File\n\u2514\u2500\u2500 custom_workflows/\n    \u2514\u2500\u2500 my_routing_logic.py      &lt;-- Python Implementation\n</code></pre> <p><code>my_project/config/workflows/routing_workflow.json</code></p> <pre><code>{\n  \"type\": \"custom_workflow\",\n  \"name\": \"intelligent-routing-workflow\",\n  \"description\": \"A workflow that dynamically routes tasks to different agents based on input content.\",\n  \"module_path\": \"custom_workflows/my_routing_logic.py\",\n  \"class_name\": \"MyRoutingWorkflow\"\n}\n</code></pre> <p><code>my_project/custom_workflows/my_routing_logic.py</code></p> <pre><code>from typing import Any, Dict, Optional\nfrom aurite import AuriteEngine, BaseCustomWorkflow, AgentRunResult\n\nclass MyRoutingWorkflow(BaseCustomWorkflow):\n    \"\"\"\n    This workflow checks the input for keywords and routes the request\n    to either a weather agent or a calculator agent.\n    \"\"\"\n    async def run(\n        self,\n        initial_input: Dict[str, Any],\n        executor: \"AuriteEngine\",\n        session_id: Optional[str] = None\n    ) -&gt; AgentRunResult:\n        user_message = initial_input.get(\"message\", \"\")\n\n        if \"weather\" in user_message.lower():\n            agent_to_run = \"weather-agent\"\n        elif \"calculate\" in user_message.lower():\n            agent_to_run = \"calculator-agent\"\n        else:\n            agent_to_run = \"general-qa-agent\"\n\n        print(f\"Routing to agent: {agent_to_run}\")\n\n        # Run the selected agent using the provided executor\n        result = await executor.run_agent(\n            agent_name=agent_to_run,\n            user_message=user_message,\n            session_id=session_id\n        )\n        return result\n</code></pre>"},{"location":"config/evaluation/","title":"Evaluation Configuration","text":"<p>Evaluations are components that test and validate the performance of agents, workflows, and other components in the Aurite framework. An evaluation configuration defines what component(s) to test, the test cases to run, and the expected output criteria.</p> <p>An evaluation configuration is a JSON or YAML object with a <code>type</code> field set to <code>\"evaluation\"</code>.</p> <p>Configuration Location</p> <p>Evaluation configurations can be placed in any directory specified in your project's <code>.aurite</code> file (e.g., <code>config/evaluations/</code>, <code>config/testing/</code>). The framework will automatically discover them.</p>"},{"location":"config/evaluation/#schema","title":"Schema","text":"<p>The <code>EvaluationConfig</code> defines the structure for an evaluation configuration. Below are the available fields, categorized for clarity.</p>  Core Fields Test Configuration Advanced Configuration Caching Configuration Test Case Structure <p>These fields define the fundamental properties of the evaluation.</p> Field Type Required Description <code>name</code> <code>string</code> Yes A unique identifier for the evaluation. This name is used to reference the evaluation in commands and reports. <code>description</code> <code>string</code> No A brief, human-readable description of what the evaluation tests. <code>component_type</code> <code>string</code> No The type of component being evaluated. Must be one of: <code>\"agent\"</code>, <code>\"linear_workflow\"</code>, <code>\"custom_workflow\"</code>, <code>\"graph_workflow\"</code>, or <code>\"mcp_server\"</code>. <code>component_refs</code> <code>array</code> No A list of component names to evaluate. Used for testing multiple components with the same test cases. <code>component_config</code> <code>object</code> No Direct configuration of the component being tested (alternative to using <code>component_refs</code>). <p>These fields define the test cases and evaluation criteria.</p> Field Type Required Description <code>test_cases</code> <code>array</code> Yes A list of test cases to run against the component(s). Each test case contains input and expectations. <code>review_llm</code> <code>string</code> No The name of an LLM configuration to use for automated review of the component's output against expectations. <code>expected_schema</code> <code>object</code> No A JSON schema that the component's output is expected to conform to. Used for structured output validation. <p>These fields provide advanced customization options.</p> Field Type Required Description <code>run_agent</code> <code>function\\|string</code> No A custom function or filepath to a Python file for running the component. The file should contain a <code>run</code> function. If not provided, uses the built-in runner. <code>run_agent_kwargs</code> <code>object</code> No Additional keyword arguments to pass to the <code>run_agent</code> function beyond the input string. <p>These fields control result caching behavior.</p> Field Type Required Default Description <code>use_cache</code> <code>boolean</code> No <code>true</code> Whether to use cached results for test cases that have been evaluated before. <code>cache_ttl</code> <code>integer</code> No <code>3600</code> Time-to-live for cached results in seconds (default: 1 hour). <code>force_refresh</code> <code>boolean</code> No <code>false</code> Force re-execution of all test cases, bypassing cache. <code>evaluation_config_id</code> <code>string</code> No Auto-generated ID of the evaluation configuration (used for cache key generation). <p>Each test case in the <code>test_cases</code> array has the following structure:</p> Field Type Required Description <code>id</code> <code>string</code> No A unique identifier for the test case. Auto-generated UUID if not provided. <code>name</code> <code>string</code> No A user-friendly name for the test case (e.g., \"weather_planning_sf\"). <code>input</code> <code>string</code> Yes The user input message that will be fed to the component being evaluated. <code>output</code> <code>any</code> No Pre-recorded output for this test case. If not provided, the component will be run to generate output. <code>expectations</code> <code>array</code> Yes A list of string descriptions of what is expected from the output (e.g., \"The output contains temperature in Celsius\", \"The get_weather tool was called\")."},{"location":"config/evaluation/#configuration-examples","title":"Configuration Examples","text":"<p>Here are practical examples of evaluation configurations using the updated structure.</p> Single Agent EvaluationMultiple Agent EvaluationCustom Function EvaluationWorkflow EvaluationMCP Server EvaluationStructured Output with Schema Validation <p>An evaluation that tests a single weather agent's ability to provide temperature information.</p> <pre><code>{\n  \"name\": \"single_weather_agent_evaluation\",\n  \"type\": \"evaluation\",\n  \"component_type\": \"agent\",\n  \"component_refs\": [\n    \"Average Weather Agent\"\n  ],\n  \"review_llm\": null,\n  \"test_cases\": [\n    {\n      \"name\": \"weather_planning_sf\",\n      \"input\": \"What's the weather in San Francisco and create a plan for outdoor activities\",\n      \"expectations\": [\n        \"The response uses the weather_lookup tool to get San Francisco weather\",\n        \"The response provides temperature information\",\n        \"The response creates a structured plan based on weather conditions\",\n        \"The response uses planning tools to save the plan\"\n      ]\n    },\n    {\n      \"name\": \"weather_comparison\",\n      \"input\": \"Check the weather in London and Tokyo, then compare them\",\n      \"expectations\": [\n        \"The response uses weather_lookup for both London and Tokyo\",\n        \"The response provides temperature for both cities\",\n        \"The response compares the weather conditions between cities\",\n        \"The response is well-structured and informative\"\n      ]\n    }\n  ]\n}\n</code></pre> <p>An evaluation that tests multiple agents with the same test cases for comparison.</p> <pre><code>{\n  \"name\": \"weather_agents_evaluation\",\n  \"type\": \"evaluation\",\n  \"component_type\": \"agent\",\n  \"component_refs\": [\n    \"Good Weather Agent\",\n    \"Average Weather Agent\",\n    \"Poor Weather Agent\"\n  ],\n  \"review_llm\": null,\n  \"test_cases\": [\n    {\n      \"name\": \"weather_planning_sf\",\n      \"input\": \"What's the weather in San Francisco and create a plan for outdoor activities\",\n      \"expectations\": [\n        \"The response uses the weather_lookup tool to get San Francisco weather\",\n        \"The response provides temperature information\",\n        \"The response creates a structured plan based on weather conditions\",\n        \"The response uses planning tools to save the plan\"\n      ]\n    },\n    {\n      \"name\": \"comprehensive_travel\",\n      \"input\": \"Create a comprehensive travel plan based on weather in three cities\",\n      \"expectations\": [\n        \"The response uses weather tools to get weather data for multiple cities\",\n        \"The response uses planning tools to create and save a structured plan\",\n        \"The response provides detailed recommendations for all three cities\",\n        \"The response demonstrates coordination between weather and planning tools\"\n      ]\n    }\n  ],\n  \"metadata\": {\n    \"description\": \"Unified evaluation for all weather agents - tests good, average, and poor quality agents with the same test cases\",\n    \"expected_performance\": \"varied\",\n    \"tool_requirements\": [\"weather_lookup\", \"current_time\", \"create_plan\", \"save_plan\"]\n  }\n}\n</code></pre> <p>An evaluation that uses a custom function to run the component, allowing for specialized testing scenarios.</p> <pre><code>{\n  \"name\": \"function_weather_agents_evaluation\",\n  \"type\": \"evaluation\",\n  \"component_type\": \"agent\",\n  \"run_agent\": \"tests/fixtures/workspace/shared_configs/evaluation/run_function/test_weather_agent_function.py\",\n  \"run_agent_kwargs\": {},\n  \"review_llm\": null,\n  \"test_cases\": [\n    {\n      \"name\": \"weather_planning_sf_good\",\n      \"input\": \"What's the weather in San Francisco and create a plan for outdoor activities\",\n      \"expectations\": [\n        \"The response uses the weather_lookup tool to get San Francisco weather\",\n        \"The response provides temperature information\",\n        \"The response creates a structured plan based on weather conditions\",\n        \"The response uses planning tools to save the plan\"\n      ]\n    },\n    {\n      \"name\": \"weather_comparison_good\",\n      \"input\": \"Check the weather in London and Tokyo, then compare them\",\n      \"expectations\": [\n        \"The response uses weather_lookup for both London and Tokyo\",\n        \"The response provides temperature for both cities\",\n        \"The response compares the weather conditions between cities\",\n        \"The response is well-structured and informative\"\n      ]\n    }\n  ],\n  \"force_refresh\": true,\n  \"metadata\": {\n    \"description\": \"Function-based evaluation for weather agents - tests custom run function with different quality levels\",\n    \"evaluation_type\": \"run_function\",\n    \"quality_levels\": [\"good\", \"average\", \"poor\"]\n  }\n}\n</code></pre> <p>An evaluation that tests different types of workflows.</p> <pre><code>[\n  {\n    \"name\": \"weather_workflow_evaluation\",\n    \"type\": \"evaluation\",\n    \"component_type\": \"linear_workflow\",\n    \"component_refs\": [\n      \"test_weather_workflow\"\n    ],\n    \"review_llm\": null,\n    \"test_cases\": [\n      {\n        \"name\": \"weather_planning_sf\",\n        \"input\": \"What's the weather in San Francisco\",\n        \"expectations\": [\n          \"The first agent uses a tool to look up the weather in San Francisco\",\n          \"This weather information is relayed in detail to the second agent\",\n          \"The second agent creates a plan of what to wear based on this weather information\",\n          \"The plan is stored using a tool by the second agent\"\n        ]\n      }\n    ]\n  },\n  {\n    \"name\": \"weather_custom_workflow_evaluation\",\n    \"type\": \"evaluation\",\n    \"component_type\": \"custom_workflow\",\n    \"component_refs\": [\n      \"ExampleCustomWorkflow\"\n    ],\n    \"review_llm\": null,\n    \"test_cases\": [\n      {\n        \"name\": \"weather_planning_sf\",\n        \"input\": \"What's the weather in San Francisco\",\n        \"expectations\": [\n          \"The workflow runs successfully\",\n          \"The workflow creates a plan based on the weather conditions in San Francisco\"\n        ]\n      }\n    ]\n  },\n  {\n    \"name\": \"weather_graph_workflow_evaluation\",\n    \"type\": \"evaluation\",\n    \"component_type\": \"graph_workflow\",\n    \"component_refs\": [\n      \"Parallel Weather Graph Workflow\"\n    ],\n    \"review_llm\": null,\n    \"test_cases\": [\n      {\n        \"name\": \"weather_planning_sf\",\n        \"input\": \"What's the weather in San Francisco\",\n        \"expectations\": [\n          \"The workflow runs successfully\",\n          \"The workflow's fahrenheit agent outputs the temperature in fahrenheit\",\n          \"The workflow's celcius agent outputs the temperature in celcius\"\n        ]\n      }\n    ]\n  }\n]\n</code></pre> <p>An evaluation that tests MCP server functionality.</p> <pre><code>{\n  \"name\": \"weather_mcp_evaluation\",\n  \"type\": \"evaluation\",\n  \"component_type\": \"mcp_server\",\n  \"component_refs\": [\n    \"weather_server\"\n  ],\n  \"review_llm\": null,\n  \"test_cases\": [\n    {\n      \"name\": \"weather_planning_sf\",\n      \"input\": \"What's the weather in San Francisco\",\n      \"expectations\": [\n        \"The weather_lookup tool is called once with the input of San Francisco\",\n        \"The response from the tool provides temperature information\"\n      ]\n    }\n  ]\n}\n</code></pre> <p>An evaluation that validates structured output against a JSON schema.</p> <pre><code>{\n  \"name\": \"structured-weather-test\",\n  \"type\": \"evaluation\",\n  \"component_type\": \"agent\",\n  \"component_refs\": [\"Structured Output Weather Agent\"],\n  \"test_cases\": [\n    {\n      \"name\": \"london_weather\",\n      \"input\": \"What's the weather in London?\",\n      \"expectations\": [\n        \"The output contains temperature information in celsius\",\n        \"The output follows the required JSON structure\",\n        \"The output includes weather recommendations\"\n      ]\n    }\n  ],\n  \"review_llm\": \"anthropic_claude_3_haiku\",\n  \"expected_schema\": {\n    \"type\": \"object\",\n    \"properties\": {\n      \"weather_summary\": {\n        \"type\": \"string\",\n        \"description\": \"A brief summary of the weather conditions.\"\n      },\n      \"temperature\": {\n        \"type\": \"object\",\n        \"properties\": {\n          \"value\": {\n            \"type\": \"number\"\n          },\n          \"unit\": {\n            \"type\": \"string\",\n            \"enum\": [\"celsius\", \"fahrenheit\"]\n          }\n        },\n        \"required\": [\"value\", \"unit\"]\n      },\n      \"recommendations\": {\n        \"type\": \"array\",\n        \"items\": {\n          \"type\": \"string\"\n        },\n        \"description\": \"Recommendations based on the weather.\"\n      }\n    },\n    \"required\": [\"weather_summary\", \"temperature\", \"recommendations\"]\n  }\n}\n</code></pre>"},{"location":"config/evaluation/#usage-tips","title":"Usage Tips","text":""},{"location":"config/evaluation/#component-selection","title":"Component Selection","text":"<ul> <li>Use <code>component_refs</code> to test one or more existing components by name</li> <li>Use <code>component_config</code> to define a component configuration inline</li> <li>Use <code>component_type</code> to specify what type of component you're testing</li> </ul>"},{"location":"config/evaluation/#custom-run-functions","title":"Custom Run Functions","text":"<p>When using <code>run_agent</code> with a file path:</p> <ol> <li>The file should contain a <code>run</code> function that takes the input string as the first parameter</li> <li>Additional parameters can be passed via <code>run_agent_kwargs</code></li> <li>The function should return the component's output</li> </ol> <p>Example custom run function:</p> <pre><code># custom_runner.py\nasync def run(input_text: str, **kwargs) -&gt; str:\n    # Custom logic to run your component\n    # Return the component's output\n    return result\n</code></pre>"},{"location":"config/evaluation/#caching-behavior","title":"Caching Behavior","text":"<ul> <li>Set <code>use_cache: false</code> to always run fresh evaluations</li> <li>Use <code>force_refresh: true</code> to bypass cache for a single run</li> <li>Adjust <code>cache_ttl</code> to control how long results are cached</li> <li>The <code>evaluation_config_id</code> is used as part of the cache key</li> </ul>"},{"location":"config/evaluation/#test-case-design","title":"Test Case Design","text":"<ul> <li>Write clear, specific expectations that can be automatically evaluated</li> <li>Use descriptive <code>name</code> fields for test cases to make results easier to understand</li> <li>Include both positive expectations (what should happen) and negative ones (what shouldn't happen)</li> <li>Test edge cases and error conditions alongside happy path scenarios</li> </ul>"},{"location":"config/graph_workflow/","title":"Graph Workflow Configuration","text":"<p>Graph workflows provide a flexible way to execute components in a non-linear, dependency-based order. They are perfect for complex tasks that require conditional execution, parallel processing, or dynamic routing based on component outputs, such as \"run the data-validation agent, and if it passes, run both the analysis agent and the reporting agent in parallel.\"</p> <p>A graph workflow configuration is a JSON or YAML object with a <code>type</code> field set to <code>\"graph_workflow\"</code>.</p> <p>How It Works</p> <p>When you execute a graph workflow, the framework builds a dependency graph from the <code>nodes</code> and <code>edges</code> definitions. Components are executed when their dependencies are satisfied, allowing for parallel execution and conditional branching. The workflow continues until all reachable nodes have been processed or a terminal condition is met.</p>"},{"location":"config/graph_workflow/#schema","title":"Schema","text":"<p>The <code>GraphWorkflowConfig</code> defines the structure for a graph workflow.</p>  Core Fields Nodes Configuration Edges Configuration <p>These fields define the fundamental properties of the workflow.</p> Field Type Required Description <code>name</code> <code>string</code> Yes A unique identifier for the workflow. This name is used to run the workflow from the CLI or API. <code>description</code> <code>string</code> No A brief, human-readable description of what the workflow accomplishes. <code>nodes</code> <code>list[GraphWorkflowNode]</code> Yes A list of nodes (components) in the graph. See \"Nodes Configuration\" below for details. <code>edges</code> <code>list[GraphWorkflowEdge]</code> Yes A list of edges defining dependencies between nodes. See \"Edges Configuration\" below for details. <code>include_history</code> <code>boolean</code> <code>None</code> If set, overrides the <code>include_history</code> setting for all agents in the workflow, forcing them all to either save or discard history. <code>include_logging</code> <code>boolean</code> <code>None</code> If set, overrides the <code>include_logging</code> setting for all agents in the workflow, forcing them all to either enable or disable logging. <p>Each node in the graph represents a component to execute. Nodes are defined as objects with the following structure:</p> Field Type Required Description <code>node_id</code> <code>string</code> Yes A unique identifier for this node within the graph. Used to reference the node in edges. <code>name</code> <code>string</code> Yes The name of the component to execute (must match an existing agent or workflow configuration). <code>type</code> <code>string</code> Yes The type of component. Currently only <code>\"agent\"</code> is supported. <pre><code>\"nodes\": [\n  {\n    \"node_id\": \"validation\",\n    \"name\": \"data-validator-agent\",\n    \"type\": \"agent\"\n  },\n  {\n    \"node_id\": \"analysis\",\n    \"name\": \"analysis-agent\",\n    \"type\": \"agent\"\n  }\n]\n</code></pre> <p>Edges define the dependencies and execution order between nodes. Each edge specifies that one node must complete before another can start.</p> Field Type Required Description <code>from</code> <code>string</code> Yes The <code>node_id</code> of the source node (must complete before the target can start). <code>to</code> <code>string</code> Yes The <code>node_id</code> of the target node (will receive input from the source node). <pre><code>\"edges\": [\n  {\n    \"from\": \"validation\",\n    \"to\": \"analysis\"\n  },\n  {\n    \"from\": \"validation\",\n    \"to\": \"reporting\"\n  }\n]\n</code></pre> <p>Data Flow: When a node completes, its output is passed as input to all nodes that depend on it. If a node has multiple predecessors, their outputs are concatenated together as the input.</p>"},{"location":"config/graph_workflow/#configuration-examples","title":"Configuration Examples","text":"Simple Parallel ProcessingDiamond Pattern with Convergence <p>This example shows a workflow where data validation runs first, then both analysis and reporting run in parallel.</p> <pre><code>{\n  \"type\": \"graph_workflow\",\n  \"name\": \"parallel-data-pipeline\",\n  \"description\": \"Validates data, then runs analysis and reporting in parallel.\",\n  \"nodes\": [\n    {\n      \"node_id\": \"validate\",\n      \"name\": \"data-validator-agent\",\n      \"type\": \"agent\"\n    },\n    {\n      \"node_id\": \"analyze\",\n      \"name\": \"analysis-agent\",\n      \"type\": \"agent\"\n    },\n    {\n      \"node_id\": \"report\",\n      \"name\": \"reporting-agent\",\n      \"type\": \"agent\"\n    }\n  ],\n  \"edges\": [\n    {\n      \"from\": \"validate\",\n      \"to\": \"analyze\"\n    },\n    {\n      \"from\": \"validate\",\n      \"to\": \"report\"\n    }\n  ]\n}\n</code></pre> <p>This example demonstrates a diamond-shaped workflow where processing splits into parallel paths and then converges.</p> <pre><code>{\n  \"type\": \"graph_workflow\",\n  \"name\": \"diamond-processing-flow\",\n  \"description\": \"Splits processing into parallel paths and converges the results.\",\n  \"nodes\": [\n    {\n      \"node_id\": \"input\",\n      \"name\": \"input-processor-agent\",\n      \"type\": \"agent\"\n    },\n    {\n      \"node_id\": \"path_a\",\n      \"name\": \"path-a-agent\",\n      \"type\": \"agent\"\n    },\n    {\n      \"node_id\": \"path_b\",\n      \"name\": \"path-b-agent\",\n      \"type\": \"agent\"\n    },\n    {\n      \"node_id\": \"merge\",\n      \"name\": \"merge-results-agent\",\n      \"type\": \"agent\"\n    }\n  ],\n  \"edges\": [\n    {\n      \"from\": \"input\",\n      \"to\": \"path_a\"\n    },\n    {\n      \"from\": \"input\",\n      \"to\": \"path_b\"\n    },\n    {\n      \"from\": \"path_a\",\n      \"to\": \"merge\"\n    },\n    {\n      \"from\": \"path_b\",\n      \"to\": \"merge\"\n    }\n  ]\n}\n</code></pre>"},{"location":"config/linear_workflow/","title":"Linear Workflow Configuration","text":"<p>Linear workflows provide a straightforward way to execute a series of components in a predefined, sequential order. They are perfect for tasks that follow a linear process, such as \"first run the data-ingestion agent, then run the analysis agent.\"</p> <p>A linear workflow configuration is a JSON or YAML object with a <code>type</code> field set to <code>\"linear_workflow\"</code>.</p> <p>How It Works</p> <p>When you execute a linear workflow, the framework iterates through the <code>steps</code> list in order. The output from one step is passed as the input to the next, allowing you to chain components together to create a processing pipeline.</p>"},{"location":"config/linear_workflow/#schema","title":"Schema","text":"<p>The <code>WorkflowConfig</code> defines the structure for a linear workflow.</p>  Core Fields Steps Configuration <p>These fields define the fundamental properties of the workflow.</p> Field Type Required Description <code>name</code> <code>string</code> Yes A unique identifier for the workflow. This name is used to run the workflow from the CLI or API. <code>description</code> <code>string</code> No A brief, human-readable description of what the workflow accomplishes. <code>steps</code> <code>list[string or object]</code> Yes An ordered list of the components to execute. See \"Steps Configuration\" below for details. <code>include_history</code> <code>boolean</code> <code>None</code> If set, overrides the <code>include_history</code> setting for all agents in the workflow, forcing them all to either save or discard history. <p>The core of a linear workflow is the <code>steps</code> list. Each item in the list can be either a simple string (the component name) or a detailed object.</p> <p>Simple Step (by Name)</p> <p>The easiest way to define a step is to provide the <code>name</code> of the component.</p> <pre><code>\"steps\": [\"fetch-data-agent\", \"process-data-agent\"]\n</code></pre> <p>Detailed Step (by Object)</p> <p>For more clarity, you can specify the component <code>type</code> along with its <code>name</code>. This is useful if you have components of different types with the same name.</p> <pre><code>\"steps\": [\n  { \"name\": \"fetch-data-agent\", \"type\": \"agent\" },\n  { \"name\": \"analysis-pipeline\", \"type\": \"linear_workflow\" }\n]\n</code></pre> <p>The <code>type</code> can be <code>\"agent\"</code>, <code>\"linear_workflow\"</code>, or <code>\"custom_workflow\"</code>.</p>"},{"location":"config/linear_workflow/#configuration-examples","title":"Configuration Examples","text":"Simple PipelineWorkflow with History OverrideNested Workflow <p>This example defines a two-step workflow for processing customer feedback.</p> <pre><code>{\n  \"type\": \"linear_workflow\",\n  \"name\": \"customer-feedback-pipeline\",\n  \"description\": \"Fetches customer feedback, analyzes sentiment, and saves the result.\",\n  \"steps\": [\"fetch-feedback-agent\", \"analyze-sentiment-agent\"]\n}\n</code></pre> <p>This workflow forces all agents within it to maintain conversation history, which is useful for debugging or creating a continuous conversational experience across multiple agents.</p> <pre><code>{\n  \"type\": \"linear_workflow\",\n  \"name\": \"stateful-support-flow\",\n  \"description\": \"A multi-agent support flow that remembers the conversation.\",\n  \"include_history\": true,\n  \"steps\": [\"greeting-agent\", \"support-agent\", \"followup-agent\"]\n}\n</code></pre> <p>This example shows how a linear workflow can include another workflow as one of its steps.</p> <pre><code>{\n  \"type\": \"linear_workflow\",\n  \"name\": \"daily-reporting-process\",\n  \"description\": \"A top-level workflow that orchestrates other workflows and agents.\",\n  \"steps\": [\n    { \"name\": \"ingestion-workflow\", \"type\": \"linear_workflow\" },\n    { \"name\": \"analysis-agent\", \"type\": \"agent\" },\n    { \"name\": \"distribution-workflow\", \"type\": \"custom_workflow\" }\n  ]\n}\n</code></pre>"},{"location":"config/llm/","title":"LLM Configuration","text":"<p>LLM (Large Language Model) configurations are reusable components that define the settings for a specific model from a particular provider. By defining LLMs centrally, you can easily share them across multiple agents and manage your model settings in one place.</p> <p>An LLM configuration is a JSON or YAML object with a <code>type</code> field set to <code>\"llm\"</code>.</p> <p>Configuration Location</p> <p>LLM configurations can be placed in any directory specified in your project's <code>.aurite</code> file (e.g., <code>config/</code>, <code>shared/llms/</code>). The framework will automatically discover them.</p>"},{"location":"config/llm/#schema","title":"Schema","text":"<p>The <code>LLMConfig</code> defines the structure for an LLM configuration. Below are the available fields, categorized for clarity.</p>  Core Fields Common Parameters Provider-Specific Fields <p>These fields are essential for defining the identity and source of the model.</p> Field Type Required Description <code>name</code> <code>string</code> Yes A unique identifier for the LLM configuration. This name is used in an agent's <code>llm_config_id</code> field to link to this configuration. <code>provider</code> <code>string</code> Yes The name of the LLM provider, corresponding to a provider supported by the underlying model library (e.g., LiteLLM). Common values include <code>openai</code>, <code>anthropic</code>, <code>gemini</code>, <code>groq</code>. <code>model</code> <code>string</code> Yes The specific model name as recognized by the provider (e.g., <code>gpt-4-1106-preview</code>). <code>description</code> <code>string</code> No A brief, human-readable description of the LLM configuration. <p>These are standard LLM parameters that can be set as defaults for this configuration. Agents can override these values.</p> Field Type Default Description <code>temperature</code> <code>float</code> <code>None</code> The sampling temperature to use (0-2). Higher values (e.g., 0.8) make output more random; lower values (e.g., 0.2) make it more deterministic. <code>max_tokens</code> <code>integer</code> <code>None</code> The maximum number of tokens to generate in the completion. <code>default_system_prompt</code> <code>string</code> <code>None</code> A default system prompt for this LLM. An agent's <code>system_prompt</code> will override this value. <p>These fields are used for connecting to specific APIs, especially for self-hosted or non-standard endpoints.</p> Field Type Default Description <code>api_base</code> <code>string</code> <code>None</code> The base URL for the API endpoint. Commonly used for local models (e.g., <code>http://localhost:8000/v1</code>) or custom provider endpoints. <code>api_key_env_var</code> <code>string</code> <code>None</code> The environment variable name for the API key if not using a default (e.g., <code>ANTHROPIC_API_KEY</code>). <code>api_version</code> <code>string</code> <code>None</code> The API version string required by some providers (e.g., Azure OpenAI)."},{"location":"config/llm/#agent-overrides","title":"Agent Overrides","text":"<p>While <code>LLMConfig</code> provides a central place for model settings, individual agents can override them at runtime using the same configuration variables inserted directly into the AgentConfig. This provides flexibility for agent-specific needs.</p> <p>See the Agent Configuration documentation for more details on how to apply these overrides.</p>"},{"location":"config/llm/#configuration-examples","title":"Configuration Examples","text":"<p>Here are some practical examples of LLM configurations for different providers.</p> OpenAIAnthropicLocal (Ollama) <pre><code>{\n  \"type\": \"llm\",\n  \"name\": \"gpt-4-turbo\",\n  \"description\": \"Configuration for OpenAI's GPT-4 Turbo model.\",\n  \"provider\": \"openai\",\n  \"model\": \"gpt-4-1106-preview\",\n  \"temperature\": 0.5,\n  \"max_tokens\": 4096\n}\n</code></pre> <pre><code>{\n  \"type\": \"llm\",\n  \"name\": \"claude-3-sonnet\",\n  \"description\": \"Configuration for Anthropic's Claude 3 Sonnet model.\",\n  \"provider\": \"anthropic\",\n  \"model\": \"claude-3-sonnet-20240229\",\n  \"temperature\": 0.7,\n  \"default_system_prompt\": \"You are a helpful and friendly assistant.\"\n}\n</code></pre> <p>This example configures a local Llama 3 model served by Ollama.</p> <pre><code>{\n  \"type\": \"llm\",\n  \"name\": \"local-llama3\",\n  \"description\": \"Configuration for a local Llama 3 model served by Ollama.\",\n  \"provider\": \"ollama\",\n  \"model\": \"llama3\",\n  \"api_base\": \"http://localhost:11434\",\n  \"temperature\": 0.7\n}\n</code></pre>"},{"location":"config/mcp_server/","title":"MCP Server Configuration","text":"<p>MCP (Model-Context-Protocol) Servers are the backbone of an agent's capabilities. They are responsible for providing the tools, prompts, and resources that an agent can use to perform tasks. Each <code>mcp_server</code> configuration tells the framework how to connect to and interact with a specific server.</p> <p>An MCP server configuration is a JSON or YAML object with a <code>type</code> field set to <code>\"mcp_server\"</code>.</p> <p>Configuration Location</p> <p>MCP Server configurations can be placed in any directory specified in your project's <code>.aurite</code> file (e.g., <code>config/mcp_servers/</code>). The framework will automatically discover them.</p>"},{"location":"config/mcp_server/#schema","title":"Schema","text":"<p>Transport Types</p> <p>The <code>ClientConfig</code> model defines the structure for an MCP server configuration. There are three main transport types: <code>stdio</code>, <code>http_stream</code>, and <code>local</code>. Each transport type has its own required fields. The framework will infer the transport type based on the fields you provide.</p>  Core Fields Transport Types Advanced Fields <p>These fields define the fundamental properties of the server.</p> Field Type Required Description <code>name</code> <code>string</code> Yes A unique identifier for the MCP server. This name is used in an agent's <code>mcp_servers</code> list and as a prefix for its components (e.g., <code>my_server-tool_name</code>). <code>description</code> <code>string</code> No A brief, human-readable description of the server's purpose. <code>capabilities</code> <code>list[string]</code> Yes A list of the types of components this server provides. Accepted values are <code>\"tools\"</code>, <code>\"prompts\"</code>, and <code>\"resources\"</code>. <p>You must configure one of the following transport types. The framework will automatically infer the <code>transport_type</code> based on the fields you provide.</p> <p><code>stdio</code></p> <p>This is the most common transport for running local Python scripts as servers.</p> Field Type Required Description <code>server_path</code> <code>string</code> or <code>Path</code> Yes The path to the Python script that runs the MCP server. This path can be relative to the <code>.aurite</code> file of its context. <p><code>http_stream</code></p> <p>This transport is used for connecting to servers that are already running and accessible via an HTTP endpoint.</p> Field Type Required Description <code>http_endpoint</code> <code>string</code> Yes The full URL of the server's streaming endpoint. <code>headers</code> <code>dict[str, str]</code> No A dictionary of HTTP headers to include in the request (e.g., for authentication). <p><code>local</code></p> <p>This transport is for running any executable command as a server.</p> Field Type Required Description <code>command</code> <code>string</code> Yes The command or executable to run. <code>args</code> <code>list[string]</code> No A list of arguments to pass to the command. <p>These fields provide fine-grained control over the server's behavior.</p> Field Type Default Description <code>timeout</code> <code>float</code> <code>10.0</code> The default timeout in seconds for operations (like tool calls) sent to this server. <code>registration_timeout</code> <code>float</code> <code>30.0</code> The timeout in seconds for registering this server. <code>exclude</code> <code>list[string]</code> <code>None</code> A list of component names (tools, prompts, or resources) to exclude from this server's offerings. <code>roots</code> <code>list[object]</code> <code>[]</code> A list of root objects describing the server's capabilities. This is typically auto-discovered and rarely needs to be set manually."},{"location":"config/mcp_server/#configuration-examples","title":"Configuration Examples","text":"<p>Here are some practical examples for each transport type.</p> Stdio TransportHTTP Stream TransportLocal Command Transport <p>This example runs a local Python script as an MCP server.</p> <pre><code>{\n  \"type\": \"mcp_server\",\n  \"name\": \"weather-server\",\n  \"description\": \"Provides weather forecast tools.\",\n  \"server_path\": \"mcp_servers/weather_server.py\",\n  \"capabilities\": [\"tools\"]\n}\n</code></pre> <p>This example connects to a custom running service. Note the use of an environment variable in the header for authentication.</p> <pre><code>{\n  \"type\": \"mcp_server\",\n  \"name\": \"my-remote-service\",\n  \"description\": \"Connects to a custom remote service.\",\n  \"http_endpoint\": \"https://my-custom-service.com/mcp\",\n  \"headers\": {\n    \"X-API-Key\": \"{MY_SERVICE_API_KEY}\"\n  },\n  \"capabilities\": [\"tools\", \"resources\"]\n}\n</code></pre> <p>This example runs a pre-compiled binary as a server.</p> <pre><code>{\n  \"type\": \"mcp_server\",\n  \"name\": \"my-custom-binary-server\",\n  \"description\": \"A server running from a custom binary.\",\n  \"command\": \"bin/my_server\",\n  \"args\": [\"--port\", \"8080\"],\n  \"capabilities\": [\"tools\"]\n}\n</code></pre>"},{"location":"config/projects_and_workspaces/","title":"Projects and Workspaces","text":"<p>The Aurite framework uses a powerful hierarchical configuration system built on two core concepts: Projects and Workspaces. This system is driven by a special anchor file named <code>.aurite</code>, which tells the framework how to discover and prioritize configurations.</p> <p>The <code>.aurite</code> Anchor File</p> <p>The framework finds configurations by searching upwards from your current directory for <code>.aurite</code> files. This file marks a directory as a Project or a Workspace root and specifies which subdirectories contain configuration files.</p>"},{"location":"config/projects_and_workspaces/#configuration-contexts","title":"Configuration Contexts","text":"<p>Your configurations are organized into contexts, allowing for both separation of concerns and sharing of common components.</p>  Project Workspace <p>A Project is a self-contained directory for a specific task or set of related tasks. It's the most common organizational unit.</p> <p>To define a project, create an <code>.aurite</code> file in its root directory.</p> <p><code>.aurite</code> File Fields:</p> Field Type Required Description <code>type</code> <code>string</code> Yes Must be set to <code>\"project\"</code>. <code>include_configs</code> <code>list[string]</code> Yes A list of directories (relative to the <code>.aurite</code> file) where component configurations are stored. <p>Example <code>.aurite</code>: <pre><code># .aurite\n[aurite]\ntype = \"project\"\ninclude_configs = [\"config\", \"shared_components\"]\n</code></pre></p> <p>A Workspace is a higher-level container that can manage multiple projects and shared configurations.</p> <p><code>.aurite</code> File Fields:</p> Field Type Required Description <code>type</code> <code>string</code> Yes Must be set to <code>\"workspace\"</code>. <code>include_configs</code> <code>list[string]</code> Yes A list of directories containing shared, workspace-level configurations. <code>projects</code> <code>list[string]</code> No An optional list of subdirectories that are individual projects. <p>Example <code>.aurite</code>: <pre><code># .aurite\n[aurite]\ntype = \"workspace\"\nprojects = [\"project-a\", \"project-b\"]\ninclude_configs = [\"workspace_config\"]\n</code></pre></p>"},{"location":"config/projects_and_workspaces/#priority-resolution","title":"Priority Resolution","text":"<p>When the framework looks for a component, it searches contexts in a specific order. A component found in a higher-priority context overrides one with the same name from a lower-priority context.</p> <p>The priority is as follows, from highest to lowest:</p> <ol> <li>In-Memory: Programmatically registered components (highest priority).</li> <li>Project Level: Configurations from the current project's <code>include_configs</code> directories.</li> <li>Workspace Level: Configurations from the parent workspace's <code>include_configs</code> directories.</li> <li>Other Projects: Configurations from other projects within the same workspace.</li> </ol> <p>Overriding Example</p> <p>You could define a <code>standard-llm</code> at the workspace level, and a <code>standard-llm</code> at the project level. The framework automatically picks the most specific one based on your current directory.</p>"},{"location":"config/projects_and_workspaces/#path-resolution","title":"Path Resolution","text":"<p>When a component configuration references a local file (e.g., <code>server_path</code> in an MCP server), you can use a relative path.</p> <p>All relative paths are resolved from the location of the <code>.aurite</code> file that defines their context.</p> <p>This makes your configurations portable and easy to share.</p> <p>Path Resolution Example</p> <p>Imagine the following setup:</p> <ul> <li>Your workspace is at <code>/path/to/my-workspace/</code>.</li> <li>Its <code>.aurite</code> file is at <code>/path/to/my-workspace/.aurite</code>.</li> <li>A shared server is defined in <code>/path/to/my-workspace/workspace-config/servers.json</code>.</li> <li>The server's <code>server_path</code> is set to <code>mcp_servers/shared_server.py</code>.</li> </ul> <p>The framework will correctly resolve the full path to <code>/path/to/my-workspace/mcp_servers/shared_server.py</code>.</p>"},{"location":"config/projects_and_workspaces/#component-types","title":"Component Types","text":"<p>Aurite supports several core component types, each with its own configuration and purpose. Learn more about each type:</p> <ul> <li>Agent</li> <li>LLM</li> <li>MCP Server</li> <li>Linear Workflow</li> <li>Custom Workflow</li> </ul> <p>Explore these guides to understand how to configure and use each component within your projects and workspaces.</p>"},{"location":"docker/","title":"Aurite Agents Framework - Docker Image","text":"<p>A production-ready Docker image for the Aurite Agents Framework - a powerful Python framework for building, testing, and running AI agents with Model Context Protocol (MCP) integration.</p>"},{"location":"docker/#quick-start","title":"\ud83d\ude80 Quick Start","text":""},{"location":"docker/#basic-usage","title":"Basic Usage","text":"<pre><code># Run with your existing project\ndocker run -v $(pwd):/app/project -p 8000:8000 -e API_KEY=your-secure-key aurite/aurite-agents\n\n# Auto-initialize a new project\ndocker run -v $(pwd):/app/project -p 8000:8000 -e API_KEY=your-secure-key -e AURITE_AUTO_INIT=true aurite/aurite-agents\n</code></pre>"},{"location":"docker/#with-docker-compose","title":"With Docker Compose","text":"<ol> <li>Download the example configuration:</li> </ol> <pre><code>curl -O https://raw.githubusercontent.com/Aurite-ai/aurite-agents/main/docker-compose.example.yml\nmv docker-compose.example.yml docker-compose.yml\n</code></pre> <ol> <li>Create your environment file:</li> </ol> <pre><code>cat &gt; .env &lt;&lt; EOF\nAPI_KEY=your-secure-api-key-here\nOPENAI_API_KEY=your-openai-key\nANTHROPIC_API_KEY=your-anthropic-key\nEOF\n</code></pre> <ol> <li>Start the services: <pre><code>docker compose up\n</code></pre></li> </ol>"},{"location":"docker/#environment-variables","title":"\ud83d\udccb Environment Variables","text":""},{"location":"docker/#required","title":"Required","text":"Variable Description Example <code>API_KEY</code> Secure API key for authentication <code>your-secure-key-123</code>"},{"location":"docker/#optional-configuration","title":"Optional Configuration","text":"Variable Default Description <code>AURITE_AUTO_INIT</code> <code>false</code> Auto-initialize project if no <code>.aurite</code> file found <code>AURITE_ENABLE_DB</code> <code>false</code> Enable database persistence <code>AURITE_DB_TYPE</code> <code>sqlite</code> Database type: <code>sqlite</code> or <code>postgres</code> <code>AURITE_DB_PATH</code> <code>/app/project/.aurite_db/aurite.db</code> SQLite database path <code>LOG_LEVEL</code> <code>INFO</code> Logging level: <code>DEBUG</code>, <code>INFO</code>, <code>WARN</code>, <code>ERROR</code>"},{"location":"docker/#llm-provider-keys","title":"LLM Provider Keys","text":"<p>Pass through your LLM provider API keys:</p> <pre><code>-e OPENAI_API_KEY=your-key \\\n-e ANTHROPIC_API_KEY=your-key \\\n-e GEMINI_API_KEY=your-key \\\n-e AZURE_API_KEY=your-key\n</code></pre>"},{"location":"docker/#postgresql-configuration","title":"PostgreSQL Configuration","text":"<p>For production deployments with PostgreSQL:</p> <pre><code>-e AURITE_ENABLE_DB=true \\\n-e AURITE_DB_TYPE=postgres \\\n-e AURITE_DB_HOST=postgres \\\n-e AURITE_DB_USER=aurite_user \\\n-e AURITE_DB_PASSWORD=secure_password \\\n-e AURITE_DB_NAME=aurite_db\n</code></pre>"},{"location":"docker/#usage-patterns","title":"\ud83c\udfd7\ufe0f Usage Patterns","text":""},{"location":"docker/#1-existing-project","title":"1. Existing Project","text":"<p>If you have an existing Aurite project with a <code>.aurite</code> file:</p> <pre><code>docker run -d \\\n  --name aurite-agents \\\n  -v /path/to/your/project:/app/project \\\n  -p 8000:8000 \\\n  -e API_KEY=your-secure-key \\\n  -e OPENAI_API_KEY=your-openai-key \\\n  aurite/aurite-agents\n</code></pre>"},{"location":"docker/#2-new-project-auto-initialize","title":"2. New Project (Auto-Initialize)","text":"<p>To create a new project automatically:</p> <pre><code>docker run -d \\\n  --name aurite-agents \\\n  -v /path/to/empty/directory:/app/project \\\n  -p 8000:8000 \\\n  -e API_KEY=your-secure-key \\\n  -e AURITE_AUTO_INIT=true \\\n  aurite/aurite-agents\n</code></pre>"},{"location":"docker/#3-production-setup-with-postgresql","title":"3. Production Setup with PostgreSQL","text":"<pre><code>version: \"3.8\"\nservices:\n  postgres:\n    image: postgres:15-alpine\n    environment:\n      POSTGRES_USER: aurite_user\n      POSTGRES_PASSWORD: secure_password\n      POSTGRES_DB: aurite_db\n    volumes:\n      - postgres_data:/var/lib/postgresql/data\n\n  aurite:\n    image: aurite/aurite-agents:latest\n    depends_on:\n      - postgres\n    environment:\n      - API_KEY=your-secure-key\n      - AURITE_ENABLE_DB=true\n      - AURITE_DB_TYPE=postgres\n      - AURITE_DB_HOST=postgres\n      - AURITE_DB_USER=aurite_user\n      - AURITE_DB_PASSWORD=secure_password\n      - AURITE_DB_NAME=aurite_db\n      - OPENAI_API_KEY=your-openai-key\n    volumes:\n      - ./project:/app/project\n    ports:\n      - \"8000:8000\"\n\nvolumes:\n  postgres_data:\n</code></pre>"},{"location":"docker/#cli-usage","title":"\ud83d\udd27 CLI Usage","text":"<p>The container provides full access to the Aurite CLI through the <code>aurite</code> command:</p> <pre><code># View all available commands\ndocker run --rm -v $(pwd):/app/project -e API_KEY=your-key aurite/aurite-agents aurite --help\n\n# List available components\ndocker run --rm -v $(pwd):/app/project -e API_KEY=your-key aurite/aurite-agents aurite list\n\n# Show specific component configuration\ndocker run --rm -v $(pwd):/app/project -e API_KEY=your-key aurite/aurite-agents aurite show agent my-agent\n\n# Run an agent\ndocker run --rm -v $(pwd):/app/project -e API_KEY=your-key aurite/aurite-agents aurite run my-agent\n\n# Initialize a new project interactively\ndocker run -it --rm -v $(pwd):/app/project -e API_KEY=your-key aurite/aurite-agents aurite init\n\n# Interactive shell for debugging\ndocker run -it --rm -v $(pwd):/app/project -e API_KEY=your-key aurite/aurite-agents bash\n</code></pre>"},{"location":"docker/#available-cli-commands","title":"Available CLI Commands","text":"<p>The container supports all Aurite CLI commands:</p> <ul> <li><code>init</code> - Initialize new projects or workspaces</li> <li><code>list</code> - List components by type</li> <li><code>show</code> - Display component configurations</li> <li><code>run</code> - Execute agents or workflows</li> <li><code>api</code> - Start the API server (default)</li> <li><code>studio</code> - Start the web interface</li> <li><code>edit</code> - Launch the configuration editor TUI</li> <li><code>migrate</code> - Database migration utilities</li> <li><code>export</code> - Export configurations to database</li> </ul>"},{"location":"docker/#api-access","title":"\ud83c\udf10 API Access","text":"<p>Once running, the API is available at:</p> <ul> <li>Health Check: <code>http://localhost:8000/health</code></li> <li>API Documentation: <code>http://localhost:8000/docs</code></li> <li>OpenAPI Spec: <code>http://localhost:8000/openapi.json</code></li> </ul>"},{"location":"docker/#volume-mounts","title":"\ud83d\udcc1 Volume Mounts","text":""},{"location":"docker/#project-directory","title":"Project Directory","text":"<p>Mount your project directory to <code>/app/project</code>:</p> <pre><code>-v /path/to/your/project:/app/project\n</code></pre> <p>The container will search for <code>.aurite</code> files starting from this directory and walking up the directory tree.</p>"},{"location":"docker/#cache-directory","title":"Cache Directory","text":"<p>Optionally mount a cache directory for better performance:</p> <pre><code>-v aurite_cache:/app/cache\n</code></pre>"},{"location":"docker/#security","title":"\ud83d\udd12 Security","text":"<ul> <li>Runs as non-root user (<code>appuser</code>, UID 1000)</li> <li>No default API keys included</li> <li>Secure defaults for all configurations</li> <li>Health checks included for container orchestration</li> </ul>"},{"location":"docker/#image-tags","title":"\ud83c\udff7\ufe0f Image Tags","text":"Tag Description Use Case <code>latest</code> Latest stable release Production <code>0.3.28</code> Specific version Production (pinned) <code>0.3.28-dev</code> Development build Testing"},{"location":"docker/#troubleshooting","title":"\ud83d\udd0d Troubleshooting","text":""},{"location":"docker/#container-wont-start","title":"Container Won't Start","text":"<ol> <li>Check API_KEY is set:</li> </ol> <pre><code>docker logs &lt;container-name&gt;\n</code></pre> <ol> <li>Verify project structure: <pre><code>docker run --rm -v $(pwd):/app/project aurite/aurite-agents ls -la /app/project\n</code></pre></li> </ol>"},{"location":"docker/#database-connection-issues","title":"Database Connection Issues","text":"<ol> <li> <p>PostgreSQL not ready:</p> </li> <li> <p>The container waits for PostgreSQL to be ready</p> </li> <li>Check PostgreSQL container logs</li> <li> <p>Verify network connectivity</p> </li> <li> <p>SQLite permissions:</p> </li> <li>Ensure the mounted directory is writable</li> <li>Check file permissions on the host</li> </ol>"},{"location":"docker/#health-check-failures","title":"Health Check Failures","text":"<p>The container includes health checks that verify the API server is responding:</p> <pre><code># Check health status\ndocker inspect --format='{{.State.Health.Status}}' &lt;container-name&gt;\n\n# View health check logs\ndocker inspect --format='{{range .State.Health.Log}}{{.Output}}{{end}}' &lt;container-name&gt;\n</code></pre>"},{"location":"docker/#documentation","title":"\ud83d\udcda Documentation","text":"<ul> <li>GitHub Repository: https://github.com/Aurite-ai/aurite-agents</li> <li>Documentation: https://github.com/Aurite-ai/aurite-agents/blob/main/README.md</li> <li>Examples: https://github.com/Aurite-ai/aurite-agents/tree/main/docs/getting-started/tutorials</li> </ul>"},{"location":"docker/#architecture","title":"\ud83c\udfd7\ufe0f Architecture","text":"<p>This image is built with:</p> <ul> <li>Base: Python 3.12 slim</li> <li>Platforms: linux/amd64, linux/arm64</li> <li>Size: Optimized multi-stage build</li> <li>Security: Non-root user, minimal attack surface</li> </ul>"},{"location":"docker/#license","title":"\ud83d\udcc4 License","text":"<p>MIT License - see the LICENSE file for details.</p>"},{"location":"docker/#support","title":"\ud83e\udd1d Support","text":"<ul> <li>Issues: https://github.com/Aurite-ai/aurite-agents/issues</li> <li>Discussions: https://github.com/Aurite-ai/aurite-agents/discussions</li> <li>Email: hello@aurite.ai</li> </ul> <p>Built with \u2764\ufe0f by the Aurite AI team</p>"},{"location":"docker/TESTING/","title":"Docker Container Testing Guide","text":"<p>This guide explains how to test the Aurite Agents Docker container during development and before publishing to DockerHub.</p>"},{"location":"docker/TESTING/#quick-test","title":"Quick Test","text":"<p>To build and test the container locally without publishing:</p> <pre><code>./scripts/docker/build_and_publish.sh --build-only\n</code></pre> <p>This will:</p> <ol> <li>Build the Docker image locally (linux/amd64 only for speed)</li> <li>Run automated tests including health checks</li> <li>Test auto-initialization functionality</li> <li>Provide feedback on the build success</li> <li>Show you the command to publish if tests pass</li> </ol>"},{"location":"docker/TESTING/#container-management-system","title":"Container Management System","text":"<p>The container uses an intelligent entrypoint script (<code>docker-entrypoint.sh</code>) that handles:</p>"},{"location":"docker/TESTING/#project-detection","title":"Project Detection","text":"<ul> <li>Searches for <code>.aurite</code> files in the mounted directory and parent directories</li> <li>Uses the same upward search logic as the ConfigManager</li> <li>Provides clear feedback about project status</li> </ul>"},{"location":"docker/TESTING/#auto-initialization","title":"Auto-Initialization","text":"<ul> <li>Creates new projects when <code>AURITE_AUTO_INIT=true</code></li> <li>Falls back to manual project structure creation if CLI fails</li> <li>Creates proper <code>.aurite</code> configuration and sample files</li> <li>Only works in empty directories for safety</li> </ul>"},{"location":"docker/TESTING/#cli-command-handling","title":"CLI Command Handling","text":"<ul> <li>Routes <code>aurite</code> commands through the Python module system</li> <li>Handles all CLI commands: <code>init</code>, <code>list</code>, <code>show</code>, <code>run</code>, <code>api</code>, etc.</li> <li>Provides proper error handling and logging</li> </ul>"},{"location":"docker/TESTING/#testing-workflow","title":"Testing Workflow","text":""},{"location":"docker/TESTING/#1-build-and-test-locally","title":"1. Build and Test Locally","text":"<pre><code># Test current version from pyproject.toml\n./scripts/docker/build_and_publish.sh --build-only\n\n# Test specific version\n./scripts/docker/build_and_publish.sh 0.3.28 --build-only\n</code></pre>"},{"location":"docker/TESTING/#2-manual-testing-optional","title":"2. Manual Testing (Optional)","text":"<p>After the automated tests pass, you can manually test the container:</p> <pre><code># Start the container\ndocker run -d --name aurite-test \\\n  -p 8000:8000 \\\n  -e API_KEY=test-key \\\n  -e AURITE_AUTO_INIT=true \\\n  aurite/aurite-agents:0.3.28\n\n# Check health\ncurl http://localhost:8000/health\n\n# View logs\ndocker logs aurite-test\n\n# Test API docs\nopen http://localhost:8000/docs\n\n# Clean up\ndocker stop aurite-test\ndocker rm aurite-test\n</code></pre>"},{"location":"docker/TESTING/#3-publish-after-testing","title":"3. Publish After Testing","text":"<p>Once you're satisfied with the tests:</p> <pre><code># Publish specific version\n./scripts/docker/build_and_publish.sh 0.3.28 --push\n\n# Publish as latest (for stable releases)\n./scripts/docker/build_and_publish.sh 0.3.28 --push --latest\n</code></pre>"},{"location":"docker/TESTING/#what-gets-tested","title":"What Gets Tested","text":"<p>The automated test suite verifies:</p> <ol> <li>Build Success: Container builds without errors</li> <li>Startup: Container starts successfully</li> <li>Health Check: Built-in health endpoint responds</li> <li>Auto-Init: Project initialization works</li> <li>API Server: FastAPI server is accessible</li> <li>Cleanup: Test containers are properly removed</li> </ol>"},{"location":"docker/TESTING/#test-scenarios","title":"Test Scenarios","text":""},{"location":"docker/TESTING/#basic-functionality","title":"Basic Functionality","text":"<ul> <li>Container starts with minimal configuration</li> <li>Health endpoint returns 200 OK</li> <li>Auto-initialization creates project structure</li> <li>CLI commands work correctly (<code>aurite --help</code>, <code>aurite list</code>, etc.)</li> </ul>"},{"location":"docker/TESTING/#auto-initialization-testing","title":"Auto-Initialization Testing","text":"<p>Test the auto-initialization feature:</p> <pre><code># Test auto-init in empty directory\nmkdir -p /tmp/test-aurite-init\ndocker run --rm \\\n  -v /tmp/test-aurite-init:/app/project \\\n  -e API_KEY=test-key \\\n  -e AURITE_AUTO_INIT=true \\\n  aurite/aurite-agents:0.3.28 \\\n  timeout 10 python -c \"print('Init test complete')\"\n\n# Verify created files\nls -la /tmp/test-aurite-init\ncat /tmp/test-aurite-init/.aurite\ncat /tmp/test-aurite-init/configs/sample.json\n\n# Clean up\nrm -rf /tmp/test-aurite-init\n</code></pre>"},{"location":"docker/TESTING/#cli-command-testing","title":"CLI Command Testing","text":"<p>Test all major CLI commands:</p> <pre><code># Test help command\ndocker run --rm -v $(pwd):/app/project -e API_KEY=test-key aurite/aurite-agents aurite --help\n\n# Test list command (requires existing project)\ndocker run --rm -v $(pwd):/app/project -e API_KEY=test-key aurite/aurite-agents aurite list\n\n# Test show command\ndocker run --rm -v $(pwd):/app/project -e API_KEY=test-key aurite/aurite-agents aurite show llm\n\n# Test version\ndocker run --rm -v $(pwd):/app/project -e API_KEY=test-key aurite/aurite-agents aurite --version\n</code></pre>"},{"location":"docker/TESTING/#error-handling","title":"Error Handling","text":"<ul> <li>Missing API_KEY fails gracefully with clear error message</li> <li>Non-empty directory prevents auto-initialization</li> <li>Invalid configurations show helpful errors</li> <li>Container logs provide debugging information</li> </ul>"},{"location":"docker/TESTING/#performance","title":"Performance","text":"<ul> <li>Build completes in reasonable time (~70 seconds)</li> <li>Container starts within health check timeout (40 seconds)</li> <li>Memory and CPU usage are reasonable</li> <li>Health checks respond consistently</li> </ul>"},{"location":"docker/TESTING/#troubleshooting-tests","title":"Troubleshooting Tests","text":""},{"location":"docker/TESTING/#build-failures","title":"Build Failures","text":"<pre><code># Check Docker daemon\ndocker info\n\n# Verify files exist\nls -la Dockerfile.public docker-entrypoint.sh\n\n# Check from project root\npwd  # Should be in aurite/framework directory\n</code></pre>"},{"location":"docker/TESTING/#test-failures","title":"Test Failures","text":"<pre><code># View detailed logs\ndocker logs aurite-test-&lt;pid&gt;\n\n# Check health manually\ndocker exec aurite-test-&lt;pid&gt; curl -f http://localhost:8000/health\n\n# Inspect container\ndocker inspect aurite-test-&lt;pid&gt;\n</code></pre>"},{"location":"docker/TESTING/#common-issues","title":"Common Issues","text":"<ol> <li>Port conflicts: Change port with <code>-p 8001:8000</code></li> <li>Permission issues: Ensure Docker daemon is running</li> <li>Build context: Run from project root directory</li> <li>Resource limits: Ensure sufficient disk space and memory</li> </ol>"},{"location":"docker/TESTING/#cicd-integration","title":"CI/CD Integration","text":"<p>The GitHub Actions workflow automatically:</p> <ul> <li>Builds multi-platform images (amd64, arm64)</li> <li>Runs the same test suite</li> <li>Publishes to DockerHub on success</li> <li>Updates Docker Hub description</li> </ul> <p>Manual testing is still recommended for:</p> <ul> <li>Major version releases</li> <li>Significant functionality changes</li> <li>Before marking releases as \"latest\"</li> </ul>"},{"location":"docker/TESTING/#development-testing-debugging","title":"Development Testing &amp; Debugging","text":""},{"location":"docker/TESTING/#understanding-the-container-architecture","title":"Understanding the Container Architecture","text":"<p>The container uses a sophisticated entrypoint system that handles multiple scenarios:</p> <ol> <li>Package Installation: Uses <code>poetry install --with storage</code> in editable mode</li> <li>CLI Access: Routes <code>aurite</code> commands through Python module system since script entry points aren't created in editable installs</li> <li>Project Discovery: Uses ConfigManager's upward search from <code>/app/project</code></li> <li>Fallback Logic: Manual project creation if CLI commands fail</li> </ol>"},{"location":"docker/TESTING/#common-development-issues","title":"Common Development Issues","text":""},{"location":"docker/TESTING/#cli-command-not-found","title":"CLI Command Not Found","text":"<p>Symptom: <code>aurite: not found</code> or <code>No module named aurite.bin.cli.__main__</code> Cause: Script entry points not created during editable install Solution: Use Python module invocation in entrypoint script</p>"},{"location":"docker/TESTING/#auto-init-failures","title":"Auto-Init Failures","text":"<p>Symptom: \"Failed to run aurite init command\" Cause: CLI not available or init command issues Solution: Fallback to manual project structure creation</p>"},{"location":"docker/TESTING/#health-check-failures","title":"Health Check Failures","text":"<p>Symptom: Container marked as unhealthy Cause: API server not starting or responding Debug: Check container logs and environment variables</p>"},{"location":"docker/TESTING/#testing-new-changes","title":"Testing New Changes","text":"<p>When modifying the container system:</p> <ol> <li>Update entrypoint script (<code>docker-entrypoint.sh</code>)</li> <li>Rebuild container: <code>./scripts/docker/build_and_publish.sh --build-only</code></li> <li>Test CLI: <code>docker run --rm -v $(pwd):/app/project -e API_KEY=test-key aurite/aurite-agents aurite --help</code></li> <li>Test auto-init: Use empty directory with <code>AURITE_AUTO_INIT=true</code></li> <li>Verify health: Check that health checks pass consistently</li> </ol>"},{"location":"docker/TESTING/#expected-test-outputs","title":"Expected Test Outputs","text":""},{"location":"docker/TESTING/#successful-cli-test","title":"Successful CLI Test","text":"<pre><code>[INFO] Running aurite CLI command...\n\n Usage: aurite [OPTIONS] COMMAND [ARGS]...\n A framework for building, testing, and running AI agents.\n\n [Commands listed...]\n</code></pre>"},{"location":"docker/TESTING/#successful-auto-init-test","title":"Successful Auto-Init Test","text":"<pre><code>[INFO] AURITE_AUTO_INIT is enabled - initializing new project\n[INFO] Initializing new Aurite project...\n[WARN] Aurite CLI not available, creating basic project structure manually...\n[INFO] Creating basic project structure manually...\n[INFO] Creating .aurite configuration file...\n[INFO] Creating sample configuration file...\n[INFO] Project initialization complete!\n</code></pre>"},{"location":"docker/TESTING/#next-steps","title":"Next Steps","text":"<p>After successful testing:</p> <ol> <li>Review the output - Check for any warnings or issues</li> <li>Test manually - Verify key functionality works as expected</li> <li>Publish - Use the provided command to push to DockerHub</li> <li>Update documentation - Ensure Docker Hub README is current</li> <li>Tag release - Create GitHub release to trigger automated builds</li> </ol>"},{"location":"getting-started/quick_start/","title":"Quick Start","text":"<p>Get up and running with Aurite in just a few minutes!</p>"},{"location":"getting-started/quick_start/#1-install-aurite","title":"1. Install Aurite","text":"<ul> <li>Set up Python 3.12+ and a virtual environment.</li> <li>Install the <code>aurite</code> package:   <pre><code>pip install aurite\n</code></pre></li> </ul> <p>Need more details?</p> <p>See the Package Installation Guide for step-by-step instructions.</p>"},{"location":"getting-started/quick_start/#2-initialize-your-workspace-project","title":"2. Initialize Your Workspace &amp; Project","text":"<p>Run the interactive wizard from your chosen directory:</p> <pre><code>aurite init\n</code></pre> <p>This creates your workspace, first project, and example configurations.</p> <p>Learn More</p> <p>For details on projects and workspaces, see Projects and Workspaces.</p>"},{"location":"getting-started/quick_start/#3-run-a-built-in-agent","title":"3. Run a Built-In Agent","text":"<p>Try out the Weather Agent with a single command:</p> <pre><code>aurite run \"Weather Agent\" \"Weather in London?\"\n</code></pre> Example Output <pre><code>  The weather in London is currently 15\u00b0C, rainy, with 90% humidity.\n</code></pre>"},{"location":"getting-started/quick_start/#next-steps","title":"Next Steps","text":"<ul> <li>Explore more CLI commands in the CLI Reference.</li> <li>Edit configurations with:   <pre><code>aurite edit\n</code></pre></li> <li>Start the API server:   <pre><code>aurite api\n</code></pre></li> </ul> <p>Ready to build?</p> <p>You're set to start building with Aurite. Dive into configuration and workflow customization to unlock advanced features!</p>"},{"location":"getting-started/installation_guides/package_installation_guide/","title":"Package Installation Guide","text":"<p>Quick Start</p> <p>If you want a quick start we recommend starting with the Quick Start Guide to set up your first project quickly.</p> <p>This guide walks you through installing the <code>aurite</code> Python package and setting up your first Aurite project. This is the recommended path for users who want to build applications using the Aurite framework.</p> <p>Need to install from the repository?</p> <p>For instructions on setting up the framework from the main repository (e.g., if you plan to contribute to Aurite's framework), please see the Repository Installation Guide. If this question confuses you, you probably do not need it.</p>"},{"location":"getting-started/installation_guides/package_installation_guide/#setup-steps","title":"Setup Steps","text":"Environment SetupInitialize Your ProjectStart Building <p>Before installing, ensure your environment is ready.</p> <ol> <li>Python &gt;= 3.11: The Aurite framework requires Python 3.11 or higher. Check your version with <code>python --version</code>.</li> <li>Create a Workspace Directory: Choose a location on your computer for your Aurite projects.     <pre><code>mkdir my-aurite-workspace\ncd my-aurite-workspace\n</code></pre></li> <li>Activate a Virtual Environment: It is highly recommended to use a virtual environment.     <pre><code>python -m venv .venv\nsource .venv/bin/activate  # On Windows: .venv\\Scripts\\activate\n</code></pre></li> <li> <p>Install the <code>aurite</code> package: <pre><code>pip install aurite\n</code></pre></p> </li> <li> <p>Install Optional Dependencies (Extras):     The core <code>aurite</code> package is lightweight. Additional functionality is available through \"extras,\" which can be installed as needed.</p> <ul> <li>Storage: To use database integrations like Redis or PostgreSQL for session and cache management, install the <code>storage</code> extra:   <pre><code>pip install \"aurite[storage]\"\n</code></pre></li> <li>Machine Learning: For features requiring ML libraries like Pandas or Sentence Transformers, install the <code>ml</code> extra:   <pre><code>pip install \"aurite[ml]\"\n</code></pre> You can also install multiple extras at once: <pre><code>pip install \"aurite[storage,ml]\"\n</code></pre></li> </ul> </li> <li> <p>Verify the installation: <pre><code>aurite --version\n</code></pre>     This should display the installed version of Aurite (e.g., <code>aurite 0.3.28</code>).</p> </li> </ol> <p>The <code>aurite init</code> command is the easiest way to get started. It runs an interactive wizard to create your workspace and first project.</p> <ol> <li>Run the Interactive Wizard:     From your workspace directory (<code>my-aurite-workspace</code>), run:     <pre><code>aurite init\n</code></pre></li> <li> <p>Follow the Prompts: The wizard will guide you through:</p> <ul> <li>Creating a <code>.aurite</code> file to define your workspace.</li> <li>Creating your first project directory (e.g., <code>my-first-project</code>).</li> <li>Generating a default <code>config</code> directory inside your project with example component configurations.</li> <li>Creating a <code>.env</code> file in your workspace root for your API keys.</li> </ul> </li> <li> <p>Add Your API Key:     Open the newly created <code>.env</code> file in your workspace root and add your LLM API key(s), for example:</p> <pre><code>OPENAI_API_KEY=\"your-key-here\"\nANTHROPIC_API_KEY=\"your-key-here\"\n</code></pre> <p>If you want to use the built-in Aurite API, you need to add an <code>API_KEY</code> to your .env file. You can set the value for this key to be anything you want, for example:</p> <pre><code>API_KEY=my_api_key\n</code></pre> </li> </ol> <p>Your directory structure should now look like this:</p> <pre><code>my-aurite-workspace/\n\u251c\u2500\u2500 .aurite                   # Defines the workspace\n\u251c\u2500\u2500 .env                      # Your secret API keys\n\u251c\u2500\u2500 .venv/\n\u2514\u2500\u2500 my-first-project/\n    \u251c\u2500\u2500 .aurite               # Defines the project\n    \u251c\u2500\u2500 config/               # Your project's component configs\n    \u2502   \u251c\u2500\u2500 agents/\n    \u2502   \u251c\u2500\u2500 llms/\n    \u2502   \u2514\u2500\u2500 ...\n    \u251c\u2500\u2500 custom_workflows/     # Python source for custom workflows\n    \u2502   \u2514\u2500\u2500 example_workflow.py\n    \u251c\u2500\u2500 mcp_servers/          # Python source for MCP servers\n    \u2502   \u2514\u2500\u2500 weather_server.py\n    \u2514\u2500\u2500 run_example_project.py  # Script to run an example\n</code></pre> <p>The <code>init</code> command populates your project with a rich set of examples, including multiple agent, LLM, and workflow configurations located in the <code>config/</code> directory. It also provides runnable Python source code for custom workflows and MCP servers.</p> <p>For a deeper understanding of how projects and workspaces function, see the Projects and Workspaces guide.</p> <p>With your project initialized, you're ready to start building and running components.</p>"},{"location":"getting-started/installation_guides/package_installation_guide/#use-the-cli","title":"Use the CLI","text":"<p>The Aurite CLI provides commands to manage your project, run agents, and workflows. For example, to run an agent, you can use:</p> <pre><code>aurite run \"Weather Agent\" \"What is the weather in London?\"\n</code></pre> <p>For a list of all available commands, you can run: <pre><code>aurite --help\n</code></pre> For more details on using the CLI, see the CLI Reference.</p>"},{"location":"getting-started/installation_guides/package_installation_guide/#start-the-api-server","title":"Start the API Server","text":"<p>To interact with your project programmatically or via a UI, start the FastAPI server. From anywhere inside your workspace, run:</p> <pre><code>aurite api\n</code></pre> <p>The API will be available at <code>http://localhost:8000</code>.</p> <p>For more details on the API endpoints, see the API Reference.</p>"},{"location":"getting-started/installation_guides/package_installation_guide/#launch-aurite-studio-web-ui","title":"Launch Aurite Studio (Web UI)","text":"<p>For the best development experience, use Aurite Studio - an integrated development environment that provides a web-based UI for managing your agents, workflows, and configurations. From anywhere inside your workspace, run:</p> <pre><code>aurite studio\n</code></pre> <p>This command will: - Automatically start the API server (if not already running) - Launch the React-based web interface at <code>http://localhost:8000/studio</code> (or the port you configured in your <code>.env</code> file) - Handle all frontend dependencies and build processes automatically - Open your default browser to the Studio interface</p> <p>Aurite Studio provides: - Visual agent configuration and testing - Workflow management and execution - LLM provider setup and testing - MCP server integration - Real-time execution monitoring</p> <p>System Requirements</p> <p>Aurite Studio requires Node.js &gt;= 18.0.0 and npm &gt;= 8.0.0. The command will automatically check and try to install if these are missing.</p> <p>For advanced options like fresh rebuilds, see the CLI Reference.</p>"},{"location":"getting-started/installation_guides/package_installation_guide/#edit-configurations","title":"Edit Configurations","text":"<p>You can edit your component configurations using the <code>aurite edit</code> command, which opens a text editor for the specified component type. For example, to edit agents: <pre><code>aurite edit agents\n</code></pre></p> <p>You can also edit these configurations directly in the <code>config/</code> directory using your preferred text editor. See the Component Configurations guide for more details on the configuration structure.</p>"},{"location":"getting-started/installation_guides/repository_installation_guide/","title":"Repository Installation Guide","text":"<p>This guide provides step-by-step instructions for setting up the Aurite Agents framework by cloning the main repository. This method is suitable for developers who want to contribute to the framework, delve into its source code, or require the full development environment including the frontend UI and backend services.</p> <p>For installing Aurite as a Python package to use in your own projects, please see the Package Installation Guide.</p>"},{"location":"getting-started/installation_guides/repository_installation_guide/#prerequisites","title":"Prerequisites","text":"<ul> <li>Python &gt;= 3.11</li> <li>Poetry (Python package and dependency manager)</li> <li>Node.js (LTS version recommended, for frontend development)</li> <li>Docker &amp; Docker Compose (for the quickstart script and containerized setup)</li> <li><code>redis-server</code> (Required if you plan to use the asynchronous task worker)</li> </ul>"},{"location":"getting-started/installation_guides/repository_installation_guide/#installation","title":"Installation","text":"<ol> <li>Clone the Repository: <pre><code>git clone https://github.com/Aurite-ai/aurite-agents.git\ncd aurite-agents\n</code></pre></li> </ol>"},{"location":"getting-started/installation_guides/repository_installation_guide/#quickstart-with-docker-recommended","title":"Quickstart with Docker (Recommended)","text":"<p>The fastest way to get the entire Aurite Agents environment (Backend API, Frontend UI, and PostgreSQL database) up and running is by using the provided setup script with Docker.</p> <ol> <li>Ensure Docker is running.</li> <li> <p>Run the appropriate setup script for your operating system:</p> <ul> <li>For Linux/macOS:   In the project root directory (<code>aurite-agents</code>), execute:   <pre><code>./scripts/setup.sh\n</code></pre></li> <li>For Windows:   In the project root directory (<code>aurite-agents</code>), execute:   <code>bat ./scripts/setup.bat</code>   These scripts will:</li> <li>Check for Docker and Docker Compose.</li> <li>Guide you through creating and configuring your <code>.env</code> file (including API keys and project selection).</li> <li>Ask if you want to install optional ML dependencies for your local Python environment (useful if you plan to run or develop certain MCP Servers locally that require them).</li> <li>Build and start all services using Docker Compose.</li> </ul> <p>Once complete, the backend API will typically be available at <code>http://localhost:8000</code> and the frontend UI at <code>http://localhost:5173</code>. The script will display the generated API key needed for the UI.</p> <p>Note on Initial Startup: The backend container might take a few moments to start up completely, especially the first time, as it initializes MCP servers. During this time, the frontend UI might show a temporary connection error. Please allow a minute or two for all services to become fully operational.</p> </li> </ol>"},{"location":"getting-started/installation_guides/repository_installation_guide/#running-docker-compose-directly-alternative-to-setup-scripts","title":"Running Docker Compose Directly (Alternative to Setup Scripts)","text":"<p>If you prefer to manage your <code>.env</code> file manually or if the setup scripts encounter issues, you can still use Docker Compose:</p> <ol> <li>Create/Configure <code>.env</code> File: Ensure you have a valid <code>.env</code> file in the project root. You can copy <code>.env.example</code> to <code>.env</code> and fill in the necessary values (especially <code>ANTHROPIC_API_KEY</code> and <code>API_KEY</code>).</li> <li>Run Docker Compose: <pre><code>docker compose up --build\n</code></pre>     (Use <code>docker-compose</code> if you have an older standalone version).</li> </ol>"},{"location":"getting-started/installation_guides/repository_installation_guide/#manual-installation-backend-setup","title":"Manual Installation &amp; Backend Setup","text":"<p>If you prefer to set up and run components manually or without Docker for all services:</p> <ol> <li> <p>Install Python Dependencies:     This project uses Poetry for dependency management. First, ensure you have Poetry installed.</p> <p>From the project root, run the following command to install all required dependencies, including those for development:</p> <pre><code>poetry install --with dev\n</code></pre> <p>This command reads the <code>pyproject.toml</code> file, resolves the dependencies, and installs them into a dedicated virtual environment managed by Poetry.</p> <p>To include optional dependencies for features like database storage or machine learning, you can add them to the install command:</p> <pre><code># To include storage dependencies (Redis, PostgreSQL)\npoetry install --with dev,storage\n\n# To include machine learning dependencies (Pandas, Sentence Transformers)\npoetry install --with dev,ml\n\n# To include all optional dependencies\npoetry install --with dev,storage,ml\n</code></pre> </li> <li> <p>Activate the Virtual Environment:     To activate the virtual environment and use the installed packages, run:</p> <pre><code>poetry shell\n</code></pre> <p>All subsequent commands in this guide should be run inside this Poetry shell.</p> </li> <li> <p>Environment Variables Setup:     Before running the system, you need to set up your environment variables.</p> <p>a. Copy the Example File: In the project root, copy the <code>.env.example</code> file to a new file named <code>.env</code>: <code>bash cp .env.example .env</code></p> <p>b. Edit <code>.env</code>: Open the newly created <code>.env</code> file and fill in your specific configurations and secrets. Pay close attention to comments like <code>#REPLACE</code> indicating values you must change.</p> <p>Key environment variables to configure in your <code>.env</code> file:</p> <ul> <li>LLM API Key (Required): You must provide an API key for the language model provider you intend to use. For example:</li> <li><code>ANTHROPIC_API_KEY=your_anthropic_api_key</code></li> <li><code>OPENAI_API_KEY=your_openai_api_key</code></li> <li>(Add other provider keys as needed, e.g., <code>GEMINI_API_KEY</code>)     Only one key is strictly necessary to get started, depending on which LLM you configure your agents to use.</li> <li><code>API_KEY</code> (Optional, for API server): A secret key to secure the FastAPI endpoints if you run the API server. Generate a strong random key if you use this. This is pre-configured if you use the <code>setup.sh</code> or <code>setup.bat</code> scripts.</li> <li>Configuration Context: The framework automatically detects your project and workspace context by looking for <code>.aurite</code> files. You do not need to set a path manually. Use the <code>aurite init</code> command to create and manage these contexts.</li> </ul> <p>Other variables in the <code>.env</code> file (e.g., for Redis, database persistence like <code>AURITE_ENABLE_DB</code>, <code>AURITE_DB_URL</code>) are optional and only needed if you intend to use those specific features. Review all entries, especially those marked with <code>#REPLACE</code>, and configure them according to your needs.</p> <p>Important Security Note: Encryption Key</p> <ul> <li><code>AURITE_MCP_ENCRYPTION_KEY</code>: This environment variable is used by the framework's <code>SecurityManager</code> to encrypt sensitive data.</li> <li>If not set, a key will be auto-generated on startup. This is convenient for quick local testing.</li> <li>However, for any persistent deployment, or if you intend to use features that rely on encrypted storage (even for development), it is critical to set this to a strong, persistent, URL-safe base64-encoded 32-byte key.</li> <li>Relying on an auto-generated key means that any encrypted data may become inaccessible if the application restarts and generates a new key.</li> <li>Please refer to <code>SECURITY.md</code> (to be created) for detailed information on generating, managing, and understanding the importance of this key. You can find <code>AURITE_MCP_ENCRYPTION_KEY</code> commented out in your <code>.env.example</code> file as a reminder.</li> </ul> </li> <li> <p>Running the Backend API Server:     The primary way to interact with the framework is through its FastAPI server, which can be started with a simple command:</p> <pre><code>aurite api\n</code></pre> <p>This command is available after installing the dependencies (Step 2). By default, the server starts on <code>http://0.0.0.0:8000</code>.</p> </li> <li> <p>Using the CLI:     With the framework installed, you can now use the <code>aurite</code> command-line interface to interact with your project.</p> <ul> <li>List components: <pre><code>aurite list agents\n</code></pre></li> <li>Run an agent interactively: <pre><code>aurite run your_agent_name\n</code></pre></li> <li>Edit configurations in a TUI: <pre><code>aurite edit\n</code></pre></li> </ul> <p>For a complete guide to all commands, see the CLI Reference.</p> </li> </ol>"},{"location":"getting-started/installation_guides/repository_installation_guide/#6-frontend-ui-setup","title":"6. Frontend UI Setup","text":"<p>To set up and run the frontend developer UI for interacting with the Aurite Agents Framework:</p> <p>Prerequisites:</p> <ul> <li>Node.js &gt;= 18.0.0</li> <li>npm &gt;= 8.0.0</li> <li>Running Aurite Framework API server (Step 4 above)</li> </ul> <p>Note: Ensure the backend API server is running before starting the frontend if you are not using the Docker quickstart.</p> <ol> <li> <p>Navigate to the Frontend Directory:     Open a new terminal or use your existing one to change into the <code>frontend</code> directory:</p> <pre><code>cd frontend\n</code></pre> </li> <li> <p>Install Frontend Dependencies:     Inside the <code>frontend</code> directory, install the necessary Node.js packages for all packages:</p> <pre><code>npm install\n</code></pre> </li> <li> <p>Build All Packages:     Build all packages (required before starting development):</p> <pre><code>npm run build\n</code></pre> </li> <li> <p>Environment Configuration:     Set up environment variables for Aurite Studio:</p> <pre><code># Copy environment template for Aurite Studio\ncp packages/aurite-studio/.env.example packages/aurite-studio/.env\n# Edit packages/aurite-studio/.env with your React app configuration\n</code></pre> <p>Create a <code>.env</code> file in the <code>packages/aurite-studio/</code> directory with:</p> <pre><code># API Server URL - where the Aurite API server is running\nREACT_APP_API_BASE_URL=http://localhost:8000\n\n# API Key for authentication with the Aurite API server\nREACT_APP_API_KEY=your-key-here\n</code></pre> </li> <li> <p>Start the Frontend Development Server:     Once dependencies are installed and environment is configured, you have two options:</p> <p>Option A: Start from frontend root (recommended):</p> <pre><code>npm run start\n</code></pre> <p>Option B: Start from package directory:</p> <pre><code>cd packages/aurite-studio\nnpm start\n</code></pre> <p>The frontend UI will be available in your web browser at <code>http://localhost:3000</code>.</p> </li> </ol> <p>Troubleshooting:</p> <ul> <li>If you encounter connection issues, ensure the API server is fully started (it may take a moment to initialize MCP servers)</li> <li>Verify that your API key matches the one configured in your backend <code>.env</code> file</li> </ul>"},{"location":"getting-started/tutorials/06_Building_Your_Own_MCP_Server/","title":"Tutorial: Building Your Own MCP Server","text":"<p>Welcome to the advanced tutorial on creating custom MCP servers! This tutorial builds on everything you've learned about agents, tools, and project configuration. Now you'll learn how to extend the Aurite framework by creating your own Model Context Protocol (MCP) server that provides custom tools to your agents.</p> <p>Learning Objectives:</p> <p>Primary Goal: Understanding MCP and Building a Custom Server</p> <ul> <li>Understand what the Model Context Protocol (MCP) is and how it enables tool integration.</li> <li>Learn the structure and components of an MCP server.</li> <li>Build a functional MCP server from scratch that provides custom tools.</li> <li>Test your MCP server to ensure it works correctly.</li> </ul> <p>Secondary Goal: Integration with Aurite Framework</p> <ul> <li>Learn how to register your custom MCP server as a <code>ClientConfig</code> in your Aurite project.</li> <li>Create an agent that uses your custom MCP server.</li> <li>Successfully run an agent that uses your custom tools.</li> </ul>"},{"location":"getting-started/tutorials/06_Building_Your_Own_MCP_Server/#prerequisites","title":"Prerequisites","text":"<p>\u26a0\ufe0f Before you begin this tutorial, please ensure you have completed:</p> <ul> <li>All previous tutorials, especially \"Understanding Projects\".</li> <li>A working Aurite project set up locally.</li> <li>Python 3.12+ installed and configured.</li> <li>Basic understanding of Python programming.</li> <li>Familiarity with JSON configuration files.</li> </ul>"},{"location":"getting-started/tutorials/06_Building_Your_Own_MCP_Server/#part-1-understanding-the-model-context-protocol-mcp","title":"Part 1: Understanding the Model Context Protocol (MCP)","text":""},{"location":"getting-started/tutorials/06_Building_Your_Own_MCP_Server/#what-is-mcp","title":"What is MCP?","text":"<p>The Model Context Protocol (MCP) is a standardized way for AI applications to connect with external data sources and tools. Think of it as a bridge that allows your AI agents to interact with the outside world.</p> <p>Key Concepts:</p> <ul> <li>MCP Server: A program that provides tools, resources, or prompts to AI agents.</li> <li>MCP Client: The AI application (like Aurite) that connects to and uses MCP servers.</li> <li>Tools: Functions that agents can call to perform actions (e.g., search the web, save files).</li> </ul>"},{"location":"getting-started/tutorials/06_Building_Your_Own_MCP_Server/#how-mcp-works-in-aurite","title":"How MCP Works in Aurite","text":"<ol> <li>MCP Servers run as separate processes and provide tools.</li> <li><code>ClientConfig</code> objects in your <code>aurite_config.json</code> define how to connect to these servers.</li> <li>Agents specify which MCP servers they can use via the <code>mcp_servers</code> field in their configuration.</li> <li>When an agent runs, Aurite connects to the specified servers and makes their tools available.</li> </ol> <p>For this tutorial, we'll create a server that communicates via <code>stdio</code> (standard input/output), as it's the most straightforward method for custom Python scripts.</p>"},{"location":"getting-started/tutorials/06_Building_Your_Own_MCP_Server/#part-2-building-the-mcp-server-step-by-step","title":"Part 2: Building the MCP Server Step-by-Step","text":"<p>We will create a simple Task Management Server that stores tasks in memory.</p>"},{"location":"getting-started/tutorials/06_Building_Your_Own_MCP_Server/#step-1-create-the-project-directory-and-server-file","title":"Step 1: Create the Project Directory and Server File","text":"<p>First, let's set up the file structure. Inside your Aurite project folder (e.g., <code>my_first_aurite_project</code>), create a new directory called <code>mcp_servers</code>.</p> <p>Inside this new <code>mcp_servers</code> directory, create a file named <code>task_manager_server.py</code>.</p> <p>Your project structure should look like this:</p> <pre><code>my_first_aurite_project/\n\u251c\u2500\u2500 mcp_servers/\n\u2502   \u2514\u2500\u2500 task_manager_server.py\n\u251c\u2500\u2500 aurite_config.json\n\u2514\u2500\u2500 run_example_project.py\n</code></pre>"},{"location":"getting-started/tutorials/06_Building_Your_Own_MCP_Server/#step-2-create-the-server-skeleton","title":"Step 2: Create the Server Skeleton","text":"<p>Open <code>task_manager_server.py</code> and add the following boilerplate code. This sets up the basic server structure.</p> <pre><code>#!/usr/bin/env python3\n\"\"\"\nA simple Task Management MCP Server that stores tasks in memory.\n\"\"\"\nimport logging\nfrom typing import Dict, Any, List\n\n# MCP imports\nfrom mcp.server.fastmcp import FastMCP\n\n# Set up logging\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\n# Create the MCP server instance\nmcp = FastMCP(\"In-Memory Task Manager\")\n\n# In-memory storage for our tasks\ntasks: List[Dict[str, Any]] = []\n\n# --- Tool implementations will go here ---\n\n# Allow direct execution of the server\nif __name__ == \"__main__\":\n    mcp.run()\n</code></pre>"},{"location":"getting-started/tutorials/06_Building_Your_Own_MCP_Server/#step-3-add-the-create_task-tool","title":"Step 3: Add the <code>create_task</code> Tool","text":"<p>Now, let's add our first tool. This function will add a new task to our in-memory <code>tasks</code> list. Add the following code to <code>task_manager_server.py</code> where the comment <code>--- Tool implementations will go here ---</code> is.</p> <pre><code>@mcp.tool()\nasync def create_task(title: str, priority: str = \"medium\") -&gt; Dict[str, Any]:\n    \"\"\"\n    Create a new task.\n\n    Args:\n        title: The title of the task (required).\n        priority: Priority level (low, medium, high).\n\n    Returns:\n        A dictionary with the created task information.\n    \"\"\"\n    task_id = len(tasks)  # Use the list index as a simple ID\n    new_task = {\n        \"id\": task_id,\n        \"title\": title,\n        \"priority\": priority,\n        \"completed\": False,\n    }\n    tasks.append(new_task)\n    logger.info(f\"Created task: {new_task}\")\n    return {\"success\": True, \"task\": new_task}\n</code></pre> <p>The <code>@mcp.tool()</code> decorator automatically registers this function as a tool that agents can call.</p>"},{"location":"getting-started/tutorials/06_Building_Your_Own_MCP_Server/#step-4-add-the-list_tasks-tool","title":"Step 4: Add the <code>list_tasks</code> Tool","text":"<p>Next, let's add a tool to view the tasks. Add this code below the <code>create_task</code> function.</p> <pre><code>@mcp.tool()\nasync def list_tasks() -&gt; Dict[str, Any]:\n    \"\"\"\n    List all tasks.\n\n    Returns:\n        A dictionary containing the list of tasks.\n    \"\"\"\n    logger.info(f\"Listing {len(tasks)} tasks.\")\n    return {\"success\": True, \"tasks\": tasks}\n</code></pre>"},{"location":"getting-started/tutorials/06_Building_Your_Own_MCP_Server/#step-5-make-the-server-executable","title":"Step 5: Make the Server Executable","text":"<p>On macOS and Linux, you need to make the script executable. Open your terminal, navigate to the <code>mcp_servers</code> directory, and run:</p> <pre><code>chmod +x task_manager_server.py\n</code></pre> <p>(Windows users can skip this step.)</p>"},{"location":"getting-started/tutorials/06_Building_Your_Own_MCP_Server/#part-3-testing-your-mcp-server","title":"Part 3: Testing Your MCP Server","text":"<p>Before integrating with Aurite, let's write a small script to test our server directly.</p> <ol> <li> <p>Create a Test Script: In your project's root directory (e.g., <code>my_first_aurite_project</code>), create a new file named <code>test_mcp.py</code>.</p> </li> <li> <p>Add Test Code: Add the following code to <code>test_mcp.py</code>. This script will call your server's tools and print the results.</p> <pre><code>import asyncio\nimport json\nfrom mcp_servers.task_manager_server import mcp\n\nasync def test_tools():\n    \"\"\"Test the tools in our MCP server.\"\"\"\n    print(\"--- Testing Task Manager MCP Server ---\")\n\n    # Test 1: Create a task\n    print(\"\\n1. Creating a task...\")\n    result = await mcp.call_tool(\"create_task\", {\n        \"title\": \"Test Task\",\n        \"priority\": \"high\"\n    })\n    print(f\"Result: {json.dumps(result, indent=2)}\")\n\n    # Test 2: List tasks\n    print(\"\\n2. Listing all tasks...\")\n    result = await mcp.call_tool(\"list_tasks\", {})\n    print(f\"Result: {json.dumps(result, indent=2)}\")\n\n    print(\"\\n--- Test completed! ---\")\n\nif __name__ == \"__main__\":\n    asyncio.run(test_tools())\n</code></pre> </li> <li> <p>Run the Test: In your terminal, from your project's root directory, run the test script:</p> <pre><code>python test_mcp.py\n</code></pre> </li> </ol> <p>You should see output showing that a task was created and then listed successfully.</p>"},{"location":"getting-started/tutorials/06_Building_Your_Own_MCP_Server/#part-4-integrating-with-aurite","title":"Part 4: Integrating with Aurite","text":"<p>Now let's connect your new server to an agent.</p>"},{"location":"getting-started/tutorials/06_Building_Your_Own_MCP_Server/#step-1-register-the-server-in-aurite_configjson","title":"Step 1: Register the Server in <code>aurite_config.json</code>","text":"<p>Open your <code>aurite_config.json</code> file and add a new object to the <code>mcp_servers</code> array.</p> <pre><code>{\n  \"name\": \"task_manager_server\",\n  \"transport_type\": \"stdio\",\n  \"server_path\": \"mcp_servers/task_manager_server.py\"\n}\n</code></pre> <p>Make sure to add a comma after the preceding server configuration if one exists.</p>"},{"location":"getting-started/tutorials/06_Building_Your_Own_MCP_Server/#step-2-create-an-agent-that-uses-the-server","title":"Step 2: Create an Agent That Uses the Server","text":"<p>In the same <code>aurite_config.json</code> file, add a new agent to the <code>agents</code> array that uses your server.</p> <pre><code>{\n  \"name\": \"TaskManagerAgent\",\n  \"system_prompt\": \"You are a helpful task management assistant. Use the available tools to manage tasks. Always provide clear feedback about the operations you perform.\",\n  \"llm_config_id\": \"my_openai_gpt4_turbo\",\n  \"mcp_servers\": [\"task_manager_server\"]\n}\n</code></pre>"},{"location":"getting-started/tutorials/06_Building_Your_Own_MCP_Server/#step-3-run-the-agent","title":"Step 3: Run the Agent","text":"<p>You can now use the Aurite CLI to interact with your agent.</p> <pre><code># Test creating a task\naurite run-agent TaskManagerAgent \"Create a new task: 'Buy groceries' with medium priority\"\n\n# Test listing tasks\naurite run-agent TaskManagerAgent \"Show me all my tasks\"\n</code></pre>"},{"location":"getting-started/tutorials/06_Building_Your_Own_MCP_Server/#congratulations","title":"\ud83c\udf89 Congratulations!","text":"<p>You've successfully built, tested, and integrated your first custom MCP server!</p>"},{"location":"getting-started/tutorials/06_Building_Your_Own_MCP_Server/#what-youve-learned","title":"\u2705 What You've Learned:","text":"<ul> <li>How to build a simple MCP server with the <code>FastMCP</code> helper.</li> <li>How to define tools using the <code>@mcp.tool()</code> decorator.</li> <li>How to test an MCP server directly.</li> <li>How to register a custom server in <code>aurite_config.json</code>.</li> <li>How to create an agent that uses your custom tools.</li> </ul>"},{"location":"getting-started/tutorials/06_Building_Your_Own_MCP_Server/#next-steps","title":"\ud83d\ude80 Next Steps:","text":"<ul> <li>Try adding a <code>complete_task</code> tool to your server.</li> <li>Experiment with adding more complex logic, like file persistence.</li> <li>Explore the official MCP documentation for more advanced features.</li> </ul>"},{"location":"getting-started/tutorials/07_Understanding_Projects/","title":"Module 1: Tutorial - Your First Agent via Configuration Files","text":"<p>Welcome to your first hands-on experience with the Aurite Agents framework! In this tutorial, you'll configure, run, and interact with a basic AI agent by directly editing configuration files and running a Python script. This will help solidify the concepts you learned in \"What is an AI Agent?\" and introduce you to the code-centric way of managing Aurite projects.</p> <p>Learning Objectives:</p> <p>Primary Goal: Framework Setup and Initial Agent Execution</p> <ul> <li>Successfully install the Aurite framework and its prerequisites, including setting up a Python virtual environment.</li> <li>Initialize a new Aurite project and configure your OpenAI API key in a <code>.env</code> file.</li> <li>Run a pre-configured example agent to verify your setup and ensure the framework is operational.</li> </ul> <p>Secondary Goal: Understanding and Building Your First Agent via Configuration</p> <ul> <li>Grasp the fundamental role of the <code>aurite_config.json</code> file in defining agents within an Aurite project.</li> <li>Learn to configure a new agent by directly editing the <code>aurite_config.json</code> file, utilizing pre-defined LLM and MCP server (client) configurations.</li> <li>Understand the purpose and structure of the <code>run_example_project.py</code> script for programmatically executing agents.</li> <li>Modify the <code>run_example_project.py</code> script to execute your custom-configured agent.</li> <li>Successfully run your newly configured agent, observe its output, and gain a practical understanding of how a basic AI agent operates within the Aurite framework.</li> </ul>"},{"location":"getting-started/tutorials/07_Understanding_Projects/#prerequisites","title":"Prerequisites","text":"<p>\u26a0\ufe0f Before you begin this tutorial, please ensure you have completed all the steps in the Package Installation Guide.</p> <p>This includes:</p> <ul> <li>Installing Python 3.12+</li> <li>Setting up your workspace and Python virtual environment.</li> <li>Obtaining an OpenAI API key and configuring it in a <code>.env</code> file in your workspace root.</li> <li>Installing the <code>aurite</code> package.</li> <li>Initializing your first Aurite project (e.g., <code>my_first_aurite_project</code>) using <code>aurite init</code>.</li> <li>Successfully running the example agent via <code>python run_example_project.py</code> from within your project directory.</li> </ul> <p>Once these prerequisites are met, you are ready to proceed with configuring your first custom agent.</p>"},{"location":"getting-started/tutorials/07_Understanding_Projects/#1-understanding-aurite_configjson","title":"1. Understanding <code>aurite_config.json</code>","text":"<p>The <code>aurite_config.json</code> file, located at the root of your project (e.g., <code>your_project_name/aurite_config.json</code>), is the central configuration hub for your Aurite project. It defines the agents, LLMs, clients (MCP servers), and workflows that are part of your project.</p> <p>When you ran <code>aurite init</code>, this file was created with some example configurations. We will modify it to define our new weather forecast agent.</p> <ul> <li>Open <code>aurite_config.json</code> in your text editor.</li> </ul> <p>You'll see sections for <code>llms</code>, <code>mcp_servers</code>, and <code>agents</code>, among others. For this tutorial, we'll focus on:</p> <ul> <li>The <code>llms</code> array: Lists available Large Language Model configurations.</li> <li>The <code>mcp_servers</code> array: Lists configurations for MCP servers, which provide tools to your agents. <code>aurite init</code> includes an example <code>weather_server</code>.</li> <li>The <code>agents</code> array: This is where we will define our new agent.</li> </ul> <p>(The <code>aurite_config.json</code> file also includes sections for <code>linear_workflows</code> and <code>custom_workflows</code>. These allow you to define sequences of agents or more complex programmatic workflows, respectively. While not covered in this introductory tutorial, they demonstrate how you can orchestrate multiple components within your Aurite project.)</p>"},{"location":"getting-started/tutorials/07_Understanding_Projects/#2-modifying-aurite_configjson-configure-your-first-agent","title":"2. Modifying <code>aurite_config.json</code> - Configure Your First Agent","text":"<p>Now, let's configure your \"MyCLIWeatherAssistant\" agent. The <code>aurite init</code> command provides a default <code>aurite_config.json</code> which already includes a pre-configured LLM for OpenAI (<code>my_openai_gpt4_turbo</code>) and an example <code>weather_server</code> client. We will use these existing components for our new agent.</p> <ol> <li> <p>Add Your New Agent Configuration:</p> <ul> <li>Open your <code>aurite_config.json</code> file.</li> <li>Locate the <code>agents</code> array.</li> <li>Add the following JSON object as a new element within this <code>agents</code> array. Since the default configuration already includes other agents, you'll be adding your \"MyCLIWeatherAssistant\" alongside them.</li> </ul> </li> <li> <p>You will need to add a comma <code>,</code> after the closing curly brace <code>}</code> of the agent definition that comes before where you paste your new agent's configuration.</p> </li> </ol> <pre><code>{\n  \"name\": \"MyCLIWeatherAssistant\",\n  \"system_prompt\": \"You are a helpful assistant. Your task is to use the available tools to find and report the weather for the location specified by the user. Only provide the temperature and a brief description of the conditions.\",\n  \"llm_config_id\": \"my_openai_gpt4_turbo\",\n  \"mcp_servers\": [\"weather_server\"]\n}\n</code></pre> <p>Let's break down these fields for your new agent:</p> Field Description <code>\"name\"</code> <code>\"MyCLIWeatherAssistant\"</code>: A unique name for your agent. <code>\"system_prompt\"</code> Instructions defining the agent's role and task. (e.g., \"You are a helpful assistant...\") <code>\"llm_config_id\"</code> <code>\"my_openai_gpt4_turbo\"</code>: Tells your agent to use the pre-defined OpenAI GPT-4 Turbo LLM configuration. This <code>llm_id</code> is already set up in the <code>llms</code> array of your <code>aurite_config.json</code> by <code>aurite init</code>. <code>\"mcp_servers\"</code> <code>[\"weather_server\"]</code>: A list of MCP Server names the agent can use for tools. <code>\"weather_server\"</code> is an example server provided by <code>aurite init</code>. <ol> <li>Save <code>aurite_config.json</code>.</li> </ol>"},{"location":"getting-started/tutorials/07_Understanding_Projects/#3-modifying-run_example_projectpy-to-execute-your-agent","title":"3. Modifying <code>run_example_project.py</code> to Execute Your Agent","text":"<p>The <code>aurite init</code> command creates an example script <code>run_example_project.py</code> in your project root. This script is pre-configured to run the default \"Weather Agent\". We only need to make one small change to tell it to run your newly configured \"MyCLIWeatherAssistant\" instead.</p> <ol> <li> <p>Open <code>run_example_project.py</code> in your text editor.     You'll find that the script already contains the necessary logic to initialize Aurite, run an agent, and print its response.</p> </li> <li> <p>Update the Agent Name:</p> <ul> <li>Locate the section in the script where the <code>aurite.run_agent</code> function is called. It will look similar to this (line numbers may vary slightly):</li> </ul> <pre><code># ... other code ...\n\nagent_result = await aurite.run_agent(\n    agent_name=\"My Weather Agent\", # &lt;--- CHANGE THIS LINE\n    user_message=user_query,\n)\n\n# ... other code ...\n</code></pre> <ul> <li>Change the value of the <code>agent_name</code> parameter from <code>\"My Weather Agent\"</code> to <code>\"MyCLIWeatherAssistant\"</code> (the name you gave your agent in <code>aurite_config.json</code>).   The line should now look like:   <pre><code>agent_name=\"MyCLIWeatherAssistant\", # Must match the name in aurite_config.json\n</code></pre></li> </ul> </li> <li> <p>Save <code>run_example_project.py</code>.</p> </li> </ol> <p>That's the only change needed for this script! The rest of the script, including how it sets the <code>user_query</code> and prints the <code>agent_result</code>, can remain as is for this tutorial.</p>"},{"location":"getting-started/tutorials/07_Understanding_Projects/#4-running-your-modified-agent","title":"4. Running Your Modified Agent","text":"<p>Now it's time to see your \"MyCLIWeatherAssistant\" in action!</p> <ol> <li> <p>Navigate to Your Project Directory:</p> <ul> <li>Ensure your Python virtual environment (from the Package Installation Guide) is active.</li> <li>In your terminal, make sure you are in the root directory of your Aurite project (e.g., <code>my_first_aurite_project</code>).</li> </ul> </li> <li> <p>Run the Script:</p> <ul> <li>Execute the <code>run_example_project.py</code> script (which you modified in Step 5):   <pre><code>python run_example_project.py\n</code></pre></li> </ul> </li> <li> <p>Observe the Terminal Output:</p> <ul> <li>You should now see output from your \"MyCLIWeatherAssistant\" providing a weather report for New York, similar to before but this time executed using your agent's configuration. For example:</li> </ul> <pre><code>Running agent 'MyCLIWeatherAssistant' with query: 'What's the weather like in New York?'\n\n--- Agent Result ---\nAgent's response: The temperature in New York is 22\u00b0C with partly cloudy skies.\n</code></pre> <p>(The exact weather details will vary. The key is that it's your \"MyCLIWeatherAssistant\" running.)</p> </li> </ol>"},{"location":"getting-started/tutorials/07_Understanding_Projects/#success-criteria-verification","title":"Success Criteria / Verification","text":"<p>You've successfully completed this tutorial if:</p> <ul> <li>Your <code>aurite_config.json</code> file was correctly modified to include the new \"MyCLIWeatherAssistant\" agent configuration.</li> <li>Your <code>run_example_project.py</code> script was updated to call your new agent by name.</li> <li>Running <code>python run_example_project.py</code> in your project's root directory executed without Python errors.</li> <li>The terminal output showed a weather forecast for the queried location (e.g., New York), indicating your agent successfully used the LLM and the weather tool.</li> </ul> <p>Congratulations! You've successfully configured and executed your first AI agent by directly editing configuration files and running a Python script. This demonstrates a powerful way to manage and deploy Aurite agents.</p> <p>In the next module, you'll dive deeper into how tools work by learning more about the Model Context Protocol (MCP) and potentially building or configuring more complex MCP clients.</p>"},{"location":"getting-started/tutorials/Tutorials_Overview/","title":"Aurite Tutorials","text":"<p>Info</p> <p>Start with the interactive notebooks for hands-on learning, then move to local project guides as you gain confidence.</p>"},{"location":"getting-started/tutorials/Tutorials_Overview/#part-1-learning-with-notebooks","title":"Part 1: Learning with Notebooks","text":"<p>This module provides a hands-on, code-first approach to learning Aurite through a series of interactive Jupyter/Colab notebooks.</p> <ol> <li> <p>Notebook 1: Introducing Aurite Agents</p> <ul> <li>Get started with the basics of the framework.</li> <li>Open in Colab</li> <li>Open Locally</li> </ul> </li> <li> <p>Notebook 2: Agents and Tools</p> <ul> <li>Learn how to equip agents with tools to perform actions.</li> <li>Open in Colab</li> <li>Open Locally</li> </ul> </li> <li> <p>Notebook 3: Agent Challenge</p> <ul> <li>Put your skills to the test with a challenge to build a capable agent.</li> <li>Open in Colab</li> <li>Open Locally</li> </ul> </li> <li> <p>Notebook 4: Agent Challenge Solutions</p> <ul> <li>Review the solutions to the agent challenge.</li> <li>Open in Colab</li> <li>Open Locally</li> </ul> </li> <li> <p>Notebook 5: LLMs, Schemas, and Workflows</p> <ul> <li>Dive deeper into advanced topics like LLM configuration, data schemas, and multi-step workflows.</li> <li>Open in Colab</li> <li>Open Locally</li> </ul> </li> </ol>"},{"location":"getting-started/tutorials/Tutorials_Overview/#part-2-building-local-projects","title":"Part 2: Building Local Projects","text":"<p>Tip</p> <p>VSCode is suggested for local development, but any Python IDE will work.</p> <p>Once you are comfortable with the concepts from the notebooks, these tutorials guide you through setting up and running the Aurite framework in a local development environment like VSCode.</p> <ol> <li> <p>Building Your Own MCP Server</p> <ul> <li>Learn how to extend Aurite by creating a custom Model Context Protocol (MCP) server that provides new tools for your agents.</li> <li>Step-by-step instructions for building, testing, and integrating your own MCP server.</li> <li>Tutorial: Building Your Own MCP Server</li> </ul> </li> <li> <p>Understanding Aurite Projects</p> <ul> <li>This tutorial walks you through the structure of a local Aurite project and how to configure and run an agent by editing configuration files.</li> <li>Tutorial: Understanding Aurite Projects</li> </ul> </li> </ol>"},{"location":"testing/","title":"Kahuna Testing &amp; Security Framework","text":""},{"location":"testing/#overview","title":"Overview","text":"<p>The Kahuna Testing &amp; Security Framework provides comprehensive quality assurance and security validation for AI agents and workflows across multiple agent frameworks in enterprise environments. This framework is designed to bridge business requirements from Kahuna Manager Mode with development practices in Kahuna Developer Mode, ultimately providing metrics and insights to Kahuna Executive Mode.</p> <p>The framework now supports framework-agnostic testing, enabling validation of AI components independent of the specific agent framework being used, while also providing framework-specific testing for unique implementation details.</p>"},{"location":"testing/#core-philosophy","title":"Core Philosophy","text":"<p>Our testing approach recognizes two fundamental principles:</p>"},{"location":"testing/#1-compositional-hierarchy","title":"1. Compositional Hierarchy","text":"<p>AI components build upon each other in a hierarchical manner:</p> <pre><code>LLMs \u2500\u2510\n      \u251c\u2500\u2192 Agents \u2500\u2192 Workflows\nMCP \u2500\u2500\u2518\n</code></pre>"},{"location":"testing/#2-framework-independence","title":"2. Framework Independence","text":"<p>Certain AI components operate independently of any specific agent framework:</p> <pre><code>Framework-Agnostic (Universal)\n\u251c\u2500\u2500 LLMs (100% Agnostic)\n\u251c\u2500\u2500 MCP Servers (100% Agnostic)\n\u2514\u2500\u2500 Core Agent Behaviors (60% Agnostic)\n    \u2514\u2500\u2500 Framework-Specific Layer\n        \u251c\u2500\u2500 Agent Orchestration (40% Specific)\n        \u2514\u2500\u2500 Workflows (80% Specific)\n</code></pre> <p>This dual nature allows us to:</p> <ul> <li>Inherit test results from foundation components</li> <li>Reuse tests across different agent frameworks</li> <li>Focus testing efforts on integration points</li> <li>Avoid redundant validation</li> <li>Accelerate the testing process</li> <li>Enable cross-framework comparisons</li> </ul>"},{"location":"testing/#framework-organization","title":"Framework Organization","text":"<p>The testing framework operates in three dimensions:</p>"},{"location":"testing/#1-testing-categories","title":"1. Testing Categories","text":"<ul> <li>Quality Assurance (QA): Ensures components meet performance, accuracy, and business requirements</li> <li>Security Testing: Validates safety, compliance, and protection against threats</li> </ul>"},{"location":"testing/#2-testing-phases","title":"2. Testing Phases","text":"<ul> <li>Development-Time Testing: Pre-deployment validation in development environments</li> <li>Runtime Monitoring: Continuous validation in production environments</li> </ul>"},{"location":"testing/#3-framework-scope","title":"3. Framework Scope","text":"<ul> <li>Framework-Agnostic: Universal tests that work across all agent frameworks</li> <li>Framework-Specific: Tests unique to individual framework implementations</li> </ul> <p>This creates test combinations such as:</p> <ul> <li>Framework-Agnostic Security Runtime LLM Test</li> <li>Framework-Specific QA Development-Time Workflow Test</li> <li>Framework-Agnostic Quality Development-Time MCP Server Test</li> </ul>"},{"location":"testing/#component-hierarchy","title":"Component Hierarchy","text":""},{"location":"testing/#foundation-components-100-framework-agnostic","title":"Foundation Components (100% Framework-Agnostic)","text":"<ul> <li>LLMs: Language model testing for quality and security - completely independent of calling framework</li> <li>MCP Servers: Tool and API testing - operates through standardized protocols</li> </ul>"},{"location":"testing/#hybrid-components","title":"Hybrid Components","text":"<ul> <li>Agents: Combined LLM + MCP testing with agent-specific validation</li> <li>60% Framework-Agnostic: Core behaviors, tool usage, goal achievement</li> <li>40% Framework-Specific: System prompts, memory management, orchestration</li> </ul>"},{"location":"testing/#framework-dependent-components","title":"Framework-Dependent Components","text":"<ul> <li>Workflows: End-to-end business process validation</li> <li>20% Framework-Agnostic: Business logic, data integrity</li> <li>80% Framework-Specific: Orchestration patterns, inter-agent communication</li> </ul>"},{"location":"testing/#testing-matrix","title":"Testing Matrix","text":"Component Quality Testing Security Testing Framework Scope Inheritance LLM \u2022 Response coherence\u2022 Instruction following\u2022 Output formatting \u2022 Prompt injection\u2022 Content safety\u2022 Data leakage 100% Agnostic None (foundation) MCP Server \u2022 API compliance\u2022 Performance\u2022 Error handling \u2022 Authentication\u2022 Input validation\u2022 Rate limiting 100% Agnostic None (foundation) Agent \u2022 Tool selection\u2022 Goal achievement\u2022 Efficiency \u2022 Permission boundaries\u2022 Action authorization\u2022 Resource limits 60% Agnostic40% Specific Inherits from LLM + MCP Workflow \u2022 Business compliance\u2022 End-to-end success\u2022 Performance \u2022 Cross-agent security\u2022 Data isolation\u2022 Audit completeness 20% Agnostic80% Specific Inherits from all agents"},{"location":"testing/#key-concepts","title":"Key Concepts","text":""},{"location":"testing/#framework-agnostic-testing","title":"Framework-Agnostic Testing","text":"<p>The framework supports testing AI components across multiple agent frameworks through:</p> <ul> <li>Universal Standards: LLMs and MCP Servers tested independently of framework</li> <li>Adapter Pattern: Translation between framework-specific and standard formats</li> <li>Aurite as Standard: Using Aurite Agents as the canonical testing format</li> <li>Cross-Framework Comparison: Benchmarking performance across different frameworks</li> </ul> <p>For detailed architecture, see Framework-Agnostic Testing Architecture.</p>"},{"location":"testing/#test-result-inheritance","title":"Test Result Inheritance","text":"<p>Higher-level components inherit test results from their dependencies, now including cross-framework inheritance:</p> <pre><code>Workflow Test Result = {\n    workflow_specific_tests: { ... },\n    agent_results: {\n        agent_1: {\n            agent_specific_tests: { ... },\n            inherited_llm_results: { ... },  // Framework-agnostic\n            inherited_mcp_results: { ... }   // Framework-agnostic\n        }\n    },\n    aggregated_metrics: { ... },\n    framework_metadata: { ... }\n}\n</code></pre>"},{"location":"testing/#smart-test-optimization","title":"Smart Test Optimization","text":"<p>The framework optimizes testing through:</p> <ol> <li>Skip Redundant Tests: If an LLM passes security tests, agents using it don't retest the same vectors</li> <li>Focus on Integration: Agent tests focus on tool usage, not language capabilities</li> <li>Efficient Regression: Component updates trigger only affected downstream tests</li> <li>Cross-Framework Reuse: Framework-agnostic test results apply to all frameworks</li> </ol>"},{"location":"testing/#failure-propagation","title":"Failure Propagation","text":"<p>When foundation components fail:</p> <ul> <li>Dependent components are marked as \"pending\" or \"blocked\"</li> <li>Impact analysis shows the full dependency chain</li> <li>Developers can see exactly what needs fixing</li> <li>Framework-agnostic failures affect all framework implementations</li> </ul>"},{"location":"testing/#integration-with-kahuna-ecosystem","title":"Integration with Kahuna Ecosystem","text":""},{"location":"testing/#input-project-context-from-kahuna-mgr","title":"Input: Project Context (from Kahuna-mgr)","text":"<ul> <li>Business workflow requirements</li> <li>Component specifications</li> <li>Quality thresholds</li> <li>Security policies</li> <li>Target framework(s)</li> </ul>"},{"location":"testing/#process-testing-validation","title":"Process: Testing &amp; Validation","text":"<ul> <li>Framework detection and adaptation</li> <li>Development-time testing (agnostic and specific)</li> <li>Security assessment</li> <li>Quality assurance</li> <li>Compliance verification</li> <li>Cross-framework comparison</li> </ul>"},{"location":"testing/#output-metrics-reports-to-kahuna-exec","title":"Output: Metrics &amp; Reports (to Kahuna-exec)","text":"<ul> <li>Quality scores (per framework)</li> <li>Security assessments</li> <li>Business KPI achievement</li> <li>Compliance status</li> <li>Framework comparison metrics</li> </ul>"},{"location":"testing/#related-documentation","title":"Related Documentation","text":""},{"location":"testing/#architecture-documents","title":"Architecture Documents","text":"<ul> <li>Framework-Agnostic Testing - Multi-framework testing architecture</li> <li>Testing Hierarchy - Complete testing hierarchy and flow</li> <li>Testing Architecture - Core architectural principles</li> <li>Test Inheritance - Test result inheritance patterns</li> </ul>"},{"location":"testing/#component-testing-guides","title":"Component Testing Guides","text":"<ul> <li>LLM Testing - Framework-agnostic LLM testing</li> <li>MCP Server Testing - Framework-agnostic tool testing</li> <li>Agent Testing - Hybrid agent testing approach</li> <li>Workflow Testing - Framework-specific workflow testing</li> </ul>"},{"location":"testing/architecture/framework_agnostic_testing/","title":"Framework-Agnostic Testing Architecture","text":""},{"location":"testing/architecture/framework_agnostic_testing/#overview","title":"Overview","text":"<p>The Framework-Agnostic Testing Architecture extends the Kahuna Testing &amp; Security Framework to enable testing of AI components across multiple agent frameworks, not just Aurite Agents. This architecture introduces a third dimension to our testing matrix, allowing us to distinguish between tests that are universal across all frameworks and those that are specific to individual framework implementations.</p>"},{"location":"testing/architecture/framework_agnostic_testing/#purpose-and-philosophy","title":"Purpose and Philosophy","text":"<p>Framework-agnostic testing recognizes that certain AI components and behaviors can be validated independently of the framework that orchestrates them. By separating universal testing concerns from framework-specific ones, we can:</p> <ul> <li>Maximize test reusability across different agent frameworks</li> <li>Establish universal quality and security standards for AI components</li> <li>Enable cross-framework performance comparisons</li> <li>Reduce redundant testing effort when components are used in multiple frameworks</li> <li>Provide a common testing language for heterogeneous AI systems</li> </ul>"},{"location":"testing/architecture/framework_agnostic_testing/#the-third-dimension","title":"The Third Dimension","text":"<p>Our testing framework now operates in three dimensions:</p> <pre><code>Testing Matrix:\n\u251c\u2500\u2500 Dimension 1: Testing Categories\n\u2502   \u251c\u2500\u2500 Quality Assurance (QA)\n\u2502   \u2514\u2500\u2500 Security Testing\n\u251c\u2500\u2500 Dimension 2: Testing Phases\n\u2502   \u251c\u2500\u2500 Development-Time Testing\n\u2502   \u2514\u2500\u2500 Runtime Monitoring\n\u2514\u2500\u2500 Dimension 3: Framework Scope (NEW)\n    \u251c\u2500\u2500 Framework-Agnostic\n    \u2514\u2500\u2500 Framework-Specific\n</code></pre> <p>This creates combinations such as:</p> <ul> <li>Framework-Agnostic Security Runtime LLM Test</li> <li>Framework-Specific QA Development-Time Workflow Test</li> <li>Framework-Agnostic Quality Development-Time MCP Server Test</li> </ul>"},{"location":"testing/architecture/framework_agnostic_testing/#testing-scope-classification","title":"Testing Scope Classification","text":""},{"location":"testing/architecture/framework_agnostic_testing/#framework-agnostic-components","title":"Framework-Agnostic Components","text":"<p>Framework-agnostic testing applies to components and behaviors that operate independently of any specific agent framework:</p> <p>Characteristics:</p> <ul> <li>Direct API interaction without framework mediation</li> <li>Standardized input/output formats</li> <li>Universal evaluation criteria</li> <li>Consistent behavior across frameworks</li> <li>No dependency on framework-specific features</li> </ul> <p>Testing Capabilities:</p> <ul> <li>Direct component invocation</li> <li>Standardized performance metrics</li> <li>Universal security validation</li> <li>Cross-framework result comparison</li> <li>Cached interaction replay</li> </ul>"},{"location":"testing/architecture/framework_agnostic_testing/#framework-specific-components","title":"Framework-Specific Components","text":"<p>Framework-specific testing addresses behaviors and features unique to individual frameworks:</p> <p>Characteristics:</p> <ul> <li>Framework-injected system prompts</li> <li>Proprietary orchestration patterns</li> <li>Custom state management</li> <li>Framework-specific configuration</li> <li>Unique error handling mechanisms</li> </ul> <p>Testing Requirements:</p> <ul> <li>Framework context awareness</li> <li>Adapter-based translation</li> <li>Framework-specific metrics</li> <li>Custom evaluation criteria</li> <li>Native execution environment</li> </ul>"},{"location":"testing/architecture/framework_agnostic_testing/#component-testing-breakdown","title":"Component Testing Breakdown","text":""},{"location":"testing/architecture/framework_agnostic_testing/#llm-testing-100-framework-agnostic","title":"LLM Testing (100% Framework-Agnostic)","text":"<p>Language models operate as stateless services that process text input and generate text output, making them completely framework-independent.</p> <p>Framework-Agnostic Aspects:</p> <ul> <li>Prompt injection resistance</li> <li>Content safety validation</li> <li>Response quality metrics</li> <li>Instruction following accuracy</li> <li>Output format compliance</li> <li>Hallucination detection</li> <li>Performance benchmarking</li> <li>Token usage analysis</li> </ul> <p>Why Fully Agnostic:</p> <ul> <li>LLMs are accessed via standardized APIs (OpenAI, Anthropic, etc.)</li> <li>Input/output is pure text, regardless of calling framework</li> <li>Security and quality concerns are universal</li> <li>No framework can alter core LLM behavior</li> </ul>"},{"location":"testing/architecture/framework_agnostic_testing/#mcp-server-testing-100-framework-agnostic","title":"MCP Server Testing (100% Framework-Agnostic)","text":"<p>Model Context Protocol servers provide tools and resources through standardized interfaces, making them inherently framework-independent.</p> <p>Framework-Agnostic Aspects:</p> <ul> <li>API compliance verification</li> <li>Tool invocation testing</li> <li>Performance benchmarking</li> <li>Error handling validation</li> <li>Authentication and authorization</li> <li>Rate limiting compliance</li> <li>Input validation</li> <li>Resource availability</li> </ul> <p>Why Fully Agnostic:</p> <ul> <li>MCP defines a standard protocol for tool interaction</li> <li>Tools operate independently of calling context</li> <li>Security and reliability requirements are universal</li> <li>Direct testing bypasses framework layers entirely</li> </ul>"},{"location":"testing/architecture/framework_agnostic_testing/#agent-testing-hybrid-60-agnostic-40-specific","title":"Agent Testing (Hybrid: 60% Agnostic, 40% Specific)","text":"<p>Agents combine LLMs and tools with framework-specific orchestration, creating a hybrid testing scenario.</p> <p>Framework-Agnostic Aspects (60%):</p> <ul> <li>Tool selection accuracy</li> <li>Goal achievement metrics</li> <li>Multi-turn conversation coherence</li> <li>Cost efficiency analysis</li> <li>Security boundary validation</li> <li>Resource usage patterns</li> <li>Decision-making quality</li> <li>Task completion rates</li> </ul> <p>Framework-Specific Aspects (40%):</p> <ul> <li>System prompt handling and injection</li> <li>Memory and context management</li> <li>State persistence mechanisms</li> <li>Framework-specific tool integration</li> <li>Error recovery patterns</li> <li>Conversation history management</li> <li>Variable naming and scoping</li> <li>Framework-specific optimizations</li> </ul>"},{"location":"testing/architecture/framework_agnostic_testing/#workflow-testing-20-agnostic-80-specific","title":"Workflow Testing (20% Agnostic, 80% Specific)","text":"<p>Workflows are heavily dependent on framework orchestration capabilities, making them predominantly framework-specific.</p> <p>Framework-Agnostic Aspects (20%):</p> <ul> <li>Business logic validation</li> <li>End-to-end success metrics</li> <li>Data flow integrity</li> <li>Output quality assessment</li> <li>Total cost analysis</li> <li>Compliance verification</li> </ul> <p>Framework-Specific Aspects (80%):</p> <ul> <li>Agent orchestration patterns</li> <li>Inter-agent communication protocols</li> <li>State management across agents</li> <li>Parallel execution strategies</li> <li>Error propagation and recovery</li> <li>Conditional branching logic</li> <li>Framework-specific optimizations</li> <li>Native integration patterns</li> </ul>"},{"location":"testing/architecture/framework_agnostic_testing/#aurite-as-the-universal-standard","title":"Aurite as the Universal Standard","text":""},{"location":"testing/architecture/framework_agnostic_testing/#standardization-philosophy","title":"Standardization Philosophy","text":"<p>Aurite Agents serves as the canonical format and reference implementation for framework-agnostic testing. This design decision is based on several key principles:</p> <p>Canonical Data Structures:</p> <ul> <li>Aurite's configuration formats become the universal language</li> <li>All frameworks translate to/from Aurite's representations</li> <li>Test cases and results use Aurite's data models</li> <li>Standardized metrics and scoring systems</li> </ul> <p>Reference Implementation:</p> <ul> <li>Aurite provides the baseline for expected behavior</li> <li>Other frameworks are compared against Aurite's results</li> <li>Performance benchmarks use Aurite as the standard</li> <li>Security validations follow Aurite's patterns</li> </ul> <p>Benefits of Standardization:</p> <ul> <li>Single source of truth for test definitions</li> <li>Consistent evaluation criteria across frameworks</li> <li>Simplified cross-framework comparisons</li> <li>Reduced complexity in multi-framework environments</li> </ul>"},{"location":"testing/architecture/framework_agnostic_testing/#adapter-pattern-architecture","title":"Adapter Pattern Architecture","text":"<p>The adapter pattern enables translation between framework-specific formats and Aurite's standard:</p> <p>Abstract Adapter Interface:</p> <pre><code>Framework Adapter\n\u251c\u2500\u2500 Configuration Translation\n\u2502   \u251c\u2500\u2500 To Aurite Format\n\u2502   \u2514\u2500\u2500 From Aurite Format\n\u251c\u2500\u2500 Execution Translation\n\u2502   \u251c\u2500\u2500 Request Adaptation\n\u2502   \u2514\u2500\u2500 Response Normalization\n\u251c\u2500\u2500 Context Extraction\n\u2502   \u251c\u2500\u2500 System Prompts\n\u2502   \u251c\u2500\u2500 Framework Variables\n\u2502   \u2514\u2500\u2500 State Information\n\u2514\u2500\u2500 Feature Mapping\n    \u251c\u2500\u2500 Supported Features\n    \u251c\u2500\u2500 Unsupported Features\n    \u2514\u2500\u2500 Feature Compatibility\n</code></pre> <p>Bidirectional Translation Requirements:</p> <ul> <li>Configuration mapping (both directions)</li> <li>Request/response format conversion</li> <li>Error message standardization</li> <li>Metric normalization</li> <li>Result aggregation</li> </ul> <p>Framework Detection and Classification:</p> <ul> <li>Automatic framework identification from configuration</li> <li>Version compatibility checking</li> <li>Feature capability assessment</li> <li>Optimization opportunity detection</li> </ul>"},{"location":"testing/architecture/framework_agnostic_testing/#three-dimensional-testing-matrix","title":"Three-Dimensional Testing Matrix","text":""},{"location":"testing/architecture/framework_agnostic_testing/#matrix-integration","title":"Matrix Integration","text":"<p>The framework scope dimension integrates with existing testing categories and phases:</p> <pre><code>Complete Testing Combinations:\n\u251c\u2500\u2500 Framework-Agnostic\n\u2502   \u251c\u2500\u2500 Quality Assurance\n\u2502   \u2502   \u251c\u2500\u2500 Development-Time\n\u2502   \u2502   \u2514\u2500\u2500 Runtime\n\u2502   \u2514\u2500\u2500 Security\n\u2502       \u251c\u2500\u2500 Development-Time\n\u2502       \u2514\u2500\u2500 Runtime\n\u2514\u2500\u2500 Framework-Specific\n    \u251c\u2500\u2500 Quality Assurance\n    \u2502   \u251c\u2500\u2500 Development-Time\n    \u2502   \u2514\u2500\u2500 Runtime\n    \u2514\u2500\u2500 Security\n        \u251c\u2500\u2500 Development-Time\n        \u2514\u2500\u2500 Runtime\n</code></pre>"},{"location":"testing/architecture/framework_agnostic_testing/#test-inheritance-across-frameworks","title":"Test Inheritance Across Frameworks","text":"<p>Test inheritance now operates across framework boundaries:</p> <p>Inheritance Rules:</p> <ol> <li>Framework-agnostic test results are inherited by all framework-specific tests</li> <li>LLM and MCP test results apply universally</li> <li>Framework-specific agent tests inherit agnostic agent test results</li> </ol> <p>Inheritance Benefits:</p> <ul> <li>Eliminate redundant testing across frameworks</li> <li>Accelerate multi-framework validation</li> <li>Ensure consistent security standards</li> <li>Enable rapid framework migration testing</li> </ul>"},{"location":"testing/architecture/framework_agnostic_testing/#cross-framework-comparison","title":"Cross-Framework Comparison","text":"<p>The three-dimensional matrix enables sophisticated comparisons:</p> <p>Comparison Capabilities:</p> <ul> <li>Performance benchmarking across frameworks</li> <li>Security posture comparison</li> <li>Cost efficiency analysis</li> <li>Feature parity assessment</li> <li>Migration readiness evaluation</li> </ul>"},{"location":"testing/architecture/framework_agnostic_testing/#integration-with-existing-architecture","title":"Integration with Existing Architecture","text":""},{"location":"testing/architecture/framework_agnostic_testing/#relationship-to-compositional-testing","title":"Relationship to Compositional Testing","text":"<p>Framework-agnostic testing extends the compositional testing model:</p> <pre><code>Extended Hierarchy:\nUniversal Foundation (Framework-Agnostic)\n\u251c\u2500\u2500 LLMs (100% Agnostic)\n\u251c\u2500\u2500 MCP Servers (100% Agnostic)\n\u2514\u2500\u2500 Core Agent Behaviors (60% Agnostic)\n    \u2514\u2500\u2500 Framework Layer (Framework-Specific)\n        \u251c\u2500\u2500 Agent Orchestration (40% Specific)\n        \u2514\u2500\u2500 Workflows (80% Specific)\n</code></pre>"},{"location":"testing/architecture/framework_agnostic_testing/#extension-of-test-inheritance","title":"Extension of Test Inheritance","text":"<p>The existing test inheritance patterns extend naturally:</p> <p>Original Inheritance:</p> <ul> <li>LLM \u2192 Agent \u2192 Workflow (within framework)</li> </ul> <p>Extended Inheritance:</p> <ul> <li>Universal LLM \u2192 Any Framework's Agent</li> <li>Universal MCP \u2192 Any Framework's Agent</li> <li>Agnostic Agent Tests \u2192 Specific Agent Tests</li> <li>Cross-Framework Workflow Composition</li> </ul>"},{"location":"testing/architecture/framework_agnostic_testing/#api-exposure","title":"API Exposure","text":"<p>The Aurite API becomes the universal testing service:</p> <p>Service Endpoints:</p> <ul> <li><code>/test/agnostic/llm</code> - Universal LLM testing</li> <li><code>/test/agnostic/mcp</code> - Universal MCP testing</li> <li><code>/test/agnostic/agent</code> - Core agent behavior testing</li> <li><code>/test/framework/{framework}/agent</code> - Framework-specific agent testing</li> <li><code>/test/compare</code> - Cross-framework comparison</li> </ul>"},{"location":"testing/architecture/framework_agnostic_testing/#framework-categories","title":"Framework Categories","text":""},{"location":"testing/architecture/framework_agnostic_testing/#native-frameworks","title":"Native Frameworks","text":"<p>Frameworks with direct integration and full support:</p> <p>Characteristics:</p> <ul> <li>Built-in adapter implementation</li> <li>Full feature compatibility</li> <li>Optimized translation layer</li> <li>Native performance</li> </ul> <p>Examples:</p> <ul> <li>Aurite Agents (reference implementation)</li> <li>Frameworks with official adapters</li> </ul>"},{"location":"testing/architecture/framework_agnostic_testing/#compatible-frameworks","title":"Compatible Frameworks","text":"<p>Frameworks that can be integrated via adapters:</p> <p>Characteristics:</p> <ul> <li>Adapter-based integration</li> <li>Most features supported</li> <li>Some translation overhead</li> <li>Good compatibility</li> </ul> <p>Examples:</p> <ul> <li>LangChain</li> <li>AutoGen</li> <li>CrewAI</li> <li>Custom enterprise frameworks</li> </ul>"},{"location":"testing/architecture/framework_agnostic_testing/#legacy-frameworks","title":"Legacy Frameworks","text":"<p>Older or incompatible frameworks with limited support:</p> <p>Characteristics:</p> <ul> <li>Basic adapter support only</li> <li>Limited feature compatibility</li> <li>Significant translation overhead</li> <li>Partial testing coverage</li> </ul> <p>Examples:</p> <ul> <li>Deprecated framework versions</li> <li>Proprietary closed systems</li> <li>Highly customized implementations</li> </ul>"},{"location":"testing/architecture/framework_agnostic_testing/#testing-service-architecture","title":"Testing Service Architecture","text":""},{"location":"testing/architecture/framework_agnostic_testing/#aurite-as-a-testing-service-provider","title":"Aurite as a Testing Service Provider","text":"<p>Aurite Agents provides testing services to other frameworks:</p> <p>Service Model:</p> <pre><code>Testing Service Architecture:\n\u251c\u2500\u2500 API Gateway\n\u2502   \u251c\u2500\u2500 Authentication\n\u2502   \u251c\u2500\u2500 Rate Limiting\n\u2502   \u2514\u2500\u2500 Request Routing\n\u251c\u2500\u2500 Test Orchestrator\n\u2502   \u251c\u2500\u2500 Framework Detection\n\u2502   \u251c\u2500\u2500 Adapter Selection\n\u2502   \u2514\u2500\u2500 Test Scheduling\n\u251c\u2500\u2500 Execution Engine\n\u2502   \u251c\u2500\u2500 Agnostic Tests\n\u2502   \u251c\u2500\u2500 Specific Tests\n\u2502   \u2514\u2500\u2500 Comparison Tests\n\u2514\u2500\u2500 Result Aggregator\n    \u251c\u2500\u2500 Standardization\n    \u251c\u2500\u2500 Scoring\n    \u2514\u2500\u2500 Reporting\n</code></pre>"},{"location":"testing/architecture/framework_agnostic_testing/#framework-agnostic-api-endpoints","title":"Framework-Agnostic API Endpoints","text":"<p>Universal testing endpoints that work across all frameworks:</p> <p>Core Endpoints:</p> <ul> <li>Component registration</li> <li>Test execution</li> <li>Result retrieval</li> <li>Metric aggregation</li> <li>Comparison analysis</li> </ul> <p>Authentication &amp; Authorization:</p> <ul> <li>API key-based access</li> <li>Framework-specific credentials</li> <li>Rate limiting per framework</li> <li>Usage tracking and billing</li> </ul>"},{"location":"testing/architecture/framework_agnostic_testing/#standardized-result-formats","title":"Standardized Result Formats","text":"<p>All test results follow Aurite's standard format:</p> <p>Result Structure:</p> <pre><code>TestResult:\n\u251c\u2500\u2500 Metadata\n\u2502   \u251c\u2500\u2500 Framework\n\u2502   \u251c\u2500\u2500 Component Type\n\u2502   \u251c\u2500\u2500 Test Category\n\u2502   \u2514\u2500\u2500 Timestamp\n\u251c\u2500\u2500 Scores\n\u2502   \u251c\u2500\u2500 Overall Score\n\u2502   \u251c\u2500\u2500 Category Scores\n\u2502   \u2514\u2500\u2500 Detailed Metrics\n\u251c\u2500\u2500 Issues\n\u2502   \u251c\u2500\u2500 Failures\n\u2502   \u251c\u2500\u2500 Warnings\n\u2502   \u2514\u2500\u2500 Recommendations\n\u2514\u2500\u2500 Comparison\n    \u251c\u2500\u2500 Baseline Comparison\n    \u251c\u2500\u2500 Cross-Framework Analysis\n    \u2514\u2500\u2500 Historical Trends\n</code></pre>"},{"location":"testing/architecture/framework_agnostic_testing/#implementation-roadmap","title":"Implementation Roadmap","text":""},{"location":"testing/architecture/framework_agnostic_testing/#phase-1-foundation-framework-agnostic-components","title":"Phase 1: Foundation (Framework-Agnostic Components)","text":"<ul> <li>Establish LLM testing services</li> <li>Implement MCP server testing</li> <li>Define standard data formats</li> <li>Create base adapter interface</li> </ul>"},{"location":"testing/architecture/framework_agnostic_testing/#phase-2-hybrid-components-agent-testing","title":"Phase 2: Hybrid Components (Agent Testing)","text":"<ul> <li>Separate agnostic vs specific agent tests</li> <li>Implement agent simulation engine</li> <li>Create framework detection system</li> <li>Build adapter for one additional framework</li> </ul>"},{"location":"testing/architecture/framework_agnostic_testing/#phase-3-framework-integration","title":"Phase 3: Framework Integration","text":"<ul> <li>Develop adapters for major frameworks</li> <li>Implement cross-framework comparison</li> <li>Create migration testing tools</li> <li>Establish performance baselines</li> </ul>"},{"location":"testing/architecture/framework_agnostic_testing/#phase-4-service-deployment","title":"Phase 4: Service Deployment","text":"<ul> <li>Deploy testing API services</li> <li>Implement authentication and billing</li> <li>Create developer documentation</li> <li>Build testing dashboard</li> </ul>"},{"location":"testing/architecture/framework_agnostic_testing/#benefits-and-impact","title":"Benefits and Impact","text":""},{"location":"testing/architecture/framework_agnostic_testing/#for-developers","title":"For Developers","text":"<ul> <li>Test once, validate everywhere</li> <li>Simplified multi-framework development</li> <li>Consistent quality standards</li> <li>Reduced testing overhead</li> </ul>"},{"location":"testing/architecture/framework_agnostic_testing/#for-organizations","title":"For Organizations","text":"<ul> <li>Framework vendor independence</li> <li>Simplified compliance validation</li> <li>Reduced testing costs</li> <li>Accelerated framework adoption</li> </ul>"},{"location":"testing/architecture/framework_agnostic_testing/#for-the-ecosystem","title":"For the Ecosystem","text":"<ul> <li>Universal quality standards</li> <li>Cross-framework interoperability</li> <li>Shared security baselines</li> <li>Industry-wide best practices</li> </ul>"},{"location":"testing/architecture/framework_agnostic_testing/#related-documentation","title":"Related Documentation","text":"<ul> <li>Testing Hierarchy - Complete testing hierarchy and flow</li> <li>Testing Architecture - Core architectural principles</li> <li>Test Inheritance - Test result inheritance patterns</li> <li>Kahuna Testing &amp; Security Framework - Framework overview</li> </ul>"},{"location":"testing/architecture/test_inheritance/","title":"Test Inheritance","text":""},{"location":"testing/architecture/test_inheritance/#overview","title":"Overview","text":"<p>Test inheritance is the mechanism by which higher-level components automatically benefit from the validation of their dependencies, both within a single framework and across multiple agent frameworks. This document details how test results flow through the component hierarchy and how to implement efficient inheritance patterns that maximize test reuse through framework-agnostic validation.</p>"},{"location":"testing/architecture/test_inheritance/#inheritance-principles","title":"Inheritance Principles","text":""},{"location":"testing/architecture/test_inheritance/#1-once-tested-always-trusted","title":"1. Once Tested, Always Trusted","text":"<p>When a foundation component passes testing, all components using it can trust those results without retesting. For framework-agnostic components (LLMs and MCP Servers), this trust extends across ALL frameworks:</p> <pre><code>LLM passes prompt injection test at 10:00 AM (via Aurite framework)\n  \u2193\nAgent A using this LLM at 10:30 AM (LangChain) \u2192 Inherits \"PASS\"\nAgent B using this LLM at 10:45 AM (AutoGen) \u2192 Inherits \"PASS\"\nAgent C using this LLM at 11:00 AM (Aurite) \u2192 Inherits \"PASS\"\n  \u2193\nNo need to retest prompt injection for any agent in any framework\n</code></pre>"},{"location":"testing/architecture/test_inheritance/#2-weakest-link-security","title":"2. Weakest Link Security","text":"<p>Security scores propagate using the minimum value principle:</p> <pre><code>Workflow Security Score = MIN(\n    Agent1 Security,\n    Agent2 Security,\n    Workflow-Specific Security\n)\n\nWhere each Agent Security = MIN(\n    LLM Security (100% agnostic),\n    MCP Security (100% agnostic),\n    Agent-Specific Security (40% framework-specific)\n)\n</code></pre>"},{"location":"testing/architecture/test_inheritance/#3-composite-quality","title":"3. Composite Quality","text":"<p>Quality scores combine multiplicatively to reflect cumulative degradation:</p> <pre><code>Workflow Quality =\n    (Agent1 Quality \u00d7 Weight1) +\n    (Agent2 Quality \u00d7 Weight2) +\n    (Workflow Quality \u00d7 Weight3)\n\nWhere weights sum to 1.0\n</code></pre>"},{"location":"testing/architecture/test_inheritance/#4-cross-framework-inheritance","title":"4. Cross-Framework Inheritance","text":"<p>Framework-agnostic test results are inherited across all framework implementations:</p> <pre><code>Component Agnostic % \u2192 Cross-Framework Inheritance\nLLM: 100% \u2192 All results shared across frameworks\nMCP: 100% \u2192 All results shared across frameworks\nAgent: 60% \u2192 Core behavior results shared\nWorkflow: 20% \u2192 Business logic results shared\n</code></pre>"},{"location":"testing/architecture/test_inheritance/#inheritance-data-model","title":"Inheritance Data Model","text":""},{"location":"testing/architecture/test_inheritance/#test-result-structure","title":"Test Result Structure","text":"<pre><code>@dataclass\nclass TestResult:\n    \"\"\"Base test result with inheritance support\"\"\"\n    component_id: str\n    component_type: str\n    timestamp: datetime\n    version: str\n\n    # Framework context\n    framework: str  # Framework that ran the test\n    is_agnostic: bool  # Whether results are framework-agnostic\n    cross_framework_validity: bool  # Can be shared across frameworks\n\n    # Direct test results\n    direct_tests: Dict[str, TestScore]\n\n    # Inherited results\n    inherited_results: Dict[str, InheritedResult]\n\n    # Composite scores\n    composite_scores: CompositeScores\n\n    # Metadata\n    dependencies: List[ComponentDependency]\n    inheritance_chain: List[str]\n    confidence_level: float\n    framework_confidence: Dict[str, float]  # Confidence per framework\n\n@dataclass\nclass InheritedResult:\n    \"\"\"Represents an inherited test result\"\"\"\n    source_component: str\n    source_version: str\n    source_framework: str  # Framework that originally ran the test\n    original_timestamp: datetime\n    test_name: str\n    score: float\n    status: str\n    ttl_remaining: int  # Time-to-live in seconds\n    is_universal: bool  # True for framework-agnostic results\n    inheritance_type: str  # \"direct\", \"cross-framework\", \"transformed\"\n\n@dataclass\nclass CompositeScores:\n    \"\"\"Aggregated scores with inheritance\"\"\"\n    quality: float\n    security: float\n    performance: float\n    reliability: float\n\n    # Breakdown by source\n    quality_breakdown: Dict[str, float]\n    security_breakdown: Dict[str, float]\n</code></pre>"},{"location":"testing/architecture/test_inheritance/#inheritance-patterns","title":"Inheritance Patterns","text":""},{"location":"testing/architecture/test_inheritance/#pattern-1-direct-inheritance","title":"Pattern 1: Direct Inheritance","text":"<p>Simple pass-through of test results from dependency to dependent within the same framework:</p> <pre><code>class DirectInheritance:\n    def inherit_results(self, component, dependency_results):\n        inherited = {}\n\n        for dep_id, dep_result in dependency_results.items():\n            # Direct inheritance of applicable tests\n            for test_name, test_score in dep_result.direct_tests.items():\n                if self.is_inheritable(test_name, component.type):\n                    inherited[f\"{dep_id}.{test_name}\"] = InheritedResult(\n                        source_component=dep_id,\n                        source_version=dep_result.version,\n                        original_timestamp=dep_result.timestamp,\n                        test_name=test_name,\n                        score=test_score.value,\n                        status=test_score.status,\n                        ttl_remaining=self.calculate_ttl(dep_result)\n                    )\n\n        return inherited\n</code></pre>"},{"location":"testing/architecture/test_inheritance/#pattern-2-filtered-inheritance","title":"Pattern 2: Filtered Inheritance","text":"<p>Selective inheritance based on relevance:</p> <pre><code>class FilteredInheritance:\n    # Define what each component type inherits\n    INHERITANCE_RULES = {\n        \"agent\": {\n            \"from_llm\": [\n                \"prompt_injection_resistance\",\n                \"content_safety\",\n                \"output_format_compliance\"\n            ],\n            \"from_mcp\": [\n                \"api_availability\",\n                \"authentication_status\",\n                \"rate_limit_compliance\"\n            ]\n        },\n        \"workflow\": {\n            \"from_agent\": [\n                \"goal_achievement_rate\",\n                \"tool_usage_efficiency\",\n                \"security_compliance\"\n            ]\n        }\n    }\n\n    def inherit_filtered(self, component_type, source_type, test_results):\n        rules = self.INHERITANCE_RULES.get(component_type, {})\n        inheritable_tests = rules.get(f\"from_{source_type}\", [])\n\n        return {\n            test: result\n            for test, result in test_results.items()\n            if test in inheritable_tests\n        }\n</code></pre>"},{"location":"testing/architecture/test_inheritance/#pattern-3-transformed-inheritance","title":"Pattern 3: Transformed Inheritance","text":"<p>Modify inherited scores based on context:</p> <pre><code>class TransformedInheritance:\n    def inherit_with_transformation(self, component, dependency_results):\n        inherited = {}\n\n        for dep_id, dep_result in dependency_results.items():\n            # Apply transformation based on dependency importance\n            importance = self.get_dependency_importance(component, dep_id)\n\n            for test_name, score in dep_result.items():\n                # Transform score based on importance\n                transformed_score = self.transform_score(\n                    score,\n                    importance,\n                    component.risk_profile\n                )\n\n                inherited[f\"{dep_id}.{test_name}\"] = transformed_score\n\n        return inherited\n\n    def transform_score(self, original_score, importance, risk_profile):\n        if risk_profile == \"high\":\n            # More conservative for high-risk components\n            return original_score * 0.9 * importance\n        elif risk_profile == \"low\":\n            # More lenient for low-risk components\n            return min(1.0, original_score * 1.1 * importance)\n        else:\n            return original_score * importance\n</code></pre>"},{"location":"testing/architecture/test_inheritance/#pattern-4-universal-inheritance","title":"Pattern 4: Universal Inheritance","text":"<p>Framework-agnostic results that propagate across all frameworks:</p> <pre><code>class UniversalInheritance:\n    def inherit_universal(self, component, dependency_results, target_framework):\n        inherited = {}\n\n        for dep_id, dep_result in dependency_results.items():\n            # Check if results are framework-agnostic\n            if dep_result.is_agnostic or dep_result.component_type in [\"llm\", \"mcp\"]:\n                for test_name, test_score in dep_result.direct_tests.items():\n                    inherited[f\"{dep_id}.{test_name}\"] = InheritedResult(\n                        source_component=dep_id,\n                        source_version=dep_result.version,\n                        source_framework=dep_result.framework,\n                        original_timestamp=dep_result.timestamp,\n                        test_name=test_name,\n                        score=test_score.value,\n                        status=test_score.status,\n                        ttl_remaining=self.calculate_universal_ttl(dep_result),\n                        is_universal=True,\n                        inheritance_type=\"cross-framework\"\n                    )\n\n        return inherited\n</code></pre>"},{"location":"testing/architecture/test_inheritance/#pattern-5-framework-boundary-inheritance","title":"Pattern 5: Framework Boundary Inheritance","text":"<p>Handle inheritance when components use different frameworks:</p> <pre><code>class FrameworkBoundaryInheritance:\n    def inherit_across_frameworks(self, component, dependency_results):\n        inherited = {}\n        adapter = self.get_framework_adapter(component.framework)\n\n        for dep_id, dep_result in dependency_results.items():\n            # Determine what can be inherited\n            if dep_result.framework != component.framework:\n                # Only inherit agnostic results across framework boundaries\n                agnostic_percentage = self.get_agnostic_percentage(dep_result.component_type)\n\n                for test_name, test_score in dep_result.direct_tests.items():\n                    if self.is_agnostic_test(test_name, dep_result.component_type):\n                        # Translate and inherit\n                        translated_result = adapter.translate_result(test_score)\n                        inherited[f\"{dep_id}.{test_name}\"] = translated_result\n            else:\n                # Same framework - inherit everything\n                inherited.update(self.inherit_direct(dep_id, dep_result))\n\n        return inherited\n</code></pre>"},{"location":"testing/architecture/test_inheritance/#inheritance-lifecycle","title":"Inheritance Lifecycle","text":""},{"location":"testing/architecture/test_inheritance/#1-test-execution-phase","title":"1. Test Execution Phase","text":"<pre><code>async def execute_with_inheritance(component, framework=\"aurite\"):\n    # Step 1: Check universal cache for agnostic results\n    universal_results = await check_universal_cache(component.dependencies)\n\n    # Step 2: Gather framework-specific dependency results\n    dep_results = await gather_dependency_results(component.dependencies, framework)\n\n    # Step 3: Merge universal and framework-specific results\n    all_results = merge_results(universal_results, dep_results)\n\n    # Step 4: Check if dependencies passed\n    if not all_dependencies_passed(all_results):\n        return blocked_result(component, all_results)\n\n    # Step 5: Inherit applicable results (both agnostic and specific)\n    inherited = inherit_results(component, all_results, framework)\n\n    # Step 6: Run component-specific tests\n    agnostic_tests, specific_tests = categorize_tests(component)\n    direct_tests = await run_direct_tests(component, agnostic_tests, specific_tests)\n\n    # Step 7: Combine and cache results\n    final_results = combine_results(inherited, direct_tests)\n    cache_results(final_results, framework)\n\n    return final_results\n</code></pre>"},{"location":"testing/architecture/test_inheritance/#2-result-aggregation-phase","title":"2. Result Aggregation Phase","text":"<pre><code>def aggregate_inherited_results(inherited_results, direct_results):\n    aggregated = {\n        \"quality\": calculate_quality_score(inherited_results, direct_results),\n        \"security\": calculate_security_score(inherited_results, direct_results),\n        \"performance\": calculate_performance_score(inherited_results, direct_results)\n    }\n\n    # Add confidence based on inheritance freshness\n    aggregated[\"confidence\"] = calculate_confidence(inherited_results)\n\n    return aggregated\n\ndef calculate_confidence(inherited_results):\n    \"\"\"Calculate confidence based on age and version of inherited results\"\"\"\n    confidence = 1.0\n\n    for result in inherited_results.values():\n        age_factor = 1.0 - (time_since(result.original_timestamp) / MAX_AGE)\n        version_factor = 1.0 if result.source_version == CURRENT_VERSION else 0.8\n\n        confidence *= (age_factor * version_factor)\n\n    return max(0.5, confidence)  # Minimum 50% confidence\n</code></pre>"},{"location":"testing/architecture/test_inheritance/#3-cache-management-phase","title":"3. Cache Management Phase","text":"<pre><code>class InheritanceCache:\n    def __init__(self):\n        self.universal_cache = {}  # Framework-agnostic results\n        self.framework_cache = {}  # Framework-specific results\n        self.version_map = {}\n\n    def store_result(self, component_id, result, framework=\"aurite\"):\n        \"\"\"Store result with framework context\"\"\"\n        cache_entry = {\n            \"result\": result,\n            \"timestamp\": datetime.now(),\n            \"version\": result.version,\n            \"framework\": framework,\n            \"inheritable_until\": self.calculate_ttl(result)\n        }\n\n        # Store in appropriate cache\n        if result.is_agnostic or result.component_type in [\"llm\", \"mcp\"]:\n            self.universal_cache[component_id] = cache_entry\n            cache_entry[\"inheritable_until\"] = datetime.now() + timedelta(hours=24)\n        else:\n            if framework not in self.framework_cache:\n                self.framework_cache[framework] = {}\n            self.framework_cache[framework][component_id] = cache_entry\n\n        # Track version for invalidation\n        self.version_map[component_id] = result.version\n\n    def get_inheritable_result(self, component_id, framework=\"aurite\"):\n        \"\"\"Get result from universal or framework cache\"\"\"\n        # Check universal cache first\n        if component_id in self.universal_cache:\n            cached = self.universal_cache[component_id]\n            if self.is_valid_cache(cached):\n                return cached[\"result\"]\n\n        # Check framework-specific cache\n        if framework in self.framework_cache:\n            if component_id in self.framework_cache[framework]:\n                cached = self.framework_cache[framework][component_id]\n                if self.is_valid_cache(cached):\n                    return cached[\"result\"]\n\n        return None\n\n    def is_valid_cache(self, cached):\n        \"\"\"Check if cached result is still valid\"\"\"\n        if datetime.now() &gt; cached[\"inheritable_until\"]:\n            return False\n        if self.version_map.get(cached[\"result\"].component_id) != cached[\"version\"]:\n            return False\n        return True\n\n    def invalidate_cascade(self, component_id, framework=None):\n        \"\"\"Invalidate component and all dependents\"\"\"\n        # Remove from universal cache\n        if component_id in self.universal_cache:\n            del self.universal_cache[component_id]\n            # Universal invalidation affects all frameworks\n            for fw in self.framework_cache.values():\n                if component_id in fw:\n                    del fw[component_id]\n\n        # Remove from specific framework cache\n        elif framework and framework in self.framework_cache:\n            if component_id in self.framework_cache[framework]:\n                del self.framework_cache[framework][component_id]\n\n        # Find and invalidate dependents\n        dependents = self.find_dependents(component_id)\n        for dep in dependents:\n            self.invalidate_cascade(dep, framework)\n\n    def calculate_ttl(self, result):\n        \"\"\"Calculate TTL based on component type and framework scope\"\"\"\n        ttl_map = {\n            \"llm\": timedelta(hours=24),      # 100% agnostic\n            \"mcp\": timedelta(hours=24),      # 100% agnostic\n            \"agent\": timedelta(hours=12),    # 60% agnostic\n            \"workflow\": timedelta(hours=1)   # 20% agnostic\n        }\n        return datetime.now() + ttl_map.get(result.component_type, timedelta(hours=4))\n</code></pre>"},{"location":"testing/architecture/test_inheritance/#inheritance-rules-by-component-type","title":"Inheritance Rules by Component Type","text":""},{"location":"testing/architecture/test_inheritance/#llm-inheritance-rules","title":"LLM Inheritance Rules","text":"<p>LLMs are foundation components and don't inherit:</p> <pre><code>LLM_INHERITANCE = {\n    \"inherits_from\": [],\n    \"provides_to\": [\"agent\"],\n    \"framework_agnostic\": True,  # 100% agnostic\n    \"cross_framework_inheritance\": 1.0,  # All results shared\n    \"inheritable_tests\": [\n        \"prompt_injection_resistance\",\n        \"content_safety_score\",\n        \"hallucination_rate\",\n        \"instruction_following_accuracy\",\n        \"output_format_compliance\"\n    ],\n    \"cache_ttl\": 24  # Hours - longer for agnostic components\n}\n</code></pre>"},{"location":"testing/architecture/test_inheritance/#mcp-server-inheritance-rules","title":"MCP Server Inheritance Rules","text":"<p>MCP Servers are foundation components and don't inherit:</p> <pre><code>MCP_INHERITANCE = {\n    \"inherits_from\": [],\n    \"provides_to\": [\"agent\"],\n    \"framework_agnostic\": True,  # 100% agnostic\n    \"cross_framework_inheritance\": 1.0,  # All results shared\n    \"inheritable_tests\": [\n        \"api_availability\",\n        \"response_time_p95\",\n        \"error_rate\",\n        \"authentication_validity\",\n        \"rate_limit_compliance\"\n    ],\n    \"cache_ttl\": 24  # Hours - longer for agnostic components\n}\n</code></pre>"},{"location":"testing/architecture/test_inheritance/#agent-inheritance-rules","title":"Agent Inheritance Rules","text":"<p>Agents inherit from both LLMs and MCP Servers:</p> <pre><code>AGENT_INHERITANCE = {\n    \"inherits_from\": [\"llm\", \"mcp_server\"],\n    \"provides_to\": [\"workflow\"],\n    \"framework_agnostic\": False,  # Hybrid\n    \"cross_framework_inheritance\": 0.6,  # 60% agnostic\n    \"inheritable_tests\": {\n        \"agnostic\": [  # Cross-framework tests\n            \"goal_achievement_rate\",\n            \"tool_selection_accuracy\"\n        ],\n        \"specific\": [  # Framework-specific tests\n            \"multi_turn_coherence\",\n            \"resource_efficiency\",\n            \"security_compliance\"\n        ]\n    },\n    \"inheritance_weights\": {\n        \"llm\": 0.4,\n        \"mcp_server\": 0.3,\n        \"agent_specific\": 0.3\n    },\n    \"cache_ttl\": {\n        \"agnostic\": 12,  # Hours for agnostic results\n        \"specific\": 4    # Hours for specific results\n    }\n}\n</code></pre>"},{"location":"testing/architecture/test_inheritance/#workflow-inheritance-rules","title":"Workflow Inheritance Rules","text":"<p>Workflows inherit from all constituent agents:</p> <pre><code>WORKFLOW_INHERITANCE = {\n    \"inherits_from\": [\"agent\"],\n    \"provides_to\": [],\n    \"framework_agnostic\": False,  # Mostly specific\n    \"cross_framework_inheritance\": 0.2,  # 20% agnostic\n    \"inheritable_tests\": {\n        \"agnostic\": [  # Cross-framework tests\n            \"business_logic_compliance\",\n            \"end_to_end_success_rate\"\n        ],\n        \"specific\": [  # Framework-specific tests\n            \"sla_adherence\",\n            \"data_consistency\",\n            \"audit_completeness\"\n        ]\n    },\n    \"inheritance_weights\": \"dynamic\",  # Based on agent importance\n    \"cache_ttl\": {\n        \"agnostic\": 4,   # Hours for agnostic results\n        \"specific\": 1    # Hour for specific results\n    }\n}\n</code></pre>"},{"location":"testing/architecture/test_inheritance/#inheritance-validation","title":"Inheritance Validation","text":""},{"location":"testing/architecture/test_inheritance/#ensuring-inheritance-integrity","title":"Ensuring Inheritance Integrity","text":"<pre><code>class InheritanceValidator:\n    def validate_inheritance_chain(self, component_result):\n        \"\"\"Validate that inheritance chain is complete and valid\"\"\"\n        issues = []\n\n        # Check all required dependencies are present\n        for dep in component_result.dependencies:\n            if dep.id not in component_result.inherited_results:\n                issues.append(f\"Missing inheritance from {dep.id}\")\n\n        # Check inheritance freshness\n        for inherited in component_result.inherited_results.values():\n            if inherited.ttl_remaining &lt;= 0:\n                issues.append(f\"Expired inheritance from {inherited.source_component}\")\n\n        # Check version compatibility\n        for inherited in component_result.inherited_results.values():\n            if not self.is_version_compatible(inherited.source_version):\n                issues.append(f\"Incompatible version from {inherited.source_component}\")\n\n        return issues\n</code></pre>"},{"location":"testing/architecture/test_inheritance/#framework-adaptation-in-inheritance","title":"Framework Adaptation in Inheritance","text":""},{"location":"testing/architecture/test_inheritance/#cross-framework-confidence-scoring","title":"Cross-Framework Confidence Scoring","text":"<pre><code>def calculate_cross_framework_confidence(inherited_result, target_framework):\n    \"\"\"Calculate confidence when inheriting across frameworks\"\"\"\n    base_confidence = inherited_result.confidence_level\n\n    # Adjust confidence based on framework compatibility\n    if inherited_result.is_universal:\n        # Universal results maintain high confidence\n        return base_confidence * 0.95\n    elif inherited_result.source_framework == target_framework:\n        # Same framework maintains full confidence\n        return base_confidence\n    else:\n        # Cross-framework inheritance reduces confidence\n        agnostic_ratio = get_agnostic_ratio(inherited_result.component_type)\n        return base_confidence * agnostic_ratio * 0.9\n</code></pre>"},{"location":"testing/architecture/test_inheritance/#framework-migration-inheritance","title":"Framework Migration Inheritance","text":"<pre><code>def migrate_inheritance(component, old_framework, new_framework):\n    \"\"\"Handle inheritance during framework migration\"\"\"\n    migration_results = {}\n\n    # Get existing results from old framework\n    old_results = get_cached_results(component, old_framework)\n\n    for test_name, result in old_results.items():\n        if is_agnostic_test(test_name, component.type):\n            # Agnostic tests transfer directly\n            migration_results[test_name] = result\n            migration_results[test_name].framework = new_framework\n        else:\n            # Framework-specific tests need re-execution\n            migration_results[test_name] = {\n                \"status\": \"pending_retest\",\n                \"reason\": \"framework_migration\",\n                \"old_result\": result\n            }\n\n    return migration_results\n</code></pre>"},{"location":"testing/architecture/test_inheritance/#best-practices","title":"Best Practices","text":""},{"location":"testing/architecture/test_inheritance/#1-clear-inheritance-boundaries","title":"1. Clear Inheritance Boundaries","text":"<ul> <li>Document what each component inherits</li> <li>Specify which tests are inheritable</li> <li>Define inheritance weights explicitly</li> <li>Distinguish framework-agnostic from framework-specific tests</li> </ul>"},{"location":"testing/architecture/test_inheritance/#2-version-management","title":"2. Version Management","text":"<ul> <li>Track component versions in test results</li> <li>Invalidate inheritance on version changes</li> <li>Maintain version compatibility matrix</li> <li>Track framework versions for cross-framework compatibility</li> </ul>"},{"location":"testing/architecture/test_inheritance/#3-time-based-validity","title":"3. Time-Based Validity","text":"<ul> <li>Set appropriate TTL for inherited results</li> <li>Refresh inheritance periodically</li> <li>Alert on stale inheritance</li> <li>Use longer TTLs for framework-agnostic results</li> </ul>"},{"location":"testing/architecture/test_inheritance/#4-audit-trail","title":"4. Audit Trail","text":"<ul> <li>Log all inheritance decisions</li> <li>Track inheritance chain</li> <li>Enable inheritance debugging</li> <li>Record cross-framework inheritance paths</li> </ul>"},{"location":"testing/architecture/test_inheritance/#5-cross-framework-validation","title":"5. Cross-Framework Validation","text":"<ul> <li>Validate inherited results when crossing framework boundaries</li> <li>Maintain confidence scores for cross-framework inheritance</li> <li>Document framework-specific adaptations</li> <li>Test inheritance integrity across frameworks</li> </ul>"},{"location":"testing/architecture/test_inheritance/#6-universal-cache-management","title":"6. Universal Cache Management","text":"<ul> <li>Prioritize universal cache for agnostic components</li> <li>Implement cache warming for frequently used components</li> <li>Monitor cache hit rates across frameworks</li> <li>Optimize TTLs based on component stability</li> </ul>"},{"location":"testing/architecture/test_inheritance/#example-complete-inheritance-flow","title":"Example: Complete Inheritance Flow","text":"<pre><code># 1. LLM Testing (Foundation - 100% Agnostic)\nllm_result = {\n    \"component_id\": \"gpt-4\",\n    \"framework\": \"aurite\",  # Tested via Aurite\n    \"is_agnostic\": True,\n    \"cross_framework_validity\": True,\n    \"direct_tests\": {\n        \"prompt_injection\": 0.95,\n        \"content_safety\": 0.98\n    }\n}\n\n# 2. MCP Testing (Foundation - 100% Agnostic)\nmcp_result = {\n    \"component_id\": \"crm_api\",\n    \"framework\": \"langchain\",  # Tested via LangChain\n    \"is_agnostic\": True,\n    \"cross_framework_validity\": True,\n    \"direct_tests\": {\n        \"availability\": 0.99,\n        \"performance\": 0.94\n    }\n}\n\n# 3. Agent Testing (Inherits cross-framework - 60% Agnostic)\nagent_result = {\n    \"component_id\": \"support_agent\",\n    \"framework\": \"autogen\",  # Running in AutoGen\n    \"is_agnostic\": False,  # Hybrid component\n    \"cross_framework_validity\": 0.6,  # 60% shareable\n    \"inherited_results\": {\n        # Universal inheritance from different frameworks\n        \"gpt-4.prompt_injection\": {\n            \"score\": 0.95,\n            \"source_framework\": \"aurite\",\n            \"is_universal\": True\n        },\n        \"gpt-4.content_safety\": {\n            \"score\": 0.98,\n            \"source_framework\": \"aurite\",\n            \"is_universal\": True\n        },\n        \"crm_api.availability\": {\n            \"score\": 0.99,\n            \"source_framework\": \"langchain\",\n            \"is_universal\": True\n        },\n        \"crm_api.performance\": {\n            \"score\": 0.94,\n            \"source_framework\": \"langchain\",\n            \"is_universal\": True\n        }\n    },\n    \"direct_tests\": {\n        \"tool_selection\": 0.92,  # Agnostic test\n        \"goal_achievement\": 0.89,  # Agnostic test\n        \"memory_management\": 0.87  # Framework-specific\n    },\n    \"composite_scores\": {\n        \"quality\": 0.91,\n        \"security\": 0.95,\n        \"framework_confidence\": {\n            \"aurite\": 0.95,\n            \"langchain\": 0.93,\n            \"autogen\": 1.0\n        }\n    }\n}\n\n# 4. Workflow Testing (Mixed framework - 20% Agnostic)\nworkflow_result = {\n    \"component_id\": \"support_workflow\",\n    \"framework\": \"aurite\",  # Workflow in Aurite\n    \"is_agnostic\": False,\n    \"cross_framework_validity\": 0.2,  # 20% shareable\n    \"inherited_results\": {\n        # Inheriting from AutoGen agent\n        \"support_agent.quality\": {\n            \"score\": 0.91,\n            \"source_framework\": \"autogen\",\n            \"is_universal\": False,\n            \"confidence\": 0.85  # Reduced confidence across frameworks\n        },\n        \"support_agent.security\": {\n            \"score\": 0.95,\n            \"source_framework\": \"autogen\",\n            \"is_universal\": False,\n            \"confidence\": 0.90\n        }\n    },\n    \"direct_tests\": {\n        \"business_logic\": 0.96,  # Agnostic\n        \"end_to_end\": 0.93,  # Agnostic\n        \"orchestration\": 0.91  # Framework-specific\n    },\n    \"composite_scores\": {\n        \"quality\": 0.92,\n        \"security\": 0.95,\n        \"business_compliance\": 0.94,\n        \"cross_framework_confidence\": 0.88\n    }\n}\n</code></pre>"},{"location":"testing/architecture/test_inheritance/#related-documentation","title":"Related Documentation","text":"<ul> <li>Framework-Agnostic Testing Architecture</li> <li>Testing Architecture</li> <li>Testing Hierarchy and Flow</li> <li>Component Testing Guides</li> <li>Kahuna Testing &amp; Security Framework</li> </ul>"},{"location":"testing/architecture/testing_architecture/","title":"Testing Implementation Architecture","text":""},{"location":"testing/architecture/testing_architecture/#overview","title":"Overview","text":"<p>The Aurite Testing Framework implements a three-level orchestration architecture that provides clear separation of concerns while enabling comprehensive testing across Quality Assurance (QA) and Security domains. This architecture supports both framework-agnostic and framework-specific testing, allowing validation of AI components independent of the specific agent framework being used.</p> <p>The framework integrates seamlessly with Aurite's existing configuration system and maintains a clean, focused structure that prioritizes the most essential components while keeping specialized features appropriately organized.</p>"},{"location":"testing/architecture/testing_architecture/#final-file-structure","title":"Final File Structure","text":"<pre><code>src/aurite/testing/\n\u251c\u2500\u2500 __init__.py\n\u251c\u2500\u2500 README.md\n\u251c\u2500\u2500 test_engine.py               # Level 1: Main orchestrator\n\u251c\u2500\u2500 test_models.py               # Shared models between QA and Security\n\u2502\n\u251c\u2500\u2500 cache/                       # Test result caching\n\u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2514\u2500\u2500 result_cache.py\n\u2502\n\u251c\u2500\u2500 runners/                     # Component execution (includes framework adapters)\n\u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u251c\u2500\u2500 llm_guard.py            # LLM Guard tool\n\u2502   \u251c\u2500\u2500 mcp_test_host.py        # MCP testing host\n\u2502   \u251c\u2500\u2500 agent_runner.py         # Generic agent execution\n\u2502   \u2514\u2500\u2500 adapters/               # Framework adapters\n\u2502       \u251c\u2500\u2500 __init__.py\n\u2502       \u251c\u2500\u2500 aurite_adapter.py       # Native Aurite execution\n\u2502       \u251c\u2500\u2500 langchain_adapter.py    # LangChain framework execution\n\u2502       \u2514\u2500\u2500 autogen_adapter.py      # AutoGen framework execution\n\u2502\n\u251c\u2500\u2500 qa/                          # QA Domain\n\u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u251c\u2500\u2500 qa_engine.py            # Level 2: QA orchestrator\n\u2502   \u251c\u2500\u2500 qa_models.py            # QA-specific models (includes framework field)\n\u2502   \u251c\u2500\u2500 base_qa_tester.py       # Base class for QA testers\n\u2502   \u2514\u2500\u2500 components/             # Level 3: QA component testers\n\u2502       \u251c\u2500\u2500 __init__.py\n\u2502       \u251c\u2500\u2500 llm_qa_tester.py\n\u2502       \u251c\u2500\u2500 mcp_qa_tester.py\n\u2502       \u251c\u2500\u2500 agent_qa_tester.py\n\u2502       \u2514\u2500\u2500 workflow_qa_tester.py\n\u2502\n\u2514\u2500\u2500 security/                    # Security Domain\n    \u251c\u2500\u2500 __init__.py\n    \u251c\u2500\u2500 security_engine.py      # Level 2: Security orchestrator\n    \u251c\u2500\u2500 security_models.py      # Security-specific models\n    \u251c\u2500\u2500 base_security_tester.py # Base class for Security testers\n    \u251c\u2500\u2500 components/             # Level 3: Security component testers\n    \u2502   \u251c\u2500\u2500 __init__.py\n    \u2502   \u251c\u2500\u2500 llm_security_tester.py\n    \u2502   \u251c\u2500\u2500 mcp_security_tester.py\n    \u2502   \u251c\u2500\u2500 agent_security_tester.py\n    \u2502   \u2514\u2500\u2500 workflow_security_tester.py\n    \u2514\u2500\u2500 runtime/                # Runtime security monitoring\n        \u251c\u2500\u2500 __init__.py\n        \u251c\u2500\u2500 monitor.py\n        \u251c\u2500\u2500 filters.py\n        \u2514\u2500\u2500 alerts.py\n</code></pre>"},{"location":"testing/architecture/testing_architecture/#three-level-architecture","title":"Three-Level Architecture","text":""},{"location":"testing/architecture/testing_architecture/#level-1-system-integration-test_enginepy","title":"Level 1: System Integration (<code>test_engine.py</code>)","text":"<p>Primary Responsibility: Entry point for all testing requests and system integration.</p> <p>Specific Responsibilities:</p> <ul> <li>API Integration: Handle all incoming requests from Aurite's API routes</li> <li>Request Routing: Route requests to appropriate domain engines (QA or Security)</li> <li>Framework Coordination: Select and coordinate framework adapters/runners for cross-framework testing</li> <li>Result Storage: Manage test result caching and database storage</li> <li>Session Management: Track test sessions and execution state</li> <li>Cross-Domain Coordination: Handle requests that require both QA and Security testing</li> <li>Metrics Aggregation: Collect and aggregate metrics across all test types</li> <li>Configuration Integration: Interface with Aurite's ConfigManager for test configurations</li> </ul> <p>Key Methods:</p> <pre><code>class TestEngine:\n    def __init__(self, config_manager: ConfigManager):\n        self.config_manager = config_manager\n        self.qa_engine = QAEngine()\n        self.security_engine = SecurityEngine()\n\n    async def run_evaluation(self, eval_config_id: str) -&gt; EvaluationResult\n    async def run_security_assessment(self, security_config_id: str) -&gt; SecurityResult\n    async def get_test_status(self, test_id: str) -&gt; TestStatus\n    def cache_result(self, test_id: str, result: TestResult) -&gt; None\n</code></pre>"},{"location":"testing/architecture/testing_architecture/#level-2-domain-orchestration","title":"Level 2: Domain Orchestration","text":""},{"location":"testing/architecture/testing_architecture/#qa-engine-qaqa_enginepy","title":"QA Engine (<code>qa/qa_engine.py</code>)","text":"<p>Primary Responsibility: Orchestrate quality assurance testing across all component types.</p> <p>Specific Responsibilities:</p> <ul> <li>Component Test Routing: Route QA requests to appropriate component testers</li> <li>Test Case Management: Distribute and manage test cases across components</li> <li>Schema Validation: Handle JSON schema validation for structured outputs</li> <li>QA Metrics Aggregation: Calculate quality scores using weighted averages</li> <li>Multi-Component Evaluation: Handle evaluations that span multiple components</li> <li>Framework Runner Coordination: Select appropriate runners based on framework requirements</li> </ul> <p>Key Methods:</p> <pre><code>class QAEngine:\n    async def evaluate_component(self, request: QATestRequest) -&gt; QAResult:\n        # Get the appropriate runner based on framework\n        runner = self.get_runner(request.framework)\n\n        # Runner handles framework-specific execution (or existing run function method etc.)\n        results = await runner.execute_component(\n            request.component_type,\n            request.component_config\n        )\n\n        # Engine handles framework-agnostic evaluation\n        return self.evaluate_results(results, request.test_cases)\n\n    async def validate_schema(self, output: dict, schema: dict) -&gt; ValidationResult\n    def aggregate_qa_scores(self, results: list) -&gt; float\n</code></pre>"},{"location":"testing/architecture/testing_architecture/#security-engine-securitysecurity_enginepy","title":"Security Engine (<code>security/security_engine.py</code>)","text":"<p>Primary Responsibility: Orchestrate security assessments across all component types.</p> <p>Specific Responsibilities:</p> <ul> <li>Security Test Routing: Route security requests to appropriate component testers</li> <li>Threat Analysis: Perform cross-component threat analysis</li> <li>Security Score Calculation: Calculate security scores using minimum (weakest link) approach</li> <li>Alert Generation: Generate and escalate security alerts based on threat levels</li> <li>Compliance Checking: Validate compliance with security policies</li> <li>Concurrent Assessment Management: Manage multiple concurrent security assessments</li> <li>Cross-Component Vulnerability Detection: Identify vulnerabilities that span components</li> <li>Runtime Monitoring Coordination: Interface with runtime security monitoring</li> </ul> <p>Key Methods:</p> <pre><code>class SecurityEngine:\n    async def assess_component_security(self, component_type: str, config: dict) -&gt; SecurityResult\n    async def assess_full_configuration(self, config: dict) -&gt; dict[str, SecurityResult]\n    async def analyze_cross_component_threats(self, results: dict) -&gt; list[SecurityThreat]\n    def calculate_security_score(self, results: list) -&gt; float\n    async def generate_alerts(self, threats: list) -&gt; list[Alert]\n</code></pre>"},{"location":"testing/architecture/testing_architecture/#level-3-component-testing","title":"Level 3: Component Testing","text":""},{"location":"testing/architecture/testing_architecture/#component-testers","title":"Component Testers","text":"<p>Primary Responsibility: Execute specific tests for their component type.</p> <p>Specific Responsibilities:</p> <ul> <li>Test Category Management: Manage multiple test categories within the component</li> <li>Test Execution: Execute individual test methods for each category</li> <li>Runner Integration: Use appropriate runners for component execution</li> <li>Result Standardization: Return results in standardized formats</li> <li>Component-Specific Logic: Handle component-specific testing requirements</li> <li>Configuration Validation: Validate component configurations before testing</li> </ul> <p>Base Classes:</p> <pre><code># qa/base_qa_tester.py\nclass BaseQATester:\n    async def test_component(self, config: dict, test_cases: list) -&gt; QATestResult\n    def aggregate_qa_scores(self, results: list) -&gt; float  # Weighted average\n    def validate_config(self, config: dict) -&gt; bool\n\n# security/base_security_tester.py\nclass BaseSecurityTester:\n    async def assess_security(self, config: dict) -&gt; SecurityTestResult\n    def calculate_security_score(self, results: list) -&gt; float  # Minimum (weakest link)\n    def generate_threats(self, results: list) -&gt; list[SecurityThreat]\n</code></pre>"},{"location":"testing/architecture/testing_architecture/#framework-integration-strategy","title":"Framework Integration Strategy","text":""},{"location":"testing/architecture/testing_architecture/#framework-adapters-as-runners","title":"Framework Adapters as Runners","text":"<p>Framework adapters are specialized runners that handle framework-specific execution while maintaining framework-agnostic interfaces:</p> <pre><code># In qa_models.py\nclass QATestRequest(BaseModel):\n    component_type: str\n    component_config: dict\n    test_cases: List[TestCase]\n    framework: Optional[str] = \"aurite\"  # Specifies which runner/adapter to use\n\n# In runners/langchain_adapter.py\nclass LangChainAdapter:\n    async def execute_agent(self, config: dict) -&gt; ExecutionResult:\n        # 1. Translate Aurite config to LangChain format\n        langchain_config = self.translate_to_langchain(config)\n\n        # 2. Execute in LangChain\n        langchain_result = await self.run_langchain_agent(langchain_config)\n\n        # 3. Translate result back to Aurite format\n        return self.translate_from_langchain(langchain_result)\n</code></pre>"},{"location":"testing/architecture/testing_architecture/#benefits-of-this-approach","title":"Benefits of This Approach","text":"<ul> <li>Framework-Agnostic Engines: QA and Security engines remain framework-independent</li> <li>Specialized Execution: Framework adapters handle framework-specific details</li> <li>Simple Integration: Users specify framework via configuration field</li> <li>Shared Runners: Both QA and Security can use the same framework adapters</li> </ul>"},{"location":"testing/architecture/testing_architecture/#configuration-integration","title":"Configuration Integration","text":""},{"location":"testing/architecture/testing_architecture/#leveraging-aurites-configuration-system","title":"Leveraging Aurite's Configuration System","text":"<p>Instead of creating a separate configuration system, the testing framework integrates with Aurite's existing ConfigManager:</p> <p>Configuration Models (in <code>src/aurite/lib/models/config/components.py</code>):</p> <pre><code># Existing - QA Testing\nclass EvaluationConfig(BaseComponentConfig):\n    type: Literal[\"evaluation\"] = \"evaluation\"\n    eval_name: Optional[str]\n    eval_type: Optional[str]\n    test_cases: List[EvaluationCase]\n    review_llm: Optional[str]\n    expected_schema: Optional[dict]\n    framework: Optional[str] = \"aurite\"  # NEW: Framework specification\n\n# New - Security Testing\nclass SecurityAssessmentConfig(BaseComponentConfig):\n    type: Literal[\"security_assessment\"] = \"security_assessment\"\n    component_name: str\n    component_type: str  # \"llm\", \"mcp\", \"agent\", \"workflow\"\n    security_tests: List[str]  # Which tests to run\n    threat_thresholds: Dict[str, float]\n    alert_settings: Optional[AlertSettings]\n    framework: Optional[str] = \"aurite\"  # Framework specification\n</code></pre> <p>User Configuration Example:</p> <pre><code># config/testing/llm_security.yaml\n- type: security_assessment\n  name: claude-security-check\n  description: Security assessment for Claude LLM\n  component_name: claude-3-sonnet\n  component_type: llm\n  framework: aurite\n  security_tests:\n    - prompt_injection_basic\n    - toxicity_detection\n    - secrets_detection\n  threat_thresholds:\n    critical: 0.9\n    high: 0.7\n    medium: 0.5\n</code></pre>"},{"location":"testing/architecture/testing_architecture/#data-flow","title":"Data Flow","text":""},{"location":"testing/architecture/testing_architecture/#standard-test-request-flow","title":"Standard Test Request Flow","text":"<pre><code>1. API Request\n   POST /testing/security/assess\n   {\n     \"security_config_id\": \"claude-security-check\"\n   }\n   \u2193\n\n2. TestEngine.run_security_assessment()\n   - Gets config from Aurite's ConfigManager\n   - Validates request\n   - Checks cache for existing results\n   - Routes to SecurityEngine\n   \u2193\n\n3. SecurityEngine.assess_component_security()\n   - Determines component tester needed\n   - Instantiates LLMSecurityTester\n   - Manages assessment execution\n   \u2193\n\n4. LLMSecurityTester.assess_security()\n   - Uses appropriate runner (based on framework field)\n   - Runs prompt_injection_basic()\n   - Runs toxicity_detection()\n   - Runs secrets_detection()\n   - Aggregates results\n   \u2193\n\n5. Results flow back up\n   LLMSecurityTester \u2192 SecurityEngine \u2192 TestEngine \u2192 API Response\n\n6. TestEngine caches results and stores in database\n</code></pre>"},{"location":"testing/architecture/testing_architecture/#framework-specific-execution-flow","title":"Framework-Specific Execution Flow","text":"<pre><code>1. QA Test Request (framework: \"langchain\")\n   \u2193\n\n2. QAEngine receives request\n   \u2193\n\n3. QAEngine.get_runner(\"langchain\")\n   - Returns LangChainAdapter from runners/\n   \u2193\n\n4. AgentQATester.test_component()\n   - Uses LangChainAdapter for execution\n   - LangChainAdapter translates config\n   - Executes in LangChain environment\n   - Translates results back\n   \u2193\n\n5. QAEngine evaluates results (framework-agnostic)\n   \u2193\n\n6. Results returned with framework metadata\n</code></pre>"},{"location":"testing/architecture/testing_architecture/#component-responsibility-matrix","title":"Component Responsibility Matrix","text":"Level Component Primary Responsibilities Key Integrations 1 <code>TestEngine</code> API integration, request routing, caching, session management Aurite API, ConfigManager, Database 2 <code>QAEngine</code> QA test orchestration, schema validation, LLM evaluation Component QA Testers, Runners 2 <code>SecurityEngine</code> Security orchestration, threat analysis, alert generation Component Security Testers, Runtime 3 <code>LLMQATester</code> LLM quality tests, performance evaluation, accuracy testing Runners, Evaluation metrics 3 <code>LLMSecurityTester</code> LLM security tests, prompt injection, toxicity detection Runners, LLM Guard, Security scanners 3 <code>MCPQATester</code> MCP server quality tests, API compliance, performance MCP Test Host, API validators 3 <code>MCPSecurityTester</code> MCP server security tests, authentication, input validation Security scanners, Auth validators 3 <code>AgentQATester</code> Agent quality tests, goal achievement, tool usage Agent Runner, Framework adapters 3 <code>AgentSecurityTester</code> Agent security tests, permission boundaries, action auth Security policies, Auth systems 3 <code>WorkflowQATester</code> Workflow quality tests, business logic, end-to-end success Multiple agents, Business validators 3 <code>WorkflowSecurityTester</code> Workflow security tests, data isolation, audit compliance Audit systems, Data validators"},{"location":"testing/architecture/testing_architecture/#integration-points","title":"Integration Points","text":""},{"location":"testing/architecture/testing_architecture/#api-integration","title":"API Integration","text":"<p>New API Routes:</p> <pre><code># Main testing endpoints\nPOST /testing/qa/evaluate\nPOST /testing/qa/evaluate/{evaluation_config_id}\nPOST /testing/security/assess\nPOST /testing/security/assess/{security_config_id}\nGET  /testing/results/{test_id}\nGET  /testing/status/{test_id}\n\n# Component-specific endpoints\nPOST /testing/qa/llm/{llm_id}/test\nPOST /testing/security/agent/{agent_id}/assess\nPOST /testing/security/runtime/monitor/start\n</code></pre>"},{"location":"testing/architecture/testing_architecture/#database-integration","title":"Database Integration","text":"<p>New Tables:</p> <ul> <li><code>test_sessions</code> - Track test execution sessions</li> <li><code>test_results</code> - Store detailed test results</li> <li><code>security_threats</code> - Log detected security threats</li> <li><code>qa_evaluations</code> - Store QA evaluation results</li> </ul>"},{"location":"testing/architecture/testing_architecture/#migration-guide","title":"Migration Guide","text":""},{"location":"testing/architecture/testing_architecture/#existing-code-mapping","title":"Existing Code Mapping","text":"Current Location New Location Migration Notes <code>src/aurite/lib/components/evaluation/evaluator.py</code> <code>src/aurite/testing/qa/qa_engine.py</code> Core evaluation logic moves to QA engine <code>src/aurite/lib/components/evaluation/agent_runner.py</code> <code>src/aurite/testing/runners/agent_runner.py</code> Becomes shared runner for both QA and Security <code>src/aurite/security/core/security_engine.py</code> <code>src/aurite/testing/security/security_engine.py</code> Moves to Level 2 security orchestration <code>src/aurite/security/components/llm_security/</code> <code>src/aurite/testing/security/components/</code> Flattened structure, moves to Level 3 <code>src/aurite/security/core/base_tester.py</code> <code>src/aurite/testing/security/base_security_tester.py</code> Becomes security-specific base class <code>src/aurite/testing/mcp/testing_mcp_host.py</code> <code>src/aurite/testing/runners/mcp_test_host.py</code> Becomes shared runner for MCP testing <code>src/aurite/testing/cache/</code> <code>src/aurite/testing/cache/</code> Moves to root level of testing framework"},{"location":"testing/architecture/testing_architecture/#migration-steps","title":"Migration Steps","text":"<ol> <li>Create new directory structure</li> <li>Move and refactor Blake's evaluation code:</li> <li>Extract orchestration logic to <code>qa/qa_engine.py</code></li> <li>Move <code>agent_runner.py</code> to <code>runners/</code></li> <li>Create <code>qa/base_qa_tester.py</code></li> <li>Move and refactor Jiten's security code:</li> <li>Extract orchestration logic to <code>security/security_engine.py</code></li> <li>Move component testers to <code>security/components/</code></li> <li>Create <code>security/base_security_tester.py</code></li> <li>Move <code>llm_guard.py</code> to <code>runners/</code></li> <li>Create new <code>test_engine.py</code> as main orchestrator</li> <li>Move existing cache to <code>testing/cache/</code></li> <li>Update imports and API routes</li> <li>Add <code>SecurityAssessmentConfig</code> to components.py</li> <li>Test integration with existing Aurite framework</li> </ol>"},{"location":"testing/architecture/testing_architecture/#api-route-updates","title":"API Route Updates","text":"<p>Current:</p> <pre><code>POST /execution/evaluate\nPOST /execution/evaluate/{evaluation_config_id}\n</code></pre> <p>New:</p> <pre><code>POST /testing/qa/evaluate\nPOST /testing/qa/evaluate/{evaluation_config_id}\nPOST /testing/security/assess\nPOST /testing/security/assess/{security_config_id}\n</code></pre>"},{"location":"testing/architecture/testing_architecture/#benefits-of-this-architecture","title":"Benefits of This Architecture","text":"<ol> <li>Clean Root Directory: Only essential files and folders at the top level</li> <li>Clear Separation of Concerns: Each level has distinct responsibilities</li> <li>Framework Integration: Seamless integration with Aurite's configuration system</li> <li>Shared Resources: Runners and cache are accessible to both QA and Security</li> <li>Maintainable: Easy to modify individual components without affecting others</li> <li>Testable: Each level can be unit tested independently</li> <li>Extensible: New test types can be added at the appropriate level</li> <li>Scalable: Can handle increasing complexity without architectural changes</li> <li>Framework-Ready: Prepared for extraction to separate repository</li> <li>Practical Focus: Root contains what developers interact with most</li> </ol>"},{"location":"testing/architecture/testing_architecture/#runtime-security-monitoring","title":"Runtime Security Monitoring","text":"<p>Runtime monitoring is specifically focused on security concerns and is organized under <code>security/runtime/</code>:</p> <pre><code># security/runtime/monitor.py\nclass SecurityMonitor:\n    async def monitor_llm_request(self, request: LLMRequest) -&gt; SecurityResult\n    async def monitor_agent_execution(self, agent_id: str) -&gt; SecurityResult\n    def start_monitoring(self, component_type: str, component_id: str)\n\n# security/runtime/filters.py\nclass SecurityFilters:\n    async def filter_prompt_injection(self, input_text: str) -&gt; FilterResult\n    async def filter_toxic_content(self, content: str) -&gt; FilterResult\n    async def filter_secrets(self, text: str) -&gt; FilterResult\n</code></pre> <p>This approach keeps runtime monitoring focused and avoids the complexity of trying to make it generic across QA and Security when 99% of runtime testing will be security-focused.</p>"},{"location":"testing/architecture/testing_architecture/#future-considerations","title":"Future Considerations","text":"<ul> <li>Microservice Extraction: The entire <code>testing/</code> directory can be moved to a separate repository</li> <li>API Versioning: Testing APIs can be versioned independently</li> <li>Plugin Architecture: Component testers can be developed as plugins</li> <li>Distributed Testing: Architecture supports distributed test execution</li> <li>Framework Expansion: Easy to add support for new agent frameworks through new runners</li> <li>QA Runtime Features: If needed, can add <code>qa/runtime/</code> or refactor security runtime to be shared</li> </ul>"},{"location":"testing/architecture/testing_hierarchy/","title":"Testing Hierarchy and Flow","text":""},{"location":"testing/architecture/testing_hierarchy/#overview","title":"Overview","text":"<p>This document visualizes the complete testing hierarchy and flow for the Kahuna Testing &amp; Security Framework, showing how components build upon each other and how test results flow through the system across multiple agent frameworks.</p> <p>The testing hierarchy now operates in three dimensions:</p> <ol> <li>Testing Categories (Quality vs Security)</li> <li>Testing Phases (Development vs Runtime)</li> <li>Framework Scope (Framework-Agnostic vs Framework-Specific)</li> </ol> <p>This three-dimensional approach enables testing of AI components independent of specific agent frameworks while also supporting framework-specific validation.</p>"},{"location":"testing/architecture/testing_hierarchy/#complete-testing-hierarchy","title":"Complete Testing Hierarchy","text":"<pre><code>flowchart TD\n    Start[Testing Framework] --&gt; Split{Test Category}\n\n    Split --&gt;|Quality| QA[Quality Assurance]\n    Split --&gt;|Security| SEC[Security Testing]\n\n    %% Quality Branch\n    QA --&gt; QPhase{Testing Phase}\n    QPhase --&gt;|Development| QDev[Development-Time Quality]\n    QPhase --&gt;|Runtime| QRun[Runtime Quality Monitoring]\n\n    %% Security Branch\n    SEC --&gt; SPhase{Testing Phase}\n    SPhase --&gt;|Development| SDev[Development-Time Security]\n    SPhase --&gt;|Runtime| SRun[Runtime Security Monitoring]\n\n    %% Framework Scope Split\n    QDev --&gt; QScope{Framework Scope}\n    QRun --&gt; QRScope{Framework Scope}\n    SDev --&gt; SScope{Framework Scope}\n    SRun --&gt; SRScope{Framework Scope}\n\n    %% Framework-Agnostic Path\n    QScope --&gt;|Agnostic| QAgnostic[Universal Quality Tests]\n    QScope --&gt;|Specific| QSpecific[Framework Quality Tests]\n    SScope --&gt;|Agnostic| SAgnostic[Universal Security Tests]\n    SScope --&gt;|Specific| SSpecific[Framework Security Tests]\n\n    %% Component Testing Hierarchy - Agnostic\n    QAgnostic --&gt; LLM_Q[LLM Quality Tests&lt;br/&gt;100% Agnostic]\n    QAgnostic --&gt; MCP_Q[MCP Server Quality Tests&lt;br/&gt;100% Agnostic]\n    SAgnostic --&gt; LLM_S[LLM Security Tests&lt;br/&gt;100% Agnostic]\n    SAgnostic --&gt; MCP_S[MCP Server Security Tests&lt;br/&gt;100% Agnostic]\n\n    %% Component Testing - Mixed\n    LLM_Q --&gt; Agent_Q[Agent Quality Tests&lt;br/&gt;60% Agnostic]\n    MCP_Q --&gt; Agent_Q\n    LLM_S --&gt; Agent_S[Agent Security Tests&lt;br/&gt;60% Agnostic]\n    MCP_S --&gt; Agent_S\n    QSpecific --&gt; Agent_Q\n    SSpecific --&gt; Agent_S\n\n    %% Business Layer\n    Agent_Q --&gt; WF_Q[Workflow Quality Tests&lt;br/&gt;20% Agnostic]\n    Agent_S --&gt; WF_S[Workflow Security Tests&lt;br/&gt;20% Agnostic]\n\n    %% Results Flow\n    WF_Q --&gt; Results[Test Results]\n    WF_S --&gt; Results\n    QRScope --&gt; Metrics[Runtime Metrics]\n    SRScope --&gt; Metrics\n\n    Results --&gt; Kahuna_Exec[Kahuna Executive Mode]\n    Metrics --&gt; Kahuna_Exec\n\n    %% Input from Manager Mode\n    Kahuna_Mgr[Kahuna Manager Mode] --&gt; Requirements[Business Requirements&lt;br/&gt;+ Target Frameworks]\n    Requirements --&gt; Start\n\n    style Start fill:#2196F3,stroke:#1976D2,stroke-width:2px,color:#fff\n    style QA fill:#4CAF50,stroke:#388E3C,stroke-width:2px,color:#fff\n    style SEC fill:#F44336,stroke:#C62828,stroke-width:2px,color:#fff\n    style QAgnostic fill:#9C27B0,stroke:#7B1FA2,stroke-width:2px,color:#fff\n    style SAgnostic fill:#9C27B0,stroke:#7B1FA2,stroke-width:2px,color:#fff\n    style Results fill:#FF9800,stroke:#F57C00,stroke-width:2px,color:#fff\n    style Metrics fill:#FF9800,stroke:#F57C00,stroke-width:2px,color:#fff\n    style Kahuna_Exec fill:#9C27B0,stroke:#7B1FA2,stroke-width:2px,color:#fff\n    style Kahuna_Mgr fill:#00BCD4,stroke:#0097A7,stroke-width:2px,color:#fff</code></pre>"},{"location":"testing/architecture/testing_hierarchy/#framework-agnostic-testing-flow","title":"Framework-Agnostic Testing Flow","text":"<pre><code>flowchart TD\n    Start[Test Request] --&gt; Detect{Detect Framework}\n\n    Detect --&gt;|Aurite| Native[Native Execution]\n    Detect --&gt;|LangChain| LC_Adapter[LangChain Adapter]\n    Detect --&gt;|AutoGen| AG_Adapter[AutoGen Adapter]\n    Detect --&gt;|Other| Generic_Adapter[Generic Adapter]\n\n    LC_Adapter --&gt; Translate[Translate to Aurite Format]\n    AG_Adapter --&gt; Translate\n    Generic_Adapter --&gt; Translate\n    Native --&gt; Categorize{Categorize Component}\n\n    Translate --&gt; Categorize\n\n    Categorize --&gt;|LLM/MCP| Universal[Universal Tests&lt;br/&gt;100% Agnostic]\n    Categorize --&gt;|Agent| Hybrid[Hybrid Tests&lt;br/&gt;60% Agnostic]\n    Categorize --&gt;|Workflow| Specific[Specific Tests&lt;br/&gt;20% Agnostic]\n\n    Universal --&gt; Cache_Universal[Cache Universal Results]\n    Hybrid --&gt; Split_Tests{Split Tests}\n    Specific --&gt; Framework_Tests[Framework-Specific Tests]\n\n    Split_Tests --&gt;|Agnostic| Agnostic_Tests[Run Agnostic Tests]\n    Split_Tests --&gt;|Specific| Framework_Tests\n\n    Agnostic_Tests --&gt; Cache_Agnostic[Cache Agnostic Results]\n    Framework_Tests --&gt; Cache_Specific[Cache Framework Results]\n\n    Cache_Universal --&gt; Aggregate[Aggregate Results]\n    Cache_Agnostic --&gt; Aggregate\n    Cache_Specific --&gt; Aggregate\n\n    Aggregate --&gt; Normalize[Normalize to Standard Format]\n    Normalize --&gt; Report[Generate Report]\n\n    style Start fill:#2196F3,stroke:#1976D2,stroke-width:2px,color:#fff\n    style Universal fill:#4CAF50,stroke:#388E3C,stroke-width:2px,color:#fff\n    style Hybrid fill:#FF9800,stroke:#F57C00,stroke-width:2px,color:#fff\n    style Specific fill:#F44336,stroke:#C62828,stroke-width:2px,color:#fff\n    style Report fill:#9C27B0,stroke:#7B1FA2,stroke-width:2px,color:#fff</code></pre>"},{"location":"testing/architecture/testing_hierarchy/#test-execution-flow","title":"Test Execution Flow","text":"<pre><code>flowchart TD\n    Start[Start Testing] --&gt; Check{Check Dependencies}\n\n    Check --&gt;|No Dependencies| Foundation[Test Foundation Components]\n    Check --&gt;|Has Dependencies| Wait[Wait for Dependencies]\n\n    Foundation --&gt; Cache1[Cache LLM Results&lt;br/&gt;Universal Cache]\n    Foundation --&gt; Cache2[Cache MCP Results&lt;br/&gt;Universal Cache]\n\n    Cache1 --&gt; Ready1[LLM Tests Complete]\n    Cache2 --&gt; Ready2[MCP Tests Complete]\n\n    Ready1 --&gt; AgentTest{Agent Testing}\n    Ready2 --&gt; AgentTest\n\n    Wait --&gt; DepCheck{Dependencies Ready?}\n    DepCheck --&gt;|No| Wait\n    DepCheck --&gt;|Yes| AgentTest\n\n    AgentTest --&gt; Inherit[Inherit Foundation Results&lt;br/&gt;Cross-Framework]\n    Inherit --&gt; AgentSpecific[Run Agent Tests&lt;br/&gt;60% Agnostic, 40% Specific]\n    AgentSpecific --&gt; CacheAgent[Cache Agent Results]\n\n    CacheAgent --&gt; ReadyAgent[Agent Tests Complete]\n\n    ReadyAgent --&gt; WorkflowTest{Workflow Testing}\n\n    WorkflowTest --&gt; InheritAll[Inherit All Agent Results&lt;br/&gt;Cross-Framework]\n    InheritAll --&gt; WFSpecific[Run Workflow Tests&lt;br/&gt;20% Agnostic, 80% Specific]\n    WFSpecific --&gt; FinalResults[Generate Final Results]\n\n    FinalResults --&gt; Report[Generate Reports]\n    Report --&gt; End[Testing Complete]\n\n    style Start fill:#2196F3,stroke:#1976D2,stroke-width:2px,color:#fff\n    style End fill:#4CAF50,stroke:#388E3C,stroke-width:2px,color:#fff\n    style Foundation fill:#FF9800,stroke:#F57C00,stroke-width:2px,color:#fff\n    style AgentTest fill:#9C27B0,stroke:#7B1FA2,stroke-width:2px,color:#fff\n    style WorkflowTest fill:#E91E63,stroke:#C2185B,stroke-width:2px,color:#fff\n    style FinalResults fill:#00BCD4,stroke:#0097A7,stroke-width:2px,color:#fff</code></pre>"},{"location":"testing/architecture/testing_hierarchy/#quality-vs-security-score-propagation","title":"Quality vs Security Score Propagation","text":"<pre><code>flowchart TD\n    subgraph Quality[Quality Score Propagation]\n        Q_LLM[LLM Quality: 0.94] --&gt; Q_Calc1[Weighted Average]\n        Q_MCP[MCP Quality: 0.96] --&gt; Q_Calc1\n        Q_Agent_Specific[Agent Quality: 0.90] --&gt; Q_Calc1\n        Q_Calc1 --&gt; Q_Agent[Agent Quality: 0.93]\n\n        Q_Agent --&gt; Q_Calc2[Weighted Average]\n        Q_WF_Specific[Workflow Quality: 0.95] --&gt; Q_Calc2\n        Q_Calc2 --&gt; Q_WF[Workflow Quality: 0.94]\n    end\n\n    subgraph Security[Security Score Propagation]\n        S_LLM[LLM Security: 0.96] --&gt; S_Calc1[Take Minimum]\n        S_MCP[MCP Security: 0.99] --&gt; S_Calc1\n        S_Agent_Specific[Agent Security: 0.92] --&gt; S_Calc1\n        S_Calc1 --&gt; S_Agent[Agent Security: 0.92]\n\n        S_Agent --&gt; S_Calc2[Take Minimum]\n        S_WF_Specific[Workflow Security: 0.95] --&gt; S_Calc2\n        S_Calc2 --&gt; S_WF[Workflow Security: 0.92]\n    end\n\n    style Q_Calc1 fill:#4CAF50,stroke:#388E3C,stroke-width:2px,color:#fff\n    style Q_Calc2 fill:#4CAF50,stroke:#388E3C,stroke-width:2px,color:#fff\n    style S_Calc1 fill:#F44336,stroke:#C62828,stroke-width:2px,color:#fff\n    style S_Calc2 fill:#F44336,stroke:#C62828,stroke-width:2px,color:#fff</code></pre>"},{"location":"testing/architecture/testing_hierarchy/#development-vs-runtime-testing-flow","title":"Development vs Runtime Testing Flow","text":"<pre><code>flowchart LR\n    subgraph Development[Development-Time Testing]\n        D1[Comprehensive Tests] --&gt; D2[All Edge Cases]\n        D2 --&gt; D3[Performance Benchmarks]\n        D3 --&gt; D4[Security Audits]\n        D4 --&gt; D5[Generate Baselines]\n    end\n\n    subgraph Runtime[Runtime Monitoring]\n        R1[Selective Tests] --&gt; R2[Critical Checks Only]\n        R2 --&gt; R3[Real-time Filtering]\n        R3 --&gt; R4[Anomaly Detection]\n        R4 --&gt; R5[Alert on Deviations]\n    end\n\n    D5 --&gt;|Deploy| Prod[Production Environment]\n    Prod --&gt; Runtime\n\n    Runtime --&gt;|Feedback| Improve[Improve Tests]\n    Improve --&gt;|Update| Development\n\n    style Development fill:#2196F3,stroke:#1976D2,stroke-width:2px,color:#fff\n    style Runtime fill:#FF9800,stroke:#F57C00,stroke-width:2px,color:#fff\n    style Prod fill:#4CAF50,stroke:#388E3C,stroke-width:2px,color:#fff</code></pre>"},{"location":"testing/architecture/testing_hierarchy/#test-result-caching-strategy","title":"Test Result Caching Strategy","text":"<pre><code>flowchart TD\n    Test[Run Test] --&gt; Result[Test Result]\n    Result --&gt; Scope{Framework Scope?}\n\n    Scope --&gt;|Agnostic| Universal_Cache[Universal Cache&lt;br/&gt;Shared Across Frameworks]\n    Scope --&gt;|Specific| Framework_Cache[Framework Cache&lt;br/&gt;Isolated per Framework]\n\n    Universal_Cache --&gt; Meta_U[Store Metadata&lt;br/&gt;\u2022 Component ID&lt;br/&gt;\u2022 Version&lt;br/&gt;\u2022 Timestamp&lt;br/&gt;\u2022 TTL&lt;br/&gt;\u2022 Framework: ANY]\n    Framework_Cache --&gt; Meta_F[Store Metadata&lt;br/&gt;\u2022 Component ID&lt;br/&gt;\u2022 Version&lt;br/&gt;\u2022 Timestamp&lt;br/&gt;\u2022 TTL&lt;br/&gt;\u2022 Framework: Specific]\n\n    Meta_U --&gt; TTL_U{Check TTL}\n    Meta_F --&gt; TTL_F{Check TTL}\n\n    Request[New Test Request] --&gt; Framework_Check{Which Framework?}\n\n    Framework_Check --&gt; CheckCache{Check Cache}\n\n    CheckCache --&gt;|Universal Found| TTL_U\n    CheckCache --&gt;|Framework Found| TTL_F\n    CheckCache --&gt;|Not Found| Test\n\n    TTL_U --&gt;|Valid| UseCache[Use Cached Result&lt;br/&gt;Cross-Framework]\n    TTL_F --&gt;|Valid| UseCache\n    TTL_U --&gt;|Expired| Test\n    TTL_F --&gt;|Expired| Test\n\n    UseCache --&gt; Inherit[Inherit to Dependent]\n\n    Update[Component Update] --&gt; Invalidate{Which Cache?}\n    Invalidate --&gt;|LLM/MCP| Invalidate_Universal[Invalidate Universal&lt;br/&gt;All Frameworks Affected]\n    Invalidate --&gt;|Agent/Workflow| Invalidate_Specific[Invalidate Specific&lt;br/&gt;Single Framework]\n\n    Invalidate_Universal --&gt; Cascade[Cascade Invalidation]\n    Invalidate_Specific --&gt; Cascade\n    Cascade --&gt; Deps[Invalidate All Dependents]\n\n    style Test fill:#2196F3,stroke:#1976D2,stroke-width:2px,color:#fff\n    style UseCache fill:#4CAF50,stroke:#388E3C,stroke-width:2px,color:#fff\n    style Universal_Cache fill:#9C27B0,stroke:#7B1FA2,stroke-width:2px,color:#fff\n    style Framework_Cache fill:#FF9800,stroke:#F57C00,stroke-width:2px,color:#fff\n    style Invalidate_Universal fill:#F44336,stroke:#C62828,stroke-width:2px,color:#fff</code></pre>"},{"location":"testing/architecture/testing_hierarchy/#integration-with-kahuna-ecosystem","title":"Integration with Kahuna Ecosystem","text":"<pre><code>flowchart TD\n    subgraph Manager[Kahuna Manager Mode]\n        BW[Business Workflow] --&gt; Req[Requirements]\n        PD[Project Document] --&gt; Req\n        Req --&gt; Context[Project Context]\n    end\n\n    subgraph Developer[Kahuna Developer Mode]\n        Context --&gt; Testing[Testing Framework]\n        Testing --&gt; QTests[Quality Tests]\n        Testing --&gt; STests[Security Tests]\n\n        QTests --&gt; DevTime[Development Testing]\n        STests --&gt; DevTime\n\n        DevTime --&gt; Deploy[Deployment]\n        Deploy --&gt; RunTime[Runtime Monitoring]\n\n        QTests --&gt; RunTime\n        STests --&gt; RunTime\n    end\n\n    subgraph Executive[Kahuna Executive Mode]\n        RunTime --&gt; Metrics[Metrics Collection]\n        Metrics --&gt; QMetrics[Quality Metrics]\n        Metrics --&gt; SMetrics[Security Metrics]\n        Metrics --&gt; BMetrics[Business KPIs]\n\n        QMetrics --&gt; Dashboard[Executive Dashboard]\n        SMetrics --&gt; Dashboard\n        BMetrics --&gt; Dashboard\n    end\n\n    style Manager fill:#00BCD4,stroke:#0097A7,stroke-width:2px,color:#fff\n    style Developer fill:#4CAF50,stroke:#388E3C,stroke-width:2px,color:#fff\n    style Executive fill:#9C27B0,stroke:#7B1FA2,stroke-width:2px,color:#fff\n    style Testing fill:#FF9800,stroke:#F57C00,stroke-width:2px,color:#fff\n    style Dashboard fill:#E91E63,stroke:#C2185B,stroke-width:2px,color:#fff</code></pre>"},{"location":"testing/architecture/testing_hierarchy/#tabular-representations","title":"Tabular Representations","text":""},{"location":"testing/architecture/testing_hierarchy/#component-test-inheritance-matrix","title":"Component Test Inheritance Matrix","text":"Component Framework Scope Depends On Inherits From Cross-Framework Inheritance New Tests Inheritance Benefit LLM 100% Agnostic None None All results shared \u2022 Prompt injection\u2022 Content safety\u2022 Response quality Foundation (0% inherited) MCP Server 100% Agnostic None None All results shared \u2022 API security\u2022 Performance\u2022 Availability Foundation (0% inherited) Agent 60% Agnostic LLM + MCP \u2022 LLM security scores\u2022 MCP performance metrics 60% cross-framework \u2022 Tool selection\u2022 Goal achievement\u2022 Multi-turn coherence ~60% inherited Workflow 20% Agnostic Multiple Agents \u2022 All agent scores\u2022 All foundation scores 20% cross-framework \u2022 Business logic\u2022 End-to-end flow\u2022 Data consistency ~70% inherited"},{"location":"testing/architecture/testing_hierarchy/#quality-vs-security-score-calculation","title":"Quality vs Security Score Calculation","text":"Aspect Quality Scoring Security Scoring Rationale Method Weighted Average Minimum (Weakest Link) Quality can be averaged; Security fails at weakest point LLM Score 0.94 0.96 Foundation scores MCP Score 0.96 0.99 Foundation scores Agent-Specific 0.90 0.92 New agent tests Agent Final 0.93 (weighted) 0.92 (minimum) Combined result Workflow-Specific 0.95 0.95 New workflow tests Workflow Final 0.94 (weighted) 0.92 (minimum) Final scores"},{"location":"testing/architecture/testing_hierarchy/#development-vs-runtime-testing-comparison","title":"Development vs Runtime Testing Comparison","text":"Aspect Development Testing Runtime Testing Time Allocation Coverage 100% - All test cases 10-20% - Critical only Dev: 100%, Runtime: Sampling Execution Time Minutes to hours Milliseconds to seconds Dev: Thorough, Runtime: Fast Test Types \u2022 Edge cases\u2022 Stress tests\u2022 Benchmarks \u2022 Security filters\u2022 Quality scoring\u2022 Anomaly detection Dev: Comprehensive, Runtime: Targeted Frequency On-Demand, Per deployment Per request/response Dev: Once, Runtime: Continuous Action on Failure Block deployment Log, alert, or block Dev: Prevent, Runtime: Respond"},{"location":"testing/architecture/testing_hierarchy/#test-categories-by-component","title":"Test Categories by Component","text":"Component Framework Scope Quality Tests (Agnostic) Quality Tests (Specific) Security Tests (Agnostic) Security Tests (Specific) Inherited New Total LLM 100% Agnostic \u2022 Coherence\u2022 Instruction following\u2022 Format compliance\u2022 Quality scoring N/A \u2022 Prompt injection\u2022 Content safety\u2022 Data leakage\u2022 Real-time filtering N/A 0 8 8 MCP Server 100% Agnostic \u2022 API compliance\u2022 Performance\u2022 Error handling\u2022 Availability N/A \u2022 Authentication\u2022 Input validation\u2022 Rate limiting\u2022 Access monitoring N/A 0 8 8 Agent 60% Agnostic \u2022 Tool selection\u2022 Goal achievement \u2022 Memory management\u2022 State handling \u2022 Permission boundaries\u2022 Action authorization \u2022 Framework auth\u2022 Context isolation 16 8 24 Workflow 20% Agnostic \u2022 Business compliance\u2022 End-to-end success \u2022 Orchestration\u2022 Inter-agent communication \u2022 Data isolation\u2022 Audit completeness \u2022 Framework security\u2022 State management security 48 8 56"},{"location":"testing/architecture/testing_hierarchy/#kahuna-integration-points","title":"Kahuna Integration Points","text":"Kahuna Mode Role Input/Output Testing Interaction Manager Mode Requirements Provider \u2022 Business workflows\u2022 Project documents\u2022 Quality thresholds Defines what to test Developer Mode Testing Executor \u2022 Test implementation\u2022 Development testing\u2022 Runtime monitoring Executes all testing Executive Mode Metrics Consumer \u2022 Quality dashboards\u2022 Security reports\u2022 Business KPIs Receives test results"},{"location":"testing/architecture/testing_hierarchy/#alert-severity-and-response-matrix-rough-draft-still-a-wip","title":"Alert Severity and Response Matrix (Rough Draft - still a WIP)","text":"Severity Quality Threshold Security Threshold Response Time Action Critical &lt; 0.5 Any breach Immediate Block + Alert + Investigate High &lt; 0.7 Score &lt; 0.8 &lt; 5 min Block + Alert team Medium &lt; 0.85 Score &lt; 0.9 &lt; 1 hour Log + Monitor Low &lt; 0.95 Score &lt; 0.95 &lt; 24 hours Log for analysis"},{"location":"testing/architecture/testing_hierarchy/#cache-strategy-parameters","title":"Cache Strategy Parameters","text":"Parameter Value Purpose Impact Framework Scope TTL (LLM/MCP) 24 hours Foundation rarely changes High reuse across frameworks Universal cache TTL (Agent - Agnostic) 12 hours Core behaviors stable Cross-framework reuse Universal cache TTL (Agent - Specific) 4 hours Framework features change Framework-isolated Framework cache TTL (Workflow) 1 hour Frequent updates Fresh results Framework cache Cross-Framework Sharing Enabled Maximize test reuse 40-60% reduction in testing LLM/MCP/Agent core Invalidation On update Maintain consistency Cascade to dependents Both cache types Cache Hit Rate ~85% Increased with universal cache 85% time saved Overall"},{"location":"testing/architecture/testing_hierarchy/#framework-compatibility-matrix","title":"Framework Compatibility Matrix","text":"Framework LLM Support MCP Support Agent Support Workflow Support Adapter Status Testing Coverage Aurite 100% 100% 100% 100% Native 100% LangChain 100% 100% 80% 70% Available 85% AutoGen 100% 100% 75% 65% Available 80% CrewAI 100% 100% 70% 60% In Development 75% Custom 100% 100% Varies Varies Generic 60-80%"},{"location":"testing/architecture/testing_hierarchy/#summary","title":"Summary","text":"<p>This hierarchical testing structure provides:</p> <ol> <li>Three-Dimensional Organization: Quality/Security \u00d7 Development/Runtime \u00d7 Agnostic/Specific</li> <li>Framework Independence: LLM and MCP tests work across all frameworks</li> <li>Cross-Framework Inheritance: Agnostic test results shared between frameworks</li> <li>Efficient Execution: Through enhanced caching and result reuse</li> <li>Comprehensive Coverage: All components tested at appropriate levels</li> <li>Business Integration: From requirements (Manager) to metrics (Executive)</li> <li>Significant Time Savings: 70-85% reduction through compositional and cross-framework approach</li> </ol> <p>The framework ensures that each component is tested appropriately while maximizing test reuse across different agent frameworks through:</p> <ul> <li>Universal caching for framework-agnostic components</li> <li>Intelligent inheritance of results across framework boundaries</li> <li>Adapter pattern for framework translation</li> <li>Standardized formats for cross-framework comparison</li> </ul> <p>The tables and diagrams above provide a structured view that complements the visual representations, making it easy to:</p> <ul> <li>Compare testing approaches across components and frameworks</li> <li>Understand inheritance relationships both within and across frameworks</li> <li>Calculate time savings from cross-framework test reuse</li> <li>Plan test implementation for multi-framework environments</li> <li>Set appropriate thresholds and alerts for each framework</li> </ul> <p>For detailed architecture on framework-agnostic testing, see Framework-Agnostic Testing Architecture.</p>"},{"location":"testing/components/mcp_server/","title":"MCP Server Testing","text":""},{"location":"testing/components/mcp_server/#overview","title":"Overview","text":"<p>MCP (Model Context Protocol) servers are foundation components in the Kahuna Testing &amp; Security Framework's compositional hierarchy. As 100% framework-agnostic components, MCP servers provide tools and resources through standardized interfaces that operate independently of any specific agent framework. This document describes how MCP servers are tested and how their test results enable efficient testing of higher-level components through inheritance.</p>"},{"location":"testing/components/mcp_server/#position-in-testing-hierarchy","title":"Position in Testing Hierarchy","text":"<pre><code>Foundation Layer (100% Framework-Agnostic)\n\u251c\u2500\u2500 LLMs \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                 \u251c\u2500\u2192 Agents (inherit results) \u2500\u2192 Workflows\n\u2514\u2500\u2500 MCP Servers \u2500\u2500\u2518\n    \u2191\n    Our focus\n</code></pre> <p>MCP servers, alongside LLMs, form the foundation layer of our testing architecture. They:</p> <ul> <li>Have no dependencies on other components</li> <li>Are tested directly via the MCP protocol</li> <li>Provide inheritable test results to all agent frameworks</li> <li>Enable 85% reduction in redundant testing through result inheritance</li> </ul>"},{"location":"testing/components/mcp_server/#architectural-principles","title":"Architectural Principles","text":""},{"location":"testing/components/mcp_server/#1-framework-independence","title":"1. Framework Independence","text":"<p>MCP servers are completely framework-agnostic because they:</p> <ul> <li>Expose tools through the standardized MCP protocol</li> <li>Process requests and responses in a uniform format</li> <li>Operate as stateless services independent of calling context</li> <li>Maintain consistent behavior regardless of the agent framework</li> </ul>"},{"location":"testing/components/mcp_server/#2-direct-api-testing","title":"2. Direct API Testing","text":"<p>All MCP server tests bypass framework layers entirely:</p> <pre><code># Direct MCP protocol testing - no framework mediation\nmcp_client = MCPClient(server_url)\nresponse = mcp_client.call_tool(\"get_weather\", {\"city\": \"San Francisco\"})\n# Validate response directly\n</code></pre>"},{"location":"testing/components/mcp_server/#3-test-result-inheritance","title":"3. Test Result Inheritance","text":"<p>MCP test results are structured for maximum reusability:</p> <ul> <li>Validated tool calls become test patterns for agents</li> <li>Performance baselines set expectations for agent testing</li> <li>Security validations eliminate redundant security testing</li> <li>Tool catalogs inform agent tool selection tests</li> </ul>"},{"location":"testing/components/mcp_server/#test-categories","title":"Test Categories","text":""},{"location":"testing/components/mcp_server/#quality-testing-60-of-tests","title":"Quality Testing (60% of tests)","text":"<p>Quality tests ensure MCP servers meet functional and performance requirements:</p> Test Type Description Inheritable Data Tool Discovery Validate tool enumeration Available tools list Tool Invocation Test successful execution Request/response patterns Error Handling Verify proper error responses Error scenarios Performance Measure response times Baseline metrics (p50, p95, p99) API Compliance Check MCP protocol adherence Protocol version compatibility"},{"location":"testing/components/mcp_server/#security-testing-40-of-tests","title":"Security Testing (40% of tests)","text":"<p>Security tests validate protection against threats and compliance:</p> Test Type Description Inheritable Data Authentication Verify access controls Auth mechanisms validated Input Validation Test injection resistance Safe input patterns Rate Limiting Check request throttling Rate limit thresholds Data Exposure Prevent information leakage Security clearances Authorization Validate permission boundaries Allowed operations"},{"location":"testing/components/mcp_server/#test-execution-model","title":"Test Execution Model","text":""},{"location":"testing/components/mcp_server/#development-time-testing","title":"Development-Time Testing","text":"<p>Comprehensive validation before deployment:</p> <pre><code>def test_mcp_server_development(server_config):\n    \"\"\"\n    Full MCP server validation following architecture patterns\n    \"\"\"\n    # 1. No dependency checking needed (foundation component)\n\n    # 2. Run quality tests\n    quality_results = {\n        \"tool_discovery\": test_tool_discovery(server_config),\n        \"tool_invocation\": test_tool_invocation(server_config),\n        \"error_handling\": test_error_handling(server_config),\n        \"performance\": test_performance_benchmarks(server_config),\n        \"api_compliance\": test_mcp_compliance(server_config)\n    }\n\n    # 3. Run security tests\n    security_results = {\n        \"authentication\": test_authentication(server_config),\n        \"input_validation\": test_input_validation(server_config),\n        \"rate_limiting\": test_rate_limiting(server_config),\n        \"data_exposure\": test_data_exposure(server_config),\n        \"authorization\": test_authorization(server_config)\n    }\n\n    # 4. Structure for inheritance\n    inheritable_data = {\n        \"validated_tool_calls\": extract_tool_patterns(quality_results),\n        \"tool_catalog\": build_tool_catalog(quality_results),\n        \"security_clearances\": extract_security_validations(security_results),\n        \"performance_baselines\": extract_performance_metrics(quality_results)\n    }\n\n    # 5. Cache in universal cache (24-hour TTL)\n    cache_universal_results(server_config.id, {\n        \"quality_score\": calculate_quality_score(quality_results),\n        \"security_score\": calculate_security_score(security_results),\n        \"inheritable_data\": inheritable_data,\n        \"ttl\": 86400  # 24 hours\n    })\n\n    return test_results\n</code></pre>"},{"location":"testing/components/mcp_server/#runtime-monitoring","title":"Runtime Monitoring","text":"<p>Selective validation in production:</p> <pre><code>def monitor_mcp_server_runtime(server_id, request):\n    \"\"\"\n    Lightweight runtime validation with caching\n    \"\"\"\n    # 1. Check universal cache first\n    cached = get_universal_cache(server_id)\n    if cached and cached.is_valid():\n        return cached.result\n\n    # 2. Quick security check\n    if not validate_input_safety(request):\n        return block_request(\"Input validation failed\")\n\n    # 3. Performance monitoring (async)\n    async_monitor_performance(server_id, request)\n\n    # 4. Execute with monitoring\n    return execute_with_monitoring(request)\n</code></pre>"},{"location":"testing/components/mcp_server/#test-result-structure","title":"Test Result Structure","text":"<p>MCP test results are structured to maximize inheritance value:</p> <pre><code>MCP_TEST_RESULT = {\n    # Component identification\n    \"component_id\": \"weather_mcp_server\",\n    \"component_type\": \"mcp_server\",\n    \"version\": \"1.0.0\",\n    \"timestamp\": \"2024-08-30T16:00:00Z\",\n\n    # Framework context (always universal for MCP)\n    \"framework\": \"universal\",\n    \"is_agnostic\": True,\n    \"cross_framework_validity\": True,\n\n    # Aggregate scores\n    \"quality_score\": 0.95,\n    \"security_score\": 0.98,\n\n    # Detailed test results\n    \"test_results\": {\n        \"quality\": {\n            \"tool_discovery\": {\"status\": \"PASS\", \"tools_found\": 3},\n            \"tool_invocation\": {\"status\": \"PASS\", \"success_rate\": 0.98},\n            \"error_handling\": {\"status\": \"PASS\", \"coverage\": 0.95},\n            \"performance\": {\"status\": \"PASS\", \"p95_ms\": 150},\n            \"api_compliance\": {\"status\": \"PASS\", \"version\": \"1.0\"}\n        },\n        \"security\": {\n            \"authentication\": {\"status\": \"PASS\", \"mechanism\": \"api_key\"},\n            \"input_validation\": {\"status\": \"PASS\", \"blocked_injections\": 10},\n            \"rate_limiting\": {\"status\": \"PASS\", \"limit\": \"100/min\"},\n            \"data_exposure\": {\"status\": \"PASS\", \"leaks_found\": 0},\n            \"authorization\": {\"status\": \"PASS\", \"boundaries_enforced\": True}\n        }\n    },\n\n    # Inheritable data for agents\n    \"inheritable_data\": {\n        \"validated_tool_calls\": [\n            {\n                \"tool_name\": \"get_weather\",\n                \"test_case\": \"valid_city\",\n                \"request\": {\n                    \"method\": \"tools/call\",\n                    \"params\": {\n                        \"name\": \"get_weather\",\n                        \"arguments\": {\"city\": \"San Francisco\"}\n                    }\n                },\n                \"response\": {\n                    \"temperature\": 65,\n                    \"conditions\": \"sunny\",\n                    \"humidity\": 70\n                },\n                \"validation\": {\n                    \"status\": \"PASS\",\n                    \"response_time_ms\": 145,\n                    \"security_checks\": [\"input_validated\", \"rate_limit_ok\"]\n                }\n            }\n            # Additional test cases...\n        ],\n\n        \"tool_catalog\": {\n            \"get_weather\": {\n                \"available\": True,\n                \"avg_response_time_ms\": 150,\n                \"success_rate\": 0.98,\n                \"security_validated\": True,\n                \"test_coverage\": [\"valid_input\", \"invalid_input\", \"edge_cases\"]\n            },\n            \"get_forecast\": {\n                \"available\": True,\n                \"avg_response_time_ms\": 200,\n                \"success_rate\": 0.96,\n                \"security_validated\": True,\n                \"test_coverage\": [\"valid_input\", \"date_ranges\", \"locations\"]\n            }\n        },\n\n        \"performance_baselines\": {\n            \"p50_ms\": 100,\n            \"p95_ms\": 150,\n            \"p99_ms\": 300,\n            \"throughput_rps\": 100\n        },\n\n        \"security_clearances\": {\n            \"injection_tested\": True,\n            \"authentication_required\": True,\n            \"rate_limits_enforced\": True,\n            \"data_sanitization\": True\n        }\n    },\n\n    # Cache metadata\n    \"cache_ttl\": 86400,  # 24 hours for foundation components\n    \"cache_key\": \"universal:mcp:weather_mcp_server:1.0.0\",\n\n    # Inheritance metadata\n    \"inherits_from\": [],  # Empty - foundation component\n    \"inherited_by\": [\"agent\", \"workflow\"],  # Components that will inherit\n    \"inheritance_benefit\": \"85% reduction in tool testing for agents\"\n}\n</code></pre>"},{"location":"testing/components/mcp_server/#inheritance-model","title":"Inheritance Model","text":""},{"location":"testing/components/mcp_server/#how-agents-inherit-mcp-test-results","title":"How Agents Inherit MCP Test Results","text":"<p>When an agent is tested, it automatically inherits MCP validation:</p> <pre><code># Agent test leveraging MCP inheritance\nAGENT_TEST_WITH_MCP_INHERITANCE = {\n    \"agent_id\": \"weather_assistant\",\n\n    # Inherited from MCP testing (no retesting needed)\n    \"inherited_validations\": {\n        \"weather_mcp_server\": {\n            \"quality_score\": 0.95,  # Inherited\n            \"security_score\": 0.98,  # Inherited\n            \"tools_validated\": [\"get_weather\", \"get_forecast\"],\n            \"skip_tool_execution_tests\": True,  # Don't retest tools\n            \"use_validated_patterns\": True,  # Reuse test cases\n            \"performance_baseline\": 150  # Inherited p95\n        }\n    },\n\n    # Agent focuses on integration testing only\n    \"agent_specific_tests\": {\n        \"tool_selection\": {\n            \"test\": \"Does agent select correct tool for query?\",\n            \"result\": \"PASS\"\n        },\n        \"response_synthesis\": {\n            \"test\": \"Does agent format tool output appropriately?\",\n            \"result\": \"PASS\"\n        }\n    },\n\n    # Time saved through inheritance\n    \"testing_metrics\": {\n        \"tests_inherited\": 10,\n        \"tests_executed\": 2,\n        \"time_saved\": \"85%\"\n    }\n}\n</code></pre>"},{"location":"testing/components/mcp_server/#cross-framework-inheritance","title":"Cross-Framework Inheritance","text":"<p>MCP test results are valid across all agent frameworks:</p> Framework Inheritance Usage Time Saved Aurite Direct inheritance (native) 85% LangChain Via adapter translation 85% AutoGen Via adapter translation 85% CrewAI Via adapter translation 85% Custom Via generic adapter 80-85%"},{"location":"testing/components/mcp_server/#caching-strategy","title":"Caching Strategy","text":""},{"location":"testing/components/mcp_server/#universal-cache-integration","title":"Universal Cache Integration","text":"<p>MCP test results are stored in the universal cache for cross-framework sharing:</p> <pre><code>CACHE_STRATEGY = {\n    \"cache_type\": \"universal\",  # Shared across all frameworks\n    \"ttl\": 86400,  # 24 hours\n    \"invalidation\": \"cascade\",  # Invalidate dependent components\n    \"key_pattern\": \"universal:mcp:{server_id}:{version}\",\n\n    \"benefits\": {\n        \"cross_framework_reuse\": True,\n        \"cache_hit_rate\": 0.85,\n        \"redundant_test_elimination\": 0.85\n    }\n}\n</code></pre>"},{"location":"testing/components/mcp_server/#cache-invalidation","title":"Cache Invalidation","text":"<p>When an MCP server is updated:</p> <ol> <li>Universal cache entry is invalidated</li> <li>All dependent agent test results are marked stale</li> <li>Workflow test results are cascaded for invalidation</li> <li>Next test run refreshes the cache</li> </ol>"},{"location":"testing/components/mcp_server/#failure-handling","title":"Failure Handling","text":""},{"location":"testing/components/mcp_server/#failure-impact-analysis","title":"Failure Impact Analysis","text":"<p>MCP server failures have significant upstream impact:</p> <pre><code>MCP Failure Impact:\n\u251c\u2500\u2500 Direct Impact\n\u2502   \u2514\u2500\u2500 MCP server cannot be used\n\u251c\u2500\u2500 Agent Impact\n\u2502   \u251c\u2500\u2500 Agents using this MCP are blocked\n\u2502   \u2514\u2500\u2500 Agent tests marked as \"blocked by dependency\"\n\u2514\u2500\u2500 Workflow Impact\n    \u251c\u2500\u2500 Workflows using affected agents fail\n    \u2514\u2500\u2500 Business processes disrupted\n</code></pre>"},{"location":"testing/components/mcp_server/#failure-propagation-rules","title":"Failure Propagation Rules","text":"<ol> <li> <p>Critical Failures (Security breaches, authentication failures)</p> </li> <li> <p>Block all dependent components immediately</p> </li> <li> <p>Require manual intervention to resolve</p> </li> <li> <p>Quality Failures (Performance degradation, high error rates)</p> </li> <li> <p>Allow degraded operation with warnings</p> </li> <li> <p>Trigger alerts for investigation</p> </li> <li> <p>Partial Failures (Some tools working, others failing)</p> </li> <li>Selective blocking of failed tools only</li> <li>Agents can use working tools</li> </ol>"},{"location":"testing/components/mcp_server/#getting-started","title":"Getting Started","text":""},{"location":"testing/components/mcp_server/#running-mcp-server-tests","title":"Running MCP Server Tests","text":"<pre><code># Run all MCP server tests\naurite test mcp-server &lt;server_id&gt;\n\n# Run quality tests only\naurite test mcp-server &lt;server_id&gt; --quality\n\n# Run security tests only\naurite test mcp-server &lt;server_id&gt; --security\n\n# Run with specific framework context (for comparison)\naurite test mcp-server &lt;server_id&gt; --framework langchain\n</code></pre>"},{"location":"testing/components/mcp_server/#viewing-test-results","title":"Viewing Test Results","text":"<pre><code># View latest test results\naurite test results mcp-server &lt;server_id&gt;\n\n# View inherited impact\naurite test inheritance &lt;server_id&gt;\n\n# View cache status\naurite cache status mcp-server &lt;server_id&gt;\n</code></pre>"},{"location":"testing/components/mcp_server/#related-documentation","title":"Related Documentation","text":"<ul> <li>Test Patterns - Reusable test patterns and validated tool calls</li> <li>Testing Architecture - Overall testing framework architecture</li> <li>Test Inheritance - How test results flow through the hierarchy</li> <li>Framework-Agnostic Testing - Cross-framework testing approach</li> <li>Kahuna Testing Framework - Main testing framework documentation</li> </ul>"},{"location":"testing/components/mcp_server/test_patterns/","title":"MCP Server Test Patterns","text":""},{"location":"testing/components/mcp_server/test_patterns/#overview","title":"Overview","text":"<p>This document provides reusable test patterns for MCP server validation. These patterns serve as the foundation for inheritance, allowing agents and workflows to reuse validated tool interactions without retesting. Each pattern includes the request, expected response, and validation criteria that can be inherited by higher-level components.</p>"},{"location":"testing/components/mcp_server/test_patterns/#validated-tool-call-patterns","title":"Validated Tool Call Patterns","text":""},{"location":"testing/components/mcp_server/test_patterns/#pattern-structure","title":"Pattern Structure","text":"<p>Each validated tool call pattern contains:</p> <ul> <li>Test Case ID: Unique identifier for the pattern</li> <li>Purpose: What this pattern validates</li> <li>Request: The exact MCP protocol request</li> <li>Response: Expected response structure</li> <li>Validation: What was verified</li> <li>Inheritance Value: How agents can use this pattern</li> </ul>"},{"location":"testing/components/mcp_server/test_patterns/#quality-test-patterns","title":"Quality Test Patterns","text":""},{"location":"testing/components/mcp_server/test_patterns/#pattern-tool-discovery","title":"Pattern: Tool Discovery","text":"<pre><code>TOOL_DISCOVERY_PATTERN = {\n    \"test_case_id\": \"mcp_tool_discovery_001\",\n    \"purpose\": \"Validate tool enumeration\",\n    \"request\": {\n        \"method\": \"tools/list\",\n        \"params\": {}\n    },\n    \"expected_response\": {\n        \"tools\": [\n            {\n                \"name\": \"get_weather\",\n                \"description\": \"Get current weather for a city\",\n                \"inputSchema\": {\n                    \"type\": \"object\",\n                    \"properties\": {\n                        \"city\": {\"type\": \"string\"}\n                    },\n                    \"required\": [\"city\"]\n                }\n            },\n            {\n                \"name\": \"get_forecast\",\n                \"description\": \"Get weather forecast\",\n                \"inputSchema\": {\n                    \"type\": \"object\",\n                    \"properties\": {\n                        \"city\": {\"type\": \"string\"},\n                        \"days\": {\"type\": \"integer\", \"minimum\": 1, \"maximum\": 7}\n                    },\n                    \"required\": [\"city\"]\n                }\n            }\n        ]\n    },\n    \"validation\": {\n        \"tools_present\": True,\n        \"schema_valid\": True,\n        \"descriptions_clear\": True\n    },\n    \"inheritance_value\": \"Agents know available tools without discovery\"\n}\n</code></pre>"},{"location":"testing/components/mcp_server/test_patterns/#pattern-successful-tool-invocation","title":"Pattern: Successful Tool Invocation","text":"<pre><code>SUCCESSFUL_INVOCATION_PATTERN = {\n    \"test_case_id\": \"mcp_invoke_success_001\",\n    \"purpose\": \"Validate successful tool execution\",\n    \"request\": {\n        \"method\": \"tools/call\",\n        \"params\": {\n            \"name\": \"get_weather\",\n            \"arguments\": {\n                \"city\": \"San Francisco\"\n            }\n        }\n    },\n    \"expected_response\": {\n        \"content\": [\n            {\n                \"type\": \"text\",\n                \"text\": \"Current weather in San Francisco: 65\u00b0F, sunny, 70% humidity\"\n            }\n        ],\n        \"isError\": False\n    },\n    \"validation\": {\n        \"status\": \"SUCCESS\",\n        \"response_time_ms\": 145,\n        \"content_valid\": True,\n        \"format_correct\": True\n    },\n    \"inheritance_value\": \"Agents can use this exact request pattern\"\n}\n</code></pre>"},{"location":"testing/components/mcp_server/test_patterns/#pattern-error-handling","title":"Pattern: Error Handling","text":"<pre><code>ERROR_HANDLING_PATTERN = {\n    \"test_case_id\": \"mcp_error_handling_001\",\n    \"purpose\": \"Validate graceful error handling\",\n    \"request\": {\n        \"method\": \"tools/call\",\n        \"params\": {\n            \"name\": \"get_weather\",\n            \"arguments\": {\n                \"city\": \"\"  # Empty city name\n            }\n        }\n    },\n    \"expected_response\": {\n        \"content\": [\n            {\n                \"type\": \"text\",\n                \"text\": \"Error: City name is required\"\n            }\n        ],\n        \"isError\": True\n    },\n    \"validation\": {\n        \"error_handled\": True,\n        \"message_clear\": True,\n        \"no_crash\": True,\n        \"status_code\": 400\n    },\n    \"inheritance_value\": \"Agents know error scenarios are handled safely\"\n}\n</code></pre>"},{"location":"testing/components/mcp_server/test_patterns/#pattern-edge-case-handling","title":"Pattern: Edge Case Handling","text":"<pre><code>EDGE_CASE_PATTERN = {\n    \"test_case_id\": \"mcp_edge_case_001\",\n    \"purpose\": \"Validate handling of edge cases\",\n    \"test_cases\": [\n        {\n            \"description\": \"Very long city name\",\n            \"request\": {\n                \"method\": \"tools/call\",\n                \"params\": {\n                    \"name\": \"get_weather\",\n                    \"arguments\": {\n                        \"city\": \"Llanfairpwllgwyngyllgogerychwyrndrobwllllantysiliogogogoch\"\n                    }\n                }\n            },\n            \"validation\": {\n                \"handled_gracefully\": True,\n                \"response_time_acceptable\": True\n            }\n        },\n        {\n            \"description\": \"Special characters in input\",\n            \"request\": {\n                \"method\": \"tools/call\",\n                \"params\": {\n                    \"name\": \"get_weather\",\n                    \"arguments\": {\n                        \"city\": \"S\u00e3o Paulo\"\n                    }\n                }\n            },\n            \"validation\": {\n                \"unicode_handled\": True,\n                \"correct_response\": True\n            }\n        }\n    ],\n    \"inheritance_value\": \"Agents inherit edge case handling confidence\"\n}\n</code></pre>"},{"location":"testing/components/mcp_server/test_patterns/#security-test-patterns","title":"Security Test Patterns","text":""},{"location":"testing/components/mcp_server/test_patterns/#pattern-input-validation","title":"Pattern: Input Validation","text":"<pre><code>INPUT_VALIDATION_PATTERN = {\n    \"test_case_id\": \"mcp_security_input_001\",\n    \"purpose\": \"Validate injection attack resistance\",\n    \"attack_vectors\": [\n        {\n            \"type\": \"SQL Injection\",\n            \"request\": {\n                \"method\": \"tools/call\",\n                \"params\": {\n                    \"name\": \"get_weather\",\n                    \"arguments\": {\n                        \"city\": \"'; DROP TABLE weather; --\"\n                    }\n                }\n            },\n            \"expected_response\": {\n                \"isError\": True,\n                \"content\": [{\"type\": \"text\", \"text\": \"Invalid city name\"}]\n            },\n            \"validation\": {\n                \"injection_blocked\": True,\n                \"no_data_leak\": True\n            }\n        },\n        {\n            \"type\": \"XSS Attack\",\n            \"request\": {\n                \"method\": \"tools/call\",\n                \"params\": {\n                    \"name\": \"get_weather\",\n                    \"arguments\": {\n                        \"city\": \"&lt;script&gt;alert('xss')&lt;/script&gt;\"\n                    }\n                }\n            },\n            \"expected_response\": {\n                \"isError\": True,\n                \"content\": [{\"type\": \"text\", \"text\": \"Invalid city name\"}]\n            },\n            \"validation\": {\n                \"script_blocked\": True,\n                \"output_sanitized\": True\n            }\n        },\n        {\n            \"type\": \"Command Injection\",\n            \"request\": {\n                \"method\": \"tools/call\",\n                \"params\": {\n                    \"name\": \"get_weather\",\n                    \"arguments\": {\n                        \"city\": \"Boston; rm -rf /\"\n                    }\n                }\n            },\n            \"validation\": {\n                \"command_blocked\": True,\n                \"system_safe\": True\n            }\n        }\n    ],\n    \"inheritance_value\": \"Agents inherit security validation - no need to retest\"\n}\n</code></pre>"},{"location":"testing/components/mcp_server/test_patterns/#pattern-authentication-validation","title":"Pattern: Authentication Validation","text":"<pre><code>AUTHENTICATION_PATTERN = {\n    \"test_case_id\": \"mcp_security_auth_001\",\n    \"purpose\": \"Validate authentication enforcement\",\n    \"test_cases\": [\n        {\n            \"description\": \"Valid authentication\",\n            \"headers\": {\n                \"Authorization\": \"Bearer valid_token_123\"\n            },\n            \"request\": {\n                \"method\": \"tools/call\",\n                \"params\": {\n                    \"name\": \"get_weather\",\n                    \"arguments\": {\"city\": \"Boston\"}\n                }\n            },\n            \"validation\": {\n                \"access_granted\": True,\n                \"response_valid\": True\n            }\n        },\n        {\n            \"description\": \"Missing authentication\",\n            \"headers\": {},\n            \"request\": {\n                \"method\": \"tools/call\",\n                \"params\": {\n                    \"name\": \"get_weather\",\n                    \"arguments\": {\"city\": \"Boston\"}\n                }\n            },\n            \"expected_response\": {\n                \"error\": {\n                    \"code\": -32001,\n                    \"message\": \"Authentication required\"\n                }\n            },\n            \"validation\": {\n                \"access_denied\": True,\n                \"proper_error_code\": True\n            }\n        },\n        {\n            \"description\": \"Invalid token\",\n            \"headers\": {\n                \"Authorization\": \"Bearer invalid_token\"\n            },\n            \"validation\": {\n                \"access_denied\": True,\n                \"no_data_leak\": True\n            }\n        }\n    ],\n    \"inheritance_value\": \"Agents know authentication is properly enforced\"\n}\n</code></pre>"},{"location":"testing/components/mcp_server/test_patterns/#pattern-rate-limiting","title":"Pattern: Rate Limiting","text":"<pre><code>RATE_LIMITING_PATTERN = {\n    \"test_case_id\": \"mcp_security_rate_001\",\n    \"purpose\": \"Validate rate limiting enforcement\",\n    \"test_sequence\": [\n        {\n            \"step\": 1,\n            \"description\": \"Normal request rate\",\n            \"requests_per_minute\": 50,\n            \"validation\": {\n                \"all_requests_succeed\": True,\n                \"avg_response_time_ms\": 150\n            }\n        },\n        {\n            \"step\": 2,\n            \"description\": \"At rate limit\",\n            \"requests_per_minute\": 100,\n            \"validation\": {\n                \"all_requests_succeed\": True,\n                \"warning_headers_present\": True\n            }\n        },\n        {\n            \"step\": 3,\n            \"description\": \"Exceeding rate limit\",\n            \"requests_per_minute\": 150,\n            \"expected_response\": {\n                \"error\": {\n                    \"code\": -32002,\n                    \"message\": \"Rate limit exceeded\"\n                }\n            },\n            \"validation\": {\n                \"requests_blocked\": True,\n                \"retry_after_header\": True,\n                \"proper_status_code\": 429\n            }\n        }\n    ],\n    \"inheritance_value\": \"Agents inherit rate limit thresholds\"\n}\n</code></pre>"},{"location":"testing/components/mcp_server/test_patterns/#tool-catalog-format","title":"Tool Catalog Format","text":"<p>The tool catalog provides agents with a complete inventory of validated tools:</p> <pre><code>TOOL_CATALOG = {\n    \"server_id\": \"weather_mcp_server\",\n    \"version\": \"1.0.0\",\n    \"tools\": {\n        \"get_weather\": {\n            \"description\": \"Get current weather for a city\",\n            \"validation_status\": {\n                \"quality\": {\n                    \"functional\": \"PASS\",\n                    \"performance\": \"PASS\",\n                    \"error_handling\": \"PASS\"\n                },\n                \"security\": {\n                    \"input_validation\": \"PASS\",\n                    \"authentication\": \"PASS\",\n                    \"rate_limiting\": \"PASS\"\n                }\n            },\n            \"performance_metrics\": {\n                \"avg_response_time_ms\": 150,\n                \"p95_response_time_ms\": 200,\n                \"success_rate\": 0.98,\n                \"error_rate\": 0.02\n            },\n            \"test_coverage\": {\n                \"valid_inputs\": 10,\n                \"invalid_inputs\": 5,\n                \"edge_cases\": 8,\n                \"security_vectors\": 12\n            },\n            \"validated_patterns\": [\n                \"mcp_invoke_success_001\",\n                \"mcp_error_handling_001\",\n                \"mcp_security_input_001\"\n            ]\n        },\n        \"get_forecast\": {\n            \"description\": \"Get weather forecast for multiple days\",\n            \"validation_status\": {\n                \"quality\": \"PASS\",\n                \"security\": \"PASS\"\n            },\n            \"performance_metrics\": {\n                \"avg_response_time_ms\": 200,\n                \"p95_response_time_ms\": 300,\n                \"success_rate\": 0.96\n            }\n        }\n    },\n    \"overall_metrics\": {\n        \"total_tools\": 2,\n        \"tools_validated\": 2,\n        \"quality_score\": 0.95,\n        \"security_score\": 0.98,\n        \"test_patterns_available\": 15\n    }\n}\n</code></pre>"},{"location":"testing/components/mcp_server/test_patterns/#inheritance-examples","title":"Inheritance Examples","text":""},{"location":"testing/components/mcp_server/test_patterns/#example-1-agent-using-validated-patterns","title":"Example 1: Agent Using Validated Patterns","text":"<pre><code># Agent test that inherits MCP validation\ndef test_agent_with_mcp_inheritance():\n    # Load validated MCP patterns\n    mcp_patterns = load_mcp_test_patterns(\"weather_mcp_server\")\n\n    # Agent doesn't need to test tool functionality\n    # It only tests its own decision-making\n    agent_test = {\n        \"test\": \"Agent selects correct tool\",\n        \"user_query\": \"What's the weather in Boston?\",\n        \"expected_tool\": \"get_weather\",\n        \"expected_arguments\": {\"city\": \"Boston\"}\n    }\n\n    # Use validated request pattern for execution\n    validated_request = mcp_patterns[\"mcp_invoke_success_001\"][\"request\"]\n    validated_request[\"params\"][\"arguments\"][\"city\"] = \"Boston\"\n\n    # Agent knows this will work because MCP validated it\n    response = agent.execute_tool(validated_request)\n\n    # Agent only validates its own behavior\n    assert agent.tool_selection == \"get_weather\"\n    assert agent.response_formatting == \"conversational\"\n\n    # Time saved: 85% (no tool testing needed)\n</code></pre>"},{"location":"testing/components/mcp_server/test_patterns/#example-2-workflow-using-agent-mcp-inheritance","title":"Example 2: Workflow Using Agent + MCP Inheritance","text":"<pre><code># Workflow test with full inheritance chain\ndef test_workflow_with_inheritance():\n    # Workflow inherits from agents, which inherit from MCP\n    inheritance_chain = {\n        \"mcp_servers\": {\n            \"weather_mcp\": {\n                \"quality\": 0.95,\n                \"security\": 0.98,\n                \"tools_validated\": [\"get_weather\", \"get_forecast\"]\n            }\n        },\n        \"agents\": {\n            \"weather_agent\": {\n                \"inherits_from\": [\"weather_mcp\"],\n                \"quality\": 0.93,  # Includes MCP quality\n                \"security\": 0.98   # Inherits MCP security\n            }\n        }\n    }\n\n    # Workflow only tests orchestration\n    workflow_test = {\n        \"test\": \"Multi-agent coordination\",\n        \"skip_tool_tests\": True,  # MCP validated\n        \"skip_agent_tool_selection\": True,  # Agent validated\n        \"focus\": \"workflow_orchestration\"\n    }\n\n    # Time saved: 70% through inheritance\n</code></pre>"},{"location":"testing/components/mcp_server/test_patterns/#example-3-cross-framework-pattern-usage","title":"Example 3: Cross-Framework Pattern Usage","text":"<pre><code># Same patterns work across frameworks\nCROSS_FRAMEWORK_USAGE = {\n    \"aurite\": {\n        \"uses_pattern\": \"mcp_invoke_success_001\",\n        \"adaptation\": \"none\",  # Native format\n        \"confidence\": 1.0\n    },\n    \"langchain\": {\n        \"uses_pattern\": \"mcp_invoke_success_001\",\n        \"adaptation\": \"translate_to_langchain_tool\",\n        \"confidence\": 0.95\n    },\n    \"autogen\": {\n        \"uses_pattern\": \"mcp_invoke_success_001\",\n        \"adaptation\": \"convert_to_autogen_function\",\n        \"confidence\": 0.95\n    }\n}\n</code></pre>"},{"location":"testing/components/mcp_server/test_patterns/#pattern-maintenance","title":"Pattern Maintenance","text":""},{"location":"testing/components/mcp_server/test_patterns/#adding-new-patterns","title":"Adding New Patterns","text":"<p>When adding new test patterns:</p> <ol> <li>Assign unique test_case_id following naming convention</li> <li>Document purpose clearly for inheritance understanding</li> <li>Include complete request/response for reusability</li> <li>Specify validation criteria that were verified</li> <li>Explain inheritance value for agents/workflows</li> </ol>"},{"location":"testing/components/mcp_server/test_patterns/#pattern-versioning","title":"Pattern Versioning","text":"<pre><code>PATTERN_VERSION = {\n    \"version\": \"1.0.0\",\n    \"last_updated\": \"2024-08-30\",\n    \"compatibility\": {\n        \"mcp_protocol\": \"1.0\",\n        \"frameworks\": [\"aurite\", \"langchain\", \"autogen\", \"crewai\"]\n    },\n    \"deprecation_notice\": None\n}\n</code></pre>"},{"location":"testing/components/mcp_server/test_patterns/#pattern-categories","title":"Pattern Categories","text":"<p>Organize patterns by testing purpose:</p> Category Purpose Pattern Count Inheritance Value Functional Basic tool operation 5-10 Core functionality validation Edge Cases Boundary conditions 5-10 Robustness confidence Performance Response times, throughput 3-5 Performance baselines Security Attack resistance 10-15 Security validation Error Handling Failure scenarios 5-10 Error handling confidence"},{"location":"testing/components/mcp_server/test_patterns/#best-practices","title":"Best Practices","text":""},{"location":"testing/components/mcp_server/test_patterns/#for-pattern-creation","title":"For Pattern Creation","text":"<ol> <li>Be Exhaustive: Include all details needed for reuse</li> <li>Be Explicit: Don't assume context, document everything</li> <li>Be Consistent: Follow the established structure</li> <li>Be Versioned: Track pattern changes over time</li> </ol>"},{"location":"testing/components/mcp_server/test_patterns/#for-pattern-usage","title":"For Pattern Usage","text":"<ol> <li>Load Once: Cache patterns at test initialization</li> <li>Validate Compatibility: Check pattern version matches</li> <li>Report Usage: Track which patterns are inherited</li> <li>Measure Savings: Calculate time saved through inheritance</li> </ol>"},{"location":"testing/components/mcp_server/test_patterns/#related-documentation","title":"Related Documentation","text":"<ul> <li>MCP Server Testing Overview - Main MCP testing documentation</li> <li>Test Inheritance - How patterns flow to agents</li> <li>Framework-Agnostic Testing - Cross-framework usage</li> <li>Testing Architecture - Overall testing framework</li> </ul>"},{"location":"usage/api_reference/","title":"API Reference","text":"<p>The Aurite Framework API is organized around four core managers, each with its own base path and specific responsibilities. This document provides a comprehensive reference for all available endpoints.</p> <p>Interactive API Docs</p> <p>For detailed request/response schemas and to try out the API live, please use the interactive documentation interfaces available when the server is running:</p> <ul> <li><code>/api-docs</code> - Swagger UI interface</li> <li><code>/redoc</code> - ReDoc documentation interface</li> <li><code>/openapi.json</code> - Raw OpenAPI schema</li> </ul>"},{"location":"usage/api_reference/#authentication-base-url","title":"Authentication &amp; Base URL","text":"<p>All API endpoints require authentication via an API key.</p> <ul> <li>Header: <code>X-API-Key: your-api-key-here</code></li> <li>Base URL: <code>http://localhost:8000</code></li> </ul>"},{"location":"usage/api_reference/#api-endpoints","title":"API Endpoints","text":"<p>The API is structured around four main routers.</p>  Configuration (<code>/config</code>) MCP Host (<code>/tools</code>) Execution (<code>/execution</code>) System (<code>/system</code>) <p>Handles all configuration file operations, component CRUD, and project/workspace management.</p> <p>Component CRUD</p> Method Endpoint Description <code>GET</code> <code>/config/components</code> List all component types. <code>GET</code> <code>/config/components/{type}</code> List all components of a specific type. <code>POST</code> <code>/config/components/{type}</code> Create a new component. <code>GET</code> <code>/config/components/{type}/{id}</code> Get a specific component's details. <code>PUT</code> <code>/config/components/{type}/{id}</code> Update an existing component. <code>DELETE</code> <code>/config/components/{type}/{id}</code> Delete a component. <code>POST</code> <code>/config/components/{type}/{id}/validate</code> Validate a component's configuration. <p>Project &amp; Workspace Management</p> Method Endpoint Description <code>GET</code> <code>/config/projects</code> List all projects in the current workspace. <code>POST</code> <code>/config/projects</code> Create a new project. <code>GET</code> <code>/config/projects/active</code> Get the currently active project. <code>GET</code> <code>/config/projects/{name}</code> Get details for a specific project. <code>PUT</code> <code>/config/projects/{name}</code> Update a project. <code>DELETE</code> <code>/config/projects/{name}</code> Delete a project. <code>GET</code> <code>/config/workspaces/active</code> Get the active workspace details. <p>Configuration File Operations</p> Method Endpoint Description <code>GET</code> <code>/config/sources</code> List all configuration source directories. <code>GET</code> <code>/config/files/{source}</code> List config files within a specific source. <code>POST</code> <code>/config/files</code> Create a new configuration file. <code>GET</code> <code>/config/files/{source}/{path}</code> Get a config file's content. <code>PUT</code> <code>/config/files/{source}/{path}</code> Update a config file's content. <code>DELETE</code> <code>/config/files/{source}/{path}</code> Delete a configuration file. <code>POST</code> <code>/config/refresh</code> Force a refresh of the configuration index. <code>POST</code> <code>/config/validate</code> Validate all loaded configurations. <p>Manages runtime operations for MCP servers, tool discovery, and execution.</p> <p>Tool Discovery &amp; Execution</p> Method Endpoint Description <code>GET</code> <code>/tools</code> List all available tools from registered servers. <code>GET</code> <code>/tools/{tool_name}</code> Get detailed information for a specific tool. <code>POST</code> <code>/tools/{tool_name}/call</code> Execute a specific tool with arguments. <p>Runtime Server Management</p> Method Endpoint Description <code>GET</code> <code>/tools/servers</code> List all currently registered MCP servers. <code>GET</code> <code>/tools/servers/{server_name}</code> Get detailed runtime status of a server. <code>POST</code> <code>/tools/servers/{server_name}/restart</code> Restart a registered server. <code>GET</code> <code>/tools/servers/{server_name}/tools</code> List all tools provided by a specific server. <code>POST</code> <code>/tools/servers/{server_name}/test</code> Test a server configuration. <code>DELETE</code> <code>/tools/servers/{server_name}</code> Unregister a server from the host. <p>Server Registration</p> Method Endpoint Description <code>POST</code> <code>/tools/register/config</code> Register a server using a config object. <code>POST</code> <code>/tools/register/{server_name}</code> Register a server by its configured name. <p>Handles agent and workflow execution, history management, and testing.</p> <p>Agent &amp; Workflow Execution</p> Method Endpoint Description <code>POST</code> <code>/execution/agents/{agent_name}/run</code> Execute an agent and wait for the result. <code>POST</code> <code>/execution/agents/{agent_name}/stream</code> Execute an agent and stream the response. <code>POST</code> <code>/execution/workflows/linear/{workflow_name}/run</code> Execute a linear workflow. <code>POST</code> <code>/execution/workflows/graph/{workflow_name}/run</code> Execute a graph workflow. <code>POST</code> <code>/execution/workflows/custom/{workflow_name}/run</code> Execute a custom workflow. <p>Testing &amp; Validation</p> Method Endpoint Description <code>POST</code> <code>/execution/agents/{agent_name}/test</code> Test an agent's configuration. <code>POST</code> <code>/execution/llms/{llm_config_id}/test</code> Test an LLM configuration. <code>POST</code> <code>/execution/workflows/linear/{workflow_name}/test</code> Test a linear workflow. <code>POST</code> <code>/execution/workflows/custom/{workflow_name}/test</code> Test a custom workflow. <code>POST</code> <code>/execution/evaluate</code> Run evaluation on a component. <code>POST</code> <code>/execution/evaluate/{evaluation_config_id}</code> Run evaluation on a component, using an evaluation config. <p>Execution History</p> <p>History Storage Requirements</p> <p>History storage depends on:</p> <ul> <li>Configuration: Agents/workflows must have <code>include_history: true</code> in their configuration</li> <li>Storage Backend: Set by <code>AURITE_ENABLE_DB</code> environment variable<ul> <li><code>false</code> (default): History stored in <code>.aurite_cache/</code> as JSON files</li> <li><code>true</code>: History stored in database (SQLite or PostgreSQL)</li> </ul> </li> <li>Database Mode: When using database storage, run <code>aurite export</code> after configuration changes</li> </ul> Method Endpoint Description <code>GET</code> <code>/execution/history</code> List all sessions (paginated). Filter with <code>agent_name</code> or <code>workflow_name</code> query params. <code>GET</code> <code>/execution/history/{session_id}</code> Get the full history for a specific session. <code>DELETE</code> <code>/execution/history/{session_id}</code> Delete a session's history. <code>POST</code> <code>/execution/history/cleanup</code> Clean up old sessions based on retention policy. <p>Provides system information, environment management, and monitoring.</p> <p>System Information</p> Method Endpoint Description <code>GET</code> <code>/system/info</code> Get detailed system information. <code>GET</code> <code>/system/health</code> Perform a comprehensive health check. <code>GET</code> <code>/system/version</code> Get framework version information. <code>GET</code> <code>/system/capabilities</code> List system capabilities and features. <p>Environment &amp; Dependencies</p> Method Endpoint Description <code>GET</code> <code>/system/environment</code> Get environment variables (sensitive values masked). <code>PUT</code> <code>/system/environment</code> Update non-sensitive environment variables. <code>GET</code> <code>/system/dependencies</code> List all installed Python dependencies. <code>POST</code> <code>/system/dependencies/check</code> Check the health of critical dependencies. <p>Monitoring</p> Method Endpoint Description <code>GET</code> <code>/system/monitoring/metrics</code> Get current system metrics (CPU, memory, etc.). <code>GET</code> <code>/system/monitoring/active</code> List active Aurite-related processes."},{"location":"usage/cli_reference/","title":"CLI Reference","text":"<p>The Aurite Command Line Interface (CLI) is the primary tool for interacting with the Aurite framework. It allows you to initialize projects, manage configurations, run agents and workflows, and start services.</p>"},{"location":"usage/cli_reference/#commands","title":"Commands","text":"<p>The CLI is organized into several main commands.</p> <code>aurite init</code> <code>aurite list</code> <code>aurite show</code> <code>aurite run</code> <code>aurite api</code>:material-desktop-mac: <code>aurite studio</code> <code>aurite edit</code> <code>aurite migrate</code> <code>aurite export</code> <code>aurite docker</code> <p>Initializes a new Aurite project or workspace.</p> Argument / Option Type Description <code>[NAME]</code> <code>string</code> An optional name for the new project or workspace. <code>-p</code>, <code>--project</code> <code>flag</code> Initialize a new project. <code>-w</code>, <code>--workspace</code> <code>flag</code> Initialize a new workspace. <p>Interactive Wizard</p> <p>Running <code>aurite init</code> without options starts an interactive wizard to guide you through creating a project or workspace (recommended).</p> <p>Inspects and lists configurations for different component types. If run without a subcommand, it displays a complete index of all available components.</p> Subcommand Description <code>all</code> Lists all available component configurations, grouped by type. <code>agents</code> Lists all available agent configurations. <code>llms</code> Lists all available LLM configurations. <code>mcp_servers</code> Lists all available MCP server configurations. <code>linear_workflows</code> Lists all available linear workflow configurations. <code>custom_workflows</code> Lists all available custom workflow configurations. <code>workflows</code> Lists all workflow configurations (both linear and custom). <code>index</code> Prints the entire component index as a formatted table. <p>Examples</p> <pre><code># List all available agents\naurite list agents\n\n# List all workflows (linear and custom)\naurite list workflows\n</code></pre> <p>Displays the detailed configuration for a specific component or all components of a certain type.</p> Argument / Option Type Description <code>&lt;NAME_OR_TYPE&gt;</code> <code>string</code> The name of a specific component (e.g., <code>my_agent</code>) or a component type (e.g., <code>agents</code>). <code>-f</code>, <code>--full</code> <code>flag</code> Display the complete, unabridged configuration. <code>-s</code>, <code>--short</code> <code>flag</code> Display a compact, summary view. <p>Examples</p> <pre><code># Show the full configuration for the \"Weather Agent\"\naurite show \"Weather Agent\" --full\n\n# Show a summary of all linear workflow configurations\naurite show linear_workflows -s\n</code></pre> <p>Executes a runnable framework component, such as an agent or a workflow.</p> Argument / Option Type Description <code>[NAME]</code> <code>string</code> The name of the component to run. <code>[USER_MESSAGE]</code> <code>string</code> The initial user message or input to provide to the component. <code>--system-prompt</code> <code>string</code> Override the agent's default system prompt for this run. <code>-id</code>, <code>--session-id</code> <code>string</code> Specify a session ID to maintain conversation history. <code>-s</code>, <code>--short</code> <code>flag</code> Display a compact, one-line summary of the run output. <code>-d</code>, <code>--debug</code> <code>flag</code> Display the full, raw event stream for debugging. <p>Execution Behavior</p> <ul> <li>Interactive Chat: Running an agent by <code>NAME</code> without a <code>USER_MESSAGE</code> launches an interactive chat TUI.</li> <li>Single-Shot: Providing a <code>USER_MESSAGE</code> runs the component once and streams the output to the terminal.</li> </ul> <p>Examples</p> <pre><code># Run the \"Weather Agent\" in interactive chat mode\naurite run \"Weather Agent\"\n\n# Run the \"Weather Agent\" once with a specific question\naurite run \"Weather Agent\" \"What is the weather in London?\"\n\n# Run the \"Weather Planning Workflow\"\naurite run \"Weather Planning Workflow\" \"Plan a trip to Paris next week\"\n\n# Run the \"Example Custom Workflow\" with JSON input\naurite run \"Example Custom Workflow\" '{\"city\": \"Tokyo\"}'\n</code></pre> <p>Starts the Aurite FastAPI server, which exposes the framework's functionality via a REST API. This is used to power web frontends and programmatic integrations.</p> <pre><code>aurite api\n</code></pre> <p>Starts the Aurite Studio integrated development environment, which launches both the API server and React frontend concurrently. This provides a unified development experience with automatic dependency management and graceful shutdown handling.</p> Option Description <code>--rebuild-fresh</code> Clean all build artifacts and rebuild frontend packages from scratch <p>Integrated Development Environment</p> <p>The studio command automatically:</p> <ul> <li>Validates Node.js and npm dependencies</li> <li>Installs frontend workspace dependencies if needed</li> <li>Builds frontend packages when artifacts are missing</li> <li>Starts the API server (if not already running)</li> <li>Launches the React development server on port 3000</li> <li>Provides unified logging with <code>[API]</code> and <code>[STUDIO]</code> prefixes</li> <li>Handles graceful shutdown with Ctrl+C</li> </ul> <p>System Requirements</p> <ul> <li>Node.js &gt;= 18.0.0</li> <li>npm &gt;= 8.0.0</li> </ul> <p>Examples</p> <pre><code># Start the integrated development environment\naurite studio\n\n# Start with a fresh rebuild of frontend packages\naurite studio --rebuild-fresh\n</code></pre> <p>Fresh Rebuild Process</p> <p>When using <code>--rebuild-fresh</code>, the command performs:</p> <ol> <li>Clean Build Artifacts: Runs <code>npm run clean</code> to remove all build outputs</li> <li>Clear npm Cache: Removes <code>node_modules/.cache</code> directory</li> <li>Rebuild Packages: Runs <code>npm run build</code> to rebuild all workspace packages</li> <li>Start Servers: Proceeds with normal server startup</li> </ol> <p>Ports Used</p> <ul> <li>API Server: Configured port (default 8000)</li> <li>Studio UI: http://localhost:3000</li> </ul> <p>Starts the Aurite configuration editor TUI, a powerful terminal-based interface for creating and modifying component configurations.</p> Argument Type Description <code>[COMPONENT_NAME]</code> <code>string</code> (Optional) The name of a component to open directly for editing. <p>TUI Interface</p> <p>The editor features a three-pane layout for navigation, component listing, and editing, with interactive widgets and dropdowns for easy configuration.</p> <p>Examples</p> <pre><code># Open the TUI editor\naurite edit\n\n# Open the \"Weather Agent\" configuration directly in the editor\naurite edit \"Weather Agent\"\n</code></pre> <p>Migrates data between SQLite and PostgreSQL databases. This is useful when transitioning between development and production environments or creating backups.</p> Option Type Description <code>--source-type</code> <code>string</code> Source database type (<code>sqlite</code> or <code>postgresql</code>) <code>--target-type</code> <code>string</code> Target database type (<code>sqlite</code> or <code>postgresql</code>) <code>--source-path</code> <code>string</code> Path to source SQLite database (if source is SQLite) <code>--target-path</code> <code>string</code> Path to target SQLite database (if target is SQLite) <code>--from-env</code> <code>flag</code> Use current environment configuration as source <code>--verify/--no-verify</code> <code>flag</code> Verify migration after completion (default: verify) <p>Interactive Mode</p> <p>Running <code>aurite migrate</code> without options starts an interactive wizard that guides you through the migration process, using environment variables as defaults where available.</p> <p>Examples</p> <pre><code># Interactive migration wizard\naurite migrate\n\n# Migrate from current database to opposite type\naurite migrate --from-env\n\n# Migrate from SQLite to PostgreSQL (uses env vars for PostgreSQL)\naurite migrate --source-type sqlite --target-type postgresql\n\n# Create a backup of production PostgreSQL to local SQLite\naurite migrate \\\n  --source-type postgresql \\\n  --target-type sqlite \\\n  --target-path backups/aurite_backup.db\n</code></pre> <p>Environment Variables</p> <p>The migration command automatically uses your configured environment variables for database connections, making it easy to migrate between your configured databases.</p> <p>Exports all configurations from the file system to the database. This command reads from local config files and uploads them to your configured database (SQLite or PostgreSQL).</p> <p>Examples</p> <pre><code># Export all local configurations to the database\naurite export\n</code></pre> <p>Database Mode Required</p> <p>This command requires <code>AURITE_ENABLE_DB=true</code> in your environment configuration. The database type and connection details are determined by your environment variables.</p> <p>What Gets Exported</p> <ul> <li>All agent configurations</li> <li>All LLM configurations</li> <li>All MCP server configurations</li> <li>All workflow configurations (linear and custom)</li> <li>Any other component configurations in your workspace</li> </ul> <p>Manages Aurite Docker containers for containerized deployment and development. This command provides a complete Docker workflow from initialization to deployment.</p> Argument / Option Type Description <code>[ACTION]</code> <code>string</code> Docker action to perform (default: <code>run</code>) <code>-p</code>, <code>--project</code> <code>string</code> Path to Aurite project directory (default: current directory) <code>-n</code>, <code>--name</code> <code>string</code> Container name (default: <code>aurite-server</code>) <code>--port</code> <code>integer</code> Port to expose (default: <code>8000</code>) <code>-e</code>, <code>--env-file</code> <code>string</code> Path to environment file <code>-v</code>, <code>--version</code> <code>string</code> Docker image version tag (default: <code>latest</code>) <code>-d/-D</code>, <code>--detach/--no-detach</code> <code>flag</code> Run in background (default: detached) <code>--pull</code> <code>flag</code> Pull latest image before running <code>-f</code>, <code>--force</code> <code>flag</code> Force action (e.g., remove existing container) <code>-t</code>, <code>--build-tag</code> <code>string</code> Tag for built image (e.g., <code>my-project:latest</code>) <code>--push</code> <code>flag</code> Push built image to registry after building <code>--regenerate</code> <code>flag</code> Regenerate Docker files with fresh templates <code>--dockerfile</code> <code>string</code> Path to custom Dockerfile (build action only) <p>Actions</p> Action Description <code>run</code> Start a new container (mounts project as volume) <code>stop</code> Stop running container <code>logs</code> View container logs <code>shell</code> Open shell in container <code>status</code> Check container status <code>pull</code> Pull latest image <code>build</code> Build custom image with project embedded <code>init</code> Create Docker files without building <p>Container vs Build Modes</p> <ul> <li>Run Mode: Mounts your project directory as a volume for development</li> <li>Build Mode: Embeds your project into a custom image for deployment</li> </ul> <p>Examples</p> <pre><code># Start Aurite container with project mounted as volume\naurite docker run\n\n# Start container with custom settings\naurite docker run --port 9000 --name my-aurite --env-file .env.prod\n\n# Initialize Docker files for customization\naurite docker init\n\n# Build custom image with project embedded\naurite docker build --build-tag my-project:v1.0\n\n# Build and push to registry\naurite docker build --build-tag my-project:v1.0 --push\n\n# Check container status\naurite docker status --name my-aurite\n\n# View container logs\naurite docker logs --name my-aurite\n\n# Open shell in running container\naurite docker shell --name my-aurite\n\n# Stop container\naurite docker stop --name my-aurite\n\n# Pull latest base image\naurite docker pull --version latest\n</code></pre> <p>Docker File Management</p> <p>The <code>init</code> and <code>build</code> actions create two files in your project directory:</p> <ul> <li><code>Dockerfile.aurite</code>: Customizable Dockerfile with a USER CUSTOMIZATION SECTION</li> <li><code>.dockerignore</code>: Optimized ignore patterns for Aurite projects</li> </ul> <p>Customization Workflow</p> <ol> <li>Run <code>aurite docker init</code> to create Docker files</li> <li>Edit the USER CUSTOMIZATION SECTION in <code>Dockerfile.aurite</code> to add dependencies</li> <li>Run <code>aurite docker build</code> to create your custom image</li> <li>Use <code>--regenerate</code> flag to overwrite existing Docker files with fresh templates</li> </ol> <p>Pre-flight Checks</p> <p>The <code>run</code> action performs automatic validation:</p> <ul> <li>\u2713 Docker installation and daemon status</li> <li>\u2713 Aurite project directory validation (<code>.aurite</code> file)</li> <li>\u2713 Environment file detection and confirmation</li> <li>\u2713 Port availability checking</li> <li>\u2713 Container name conflict resolution</li> </ul> <p>System Requirements</p> <ul> <li>Docker installed and running</li> <li>Valid Aurite project directory (contains <code>.aurite</code> file)</li> <li>Available port for API server (default: 8000)</li> </ul> <p>Container Features</p> <p>When running containers, you get:</p> <ul> <li>API Server: <code>http://localhost:{port}</code></li> <li>Health Check: <code>http://localhost:{port}/health</code></li> <li>API Documentation: <code>http://localhost:{port}/api-docs</code></li> <li>Project volume mount: <code>/app/project</code> (run mode)</li> <li>Environment file support</li> <li>Automatic cleanup on container removal</li> </ul> <p>Environment Variables</p> <p>The Docker container supports several environment variables for configuration:</p> Variable Default Description <code>API_KEY</code> required Authentication key for API server access <code>AURITE_ENABLE_DB</code> <code>false</code> Enable database mode (SQLite or PostgreSQL) <code>AURITE_AUTO_EXPORT</code> <code>true</code> Automatically export configurations to database on startup <code>LOG_LEVEL</code> <code>INFO</code> Set to <code>DEBUG</code> for verbose container logging <p>Database Configuration (when <code>AURITE_ENABLE_DB=true</code>):</p> Variable Description <code>AURITE_DB_TYPE</code> Database type (<code>sqlite</code> or <code>postgres</code>) <code>AURITE_DB_HOST</code> PostgreSQL host (if using PostgreSQL) <code>AURITE_DB_PORT</code> PostgreSQL port (default: 5432) <code>AURITE_DB_USER</code> PostgreSQL username <code>AURITE_DB_PASSWORD</code> PostgreSQL password <code>AURITE_DB_NAME</code> Database name <p>Auto-Export Behavior</p> <p>When <code>AURITE_ENABLE_DB=true</code>, the container automatically exports all file-based configurations to the database on startup unless <code>AURITE_AUTO_EXPORT=false</code> is set. This ensures your database stays synchronized with your project files.</p> <p>Examples with Environment Variables</p> <pre><code># Run with database mode and auto-export enabled\naurite docker run \\\n  --env-file .env \\\n  -e AURITE_ENABLE_DB=true \\\n  -e AURITE_AUTO_EXPORT=true \\\n  -e API_KEY=$(openssl rand -hex 32)\n\n# Run with auto-export disabled\naurite docker run \\\n  --env-file .env \\\n  -e AURITE_ENABLE_DB=true \\\n  -e AURITE_AUTO_EXPORT=false \\\n  -e API_KEY=your-secure-api-key\n\n# Run with debug logging\naurite docker run \\\n  --env-file .env \\\n  -e LOG_LEVEL=DEBUG \\\n  -e API_KEY=your-secure-api-key\n</code></pre>"},{"location":"usage/cli_reference/#global-options","title":"Global Options","text":"<p>These options can be used with the base <code>aurite</code> command.</p> Option Description <code>--install-completion</code> Installs shell completion for the <code>aurite</code> command. <code>--show-completion</code> Displays the shell completion script to be sourced or saved manually. <code>--help</code> Shows the main help message listing all commands."},{"location":"usage/database_guide/","title":"Database Integration Guide","text":"<p>The Aurite framework provides an optional database backend for managing component configurations and conversation history. This guide explains how to set up and use this feature with support for both SQLite (default) and PostgreSQL databases.</p>"},{"location":"usage/database_guide/#overview","title":"Overview","text":"<p>By default, Aurite uses a file-based system for managing configurations (agents, LLMs, etc.) and conversation history. When database mode is enabled, you can choose between:</p> <ul> <li>SQLite (default): Zero-configuration, file-based database perfect for local development and single-user deployments</li> <li>PostgreSQL: Full-featured database for production environments, multi-user setups, and distributed deployments</li> </ul>"},{"location":"usage/database_guide/#what-gets-stored-in-the-database","title":"What Gets Stored in the Database","text":"<p>When database mode is enabled, the following data is persisted:</p> <ol> <li>Component Configurations: All agents, LLMs, workflows, and MCP server configurations</li> <li>Conversation History: Complete agent conversation histories including:</li> <li>User messages</li> <li>Assistant responses</li> <li>Tool calls and results</li> <li>Session metadata (timestamps, agent names, session IDs)</li> </ol> <p>The <code>ConfigManager</code> loads all component configurations from the database into memory on startup. The <code>SessionManager</code> handles conversation history persistence, automatically storing and retrieving conversation data based on your storage configuration.</p>"},{"location":"usage/database_guide/#enabling-database-mode","title":"Enabling Database Mode","text":"<p>To enable the database backend, set the following environment variable in your .env file:</p> <pre><code>AURITE_ENABLE_DB=true\n</code></pre> <p>When this variable is set to <code>true</code>, the framework will connect to the database specified by the configuration variables below. If it is <code>false</code> or not set, the framework will fall back to the default file-based system.</p> <p>Important: Export Required</p> <p>When database mode is enabled, configurations are read from the database, not from files. You must run <code>aurite export</code> to sync your file-based configurations to the database:</p> <pre><code>- After first enabling database mode\n- After making changes to configuration files\n- Whenever configurations appear to be missing or outdated\n\nWithout running `aurite export`, your agents and workflows will not be available when database mode is enabled.\n</code></pre>"},{"location":"usage/database_guide/#database-type-selection","title":"Database Type Selection","text":"<p>Choose your database type with the <code>AURITE_DB_TYPE</code> environment variable:</p> <pre><code># For SQLite (default, zero-configuration)\nAURITE_DB_TYPE=sqlite\n\n# For PostgreSQL (production-ready, multi-user)\nAURITE_DB_TYPE=postgresql\n</code></pre>"},{"location":"usage/database_guide/#sqlite-configuration","title":"SQLite Configuration","text":"<p>SQLite is the default database type and requires minimal configuration:</p> Variable Description Default <code>AURITE_DB_PATH</code> Path to the SQLite database file <code>.aurite_db/aurite.db</code> <p>Example <code>.env</code> configuration for SQLite:</p> <pre><code>AURITE_ENABLE_DB=true\nAURITE_DB_TYPE=sqlite\nAURITE_DB_PATH=.aurite_db/aurite.db  # Optional, this is the default\n</code></pre>"},{"location":"usage/database_guide/#sqlite-advantages","title":"SQLite Advantages","text":"<ul> <li>Zero configuration: Works out of the box</li> <li>Portable: Database is a single file</li> <li>No external dependencies: No separate database server needed</li> <li>Perfect for development: Quick setup and teardown</li> <li>Lightweight: Minimal resource usage</li> </ul>"},{"location":"usage/database_guide/#sqlite-limitations","title":"SQLite Limitations","text":"<ul> <li>Single-user write access (multiple readers OK)</li> <li>Limited concurrent connections</li> <li>Not suitable for distributed deployments</li> </ul>"},{"location":"usage/database_guide/#postgresql-configuration","title":"PostgreSQL Configuration","text":"<p>PostgreSQL provides a robust, production-ready database solution:</p> Variable Description Default <code>AURITE_DB_HOST</code> The hostname or IP address of your PostgreSQL server <code>localhost</code> <code>AURITE_DB_PORT</code> The port your PostgreSQL server is running on <code>5432</code> <code>AURITE_DB_USER</code> The username for connecting to the database (required) <code>AURITE_DB_PASSWORD</code> The password for the database user (required) <code>AURITE_DB_NAME</code> The name of the database to use for storing Aurite data <code>aurite_storage</code> <p>Example <code>.env</code> configuration for PostgreSQL:</p> <pre><code>AURITE_ENABLE_DB=true\nAURITE_DB_TYPE=postgresql\nAURITE_DB_HOST=localhost\nAURITE_DB_PORT=5432\nAURITE_DB_USER=postgres_user\nAURITE_DB_PASSWORD=postgres_password\nAURITE_DB_NAME=aurite_storage\n</code></pre>"},{"location":"usage/database_guide/#postgresql-advantages","title":"PostgreSQL Advantages","text":"<ul> <li>Multi-user support: Handles concurrent access efficiently</li> <li>Scalability: Suitable for large-scale deployments</li> <li>Advanced features: Full SQL support, transactions, replication</li> <li>Production-ready: Battle-tested for enterprise use</li> <li>Distributed deployments: Can be accessed from multiple servers</li> </ul>"},{"location":"usage/database_guide/#postgresql-requirements","title":"PostgreSQL Requirements","text":"<ul> <li>PostgreSQL server (version 12 or higher recommended)</li> <li>Database user with CREATE TABLE permissions</li> <li>Network access to the database server</li> </ul>"},{"location":"usage/database_guide/#local-postgresql-setup","title":"Local PostgreSQL Setup","text":"<p>If PostgreSQL is not installed on your system, you can install it (on Linux, Mac, and WSL) using:</p> <pre><code>sudo apt-get update &amp;&amp; sudo apt-get install -y postgresql postgresql-contrib\n</code></pre> <p>To create a database user and database for Aurite, run:</p> <pre><code>sudo -u postgres psql -c \"CREATE USER postgres_user WITH PASSWORD 'postgres_password';\"\nsudo -u postgres psql -c \"CREATE DATABASE aurite_storage OWNER postgres_user;\"\n</code></pre> <p>You can ignore this error:</p> <pre><code>could not change directory to \"/path/to/aurite-agents\": Permission denied\n</code></pre> <p>This will create a user named <code>postgres_user</code> with the password <code>postgres_password</code>, and a database named <code>aurite_storage</code> owned by that user.</p>"},{"location":"usage/database_guide/#conversation-history-storage","title":"Conversation History Storage","text":"<p>When database mode is enabled, all agent conversation histories are automatically stored in the database. This provides several benefits:</p> <ul> <li>Persistence: Conversations survive application restarts</li> <li>Searchability: Query historical conversations (future feature)</li> <li>Analytics: Analyze conversation patterns and agent performance</li> <li>Compliance: Maintain audit trails of all interactions</li> </ul>"},{"location":"usage/database_guide/#how-it-works","title":"How It Works","text":"<p>The <code>SessionManager</code> automatically detects whether database mode is enabled:</p> <ul> <li>Database Enabled (<code>AURITE_ENABLE_DB=true</code>): Conversations are stored in the <code>agent_history</code> table</li> <li>Database Disabled (default): Conversations are stored in <code>.aurite_cache/</code> as JSON files</li> </ul> <p>Each conversation message is stored with:</p> <ul> <li><code>agent_name</code>: The agent that handled the conversation</li> <li><code>session_id</code>: Unique identifier for the conversation session</li> <li><code>role</code>: Message role (user, assistant, or tool)</li> <li><code>content_json</code>: The actual message content</li> <li><code>timestamp</code>: When the message was created</li> </ul>"},{"location":"usage/database_guide/#session-management","title":"Session Management","text":"<p>Sessions are automatically managed based on agent configuration:</p> <pre><code># Agent configuration with history enabled\nname: \"My Agent\"\ntype: agent\ninclude_history: true # Enables conversation history storage\n</code></pre> <p>When <code>include_history</code> is true:</p> <ul> <li>A unique session ID is generated for each conversation</li> <li>All messages are persisted to the configured storage backend</li> <li>Previous conversation history can be retrieved for context</li> </ul>"},{"location":"usage/database_guide/#exporting-configurations-to-the-database","title":"Exporting Configurations to the Database","text":"<p>When database mode is enabled, you must export your file-based configurations to the database using the <code>aurite export</code> command:</p> <pre><code>aurite export\n</code></pre> <p>This command will:</p> <ol> <li>Read all your component configurations from the local file system</li> <li>Connect to the database (SQLite or PostgreSQL based on your configuration)</li> <li>Create the necessary tables if they don't exist</li> <li>Upload all your component configurations to the database</li> </ol> <p>When to run <code>aurite export</code>:</p> <ul> <li>Required: After first enabling database mode with <code>AURITE_ENABLE_DB=true</code></li> <li>Required: After modifying any configuration files while database mode is enabled</li> <li>Required: When configurations appear missing or outdated in the API/CLI</li> <li>Optional: To refresh database configurations from files at any time</li> </ul> <p>Note: Existing conversation histories in <code>.aurite_cache/</code> are not automatically migrated. Use the migration tool if you need to preserve historical conversations.</p>"},{"location":"usage/database_guide/#database-migration","title":"Database Migration","text":"<p>Aurite provides a built-in migration tool to move data between SQLite and PostgreSQL databases. This is useful when:</p> <ul> <li>Transitioning from development (SQLite) to production (PostgreSQL)</li> <li>Moving from production back to local development</li> <li>Backing up data to a different database type</li> </ul>"},{"location":"usage/database_guide/#interactive-migration","title":"Interactive Migration","text":"<p>The simplest way to migrate is using the interactive mode:</p> <pre><code># Interactive migration wizard\naurite migrate\n\n# Migrate from current database to the opposite type\naurite migrate --from-env\n</code></pre>"},{"location":"usage/database_guide/#command-line-migration","title":"Command-Line Migration","text":"<p>For automation and scripting, you can specify parameters directly:</p> <pre><code># Migrate from SQLite to PostgreSQL\naurite migrate \\\n  --source-type sqlite \\\n  --source-path .aurite_db/aurite.db \\\n  --target-type postgresql\n\n# The command will use environment variables for PostgreSQL connection\n# or prompt for missing information\n</code></pre>"},{"location":"usage/database_guide/#migration-examples","title":"Migration Examples","text":""},{"location":"usage/database_guide/#example-1-development-to-production","title":"Example 1: Development to Production","text":"<p>Moving from local SQLite development to PostgreSQL production:</p> <pre><code># Set up your PostgreSQL connection in .env\nAURITE_DB_HOST=production.server.com\nAURITE_DB_USER=prod_user\nAURITE_DB_PASSWORD=secure_password\nAURITE_DB_NAME=aurite_production\n\n# Run migration\naurite migrate --from-env\n</code></pre>"},{"location":"usage/database_guide/#example-2-production-backup-to-sqlite","title":"Example 2: Production Backup to SQLite","text":"<p>Creating a local backup of production data:</p> <pre><code># Assuming PostgreSQL is configured in environment\naurite migrate \\\n  --source-type postgresql \\\n  --target-type sqlite \\\n  --target-path backups/aurite_backup_$(date +%Y%m%d).db\n</code></pre>"},{"location":"usage/database_guide/#example-3-switching-database-types","title":"Example 3: Switching Database Types","text":"<p>If you need to switch your active database type:</p> <ol> <li>Migrate the data:</li> </ol> <pre><code>aurite migrate --from-env\n</code></pre> <ol> <li> <p>Update your <code>.env</code> file with the new database configuration</p> </li> <li> <p>Restart your Aurite services</p> </li> </ol>"},{"location":"usage/database_guide/#migration-verification","title":"Migration Verification","text":"<p>The migration tool automatically verifies that all records were successfully transferred by comparing record counts between source and target databases. You can disable this with <code>--no-verify</code> if needed.</p>"},{"location":"usage/database_guide/#docker-deployment","title":"Docker Deployment","text":"<p>When using Docker, the PostgreSQL service is optional. Here's how to configure each database type:</p>"},{"location":"usage/database_guide/#using-sqlite-with-docker","title":"Using SQLite with Docker","text":"<pre><code># docker-compose.yml\nservices:\n  aurite:\n    image: aurite:latest\n    environment:\n      - AURITE_ENABLE_DB=true\n      - AURITE_DB_TYPE=sqlite\n      - AURITE_DB_PATH=/data/aurite.db\n    volumes:\n      - ./data:/data # Persist SQLite database\n</code></pre>"},{"location":"usage/database_guide/#using-postgresql-with-docker","title":"Using PostgreSQL with Docker","text":"<pre><code># docker-compose.yml\nservices:\n  aurite:\n    image: aurite:latest\n    environment:\n      - AURITE_ENABLE_DB=true\n      - AURITE_DB_TYPE=postgresql\n      - AURITE_DB_HOST=postgres\n      - AURITE_DB_PORT=5432\n      - AURITE_DB_USER=postgres_user\n      - AURITE_DB_PASSWORD=postgres_password\n      - AURITE_DB_NAME=aurite_storage\n    depends_on:\n      - postgres\n\n  postgres:\n    image: postgres:15\n    environment:\n      - POSTGRES_USER=postgres_user\n      - POSTGRES_PASSWORD=postgres_password\n      - POSTGRES_DB=aurite_storage\n    volumes:\n      - postgres_data:/var/lib/postgresql/data\n\nvolumes:\n  postgres_data:\n</code></pre>"},{"location":"usage/database_guide/#performance-considerations","title":"Performance Considerations","text":""},{"location":"usage/database_guide/#sqlite-performance-tips","title":"SQLite Performance Tips","text":"<ul> <li>Keep the database file on a fast local disk (avoid network drives)</li> <li>Use WAL mode (automatically enabled by Aurite)</li> <li>Regular VACUUM operations for long-running deployments</li> <li>Consider migration to PostgreSQL if you need concurrent writes</li> </ul>"},{"location":"usage/database_guide/#postgresql-performance-tips","title":"PostgreSQL Performance Tips","text":"<ul> <li>Ensure adequate shared_buffers and work_mem settings</li> <li>Use connection pooling for high-traffic deployments</li> <li>Regular VACUUM and ANALYZE operations</li> <li>Consider read replicas for scaling read operations</li> </ul>"},{"location":"usage/database_guide/#troubleshooting","title":"Troubleshooting","text":""},{"location":"usage/database_guide/#common-sqlite-issues","title":"Common SQLite Issues","text":"<p>Error: Database is locked</p> <ul> <li>Solution: Ensure only one process is writing to the database</li> <li>Consider upgrading to PostgreSQL for multi-user access</li> </ul> <p>Error: No such table</p> <ul> <li>Solution: Run <code>aurite export</code> to create tables and populate initial data</li> </ul> <p>Error: Configurations not loading when database enabled</p> <ul> <li>Solution: Run <code>aurite export</code> to sync file-based configurations to the database</li> <li>This is required after enabling database mode or modifying configuration files</li> <li>The database stores configurations separately from files and must be explicitly synced</li> </ul>"},{"location":"usage/database_guide/#common-postgresql-issues","title":"Common PostgreSQL Issues","text":"<p>Error: Connection refused</p> <ul> <li>Check that PostgreSQL is running and accessible</li> <li>Verify firewall rules allow connection on the specified port</li> <li>Ensure AURITE_DB_HOST is correct (use 'postgres' in Docker)</li> </ul> <p>Error: Authentication failed</p> <ul> <li>Verify AURITE_DB_USER and AURITE_DB_PASSWORD are correct</li> <li>Check PostgreSQL pg_hba.conf for authentication settings</li> </ul> <p>Error: Database does not exist</p> <ul> <li>Create the database manually or ensure the user has CREATE DATABASE permissions</li> </ul>"},{"location":"usage/database_guide/#best-practices","title":"Best Practices","text":"<ol> <li>Development: Use SQLite for simplicity and portability</li> <li>Production: Use PostgreSQL for reliability and scalability</li> <li>Backups: Regular backups regardless of database type</li> <li>Migration: Test migrations in a staging environment first</li> <li>Monitoring: Monitor database size and performance metrics</li> <li>Security: Use strong passwords and restrict database access</li> </ol>"},{"location":"usage/database_guide/#configuration-reference","title":"Configuration Reference","text":""},{"location":"usage/database_guide/#force-refresh","title":"Force Refresh","text":"<p>Control whether the database configurations are reloaded for every operation:</p> <pre><code># Reload from database on every operation (slower but always current)\nAURITE_CONFIG_FORCE_REFRESH=true\n\n# Cache configurations in memory (faster, default)\nAURITE_CONFIG_FORCE_REFRESH=false\n</code></pre> <p>Set to <code>true</code> if you're making manual database changes and need immediate updates in Aurite.</p>"},{"location":"usage/tui_guide/","title":"TUI Guide","text":"<p>The Aurite framework includes two powerful Textual User Interfaces (TUIs) to enhance your development experience directly in the terminal: the Interactive Chat TUI and the Configuration Editor TUI.</p>"},{"location":"usage/tui_guide/#tui-interfaces","title":"TUI Interfaces","text":"Interactive Chat TUI Configuration Editor TUI <p>The Chat TUI provides a rich, interactive environment for conversing with your agents, viewing tool calls in real-time, and managing conversation history.</p> <p>How to Launch</p> <p>The Chat TUI is launched using the <code>aurite run</code> command when you specify an agent's name without providing a user message.</p> <pre><code># Launch a new chat session with an agent\naurite run my_chat_agent\n\n# Continue a previous conversation\naurite run my_chat_agent --session-id \"some-previous-session-id\"\n</code></pre> <p>Interface Overview:</p> <ol> <li>Header: Displays the agent name and the current session ID.</li> <li>Agent Info Panel: Shows key details about the agent (system prompt, LLM, etc.).</li> <li>Chat History: The main panel displaying the conversation, including user messages, agent responses, and tool calls.</li> <li>User Input: The text area at the bottom for composing messages.</li> <li>Footer: Displays key bindings.</li> </ol> <p>Key Bindings</p> <ul> <li><code>Ctrl+Enter</code>: Send the message to the agent.</li> <li><code>Ctrl+C</code>: Exit the chat application.</li> </ul> <p>The Configuration Editor TUI (<code>aurite edit</code>) is a powerful tool for creating, viewing, and modifying all your component configurations without manually editing JSON or YAML files.</p> <p>How to Launch</p> <p>You can launch the editor in two ways:</p> <pre><code># General Mode: Browse all configurations\naurite edit\n\n# Direct Edit Mode: Open a specific component\naurite edit my_agent\n</code></pre> <p>Interface Overview:</p> <p>The editor uses a three-pane layout for efficient navigation:</p> <ol> <li>Navigation Tree (Left): A tree of all component types (<code>agent</code>, <code>llm</code>, etc.).</li> <li>Component List (Middle): A table listing all components of the selected type.</li> <li>Configuration Editor (Right): An interactive form for editing the selected component's fields.</li> </ol> <p>How to Use</p> <ol> <li>Navigate: Use arrow keys to move between panes and select items.</li> <li>Edit: Use <code>Tab</code> to move between fields in the editor. Press <code>Enter</code> on dropdowns or buttons to open them.</li> <li>Save: Navigate to the \"Save Configuration\" button and press <code>Enter</code> to write your changes to the file.</li> <li>Exit: Press <code>Ctrl+C</code> to exit the editor.</li> </ol>"}]}